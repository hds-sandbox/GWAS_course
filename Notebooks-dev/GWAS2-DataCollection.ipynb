{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361d7e21-7da8-4ef0-b99b-7e2727aaa84c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data collection\"  \n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc: true\n",
    "  ipynb:\n",
    "    toc: true\n",
    "    number-sections: false\n",
    "bibliography: references/references_2.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd15249-6fe4-4640-9dc4-47806f6e7971",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"Important notes for this notebook\" icon=false}\n",
    "\n",
    "This course module introduces fundamental concepts regarding designing and executing GWAS. We touch on data collection (which involves gathering genomic data and phenotypic information from diverse populations), potential biases, and practical considerations on the standard file formats in GWAS.\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "- **Understand and identify** types of GWAS studies in the scientific literature\n",
    "- **Explore** the content of classical data files for GWAS through the command line\n",
    "- **Apply and extend** some command line programs to retrieve and explore data\n",
    "\n",
    "## How to make this notebook work\n",
    "\n",
    "We will only use the `bash command line` in this notebook. Be sure to click on the menu `Kernel --> Change Kernel --> Bash`\n",
    "\n",
    "<img src=\"Images/bash.png\" alt=\"Bash\" width=\"80\"> Choose the Bash kernel\n",
    "\n",
    ":::\n",
    "\n",
    "# Introduction to study design\n",
    "\n",
    "GWAS often require very large sample sizes to identify reproducible genome-wide significant associations, and one would need to conduct power calculations to determine the appropriate sample size. Generally speaking, there are two types of study design depending on the nature of the trait of interest:\n",
    "\n",
    "- **1)** Case-control studies when the trait of interest is dichotomous (e.g. Type 2 diabetes)\n",
    "- **2)** Quantitative measurements on the whole study sample when the trait is quantitative (e.g. height)\n",
    "\n",
    "In addition, one can choose between population-based and family-based designs. The choice generally depends on the data you have available - that is, if you have fewer samples, you can control for close relationships in your analyses rather than removing related individuals. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73499f",
   "metadata": {},
   "source": [
    "![Figure 1. Potential study designs](Images/design.png){width=75%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8853b",
   "metadata": {},
   "source": [
    "The goal of data collection is to ensure you have all the essential information required for downstream analyses. These areas of information could include:\n",
    "\n",
    "* Biological samples: blood samples or similar (for later genotyping)\n",
    "* Information about the traits of interest\n",
    "* Clinical data: disease status e.g. have diabetes (case) vs do not have diabetes (control)\n",
    "* Quantitative measurements e.g. biometric data, cholesterol, blood pressure, or blood sugar\n",
    "* Questionnaires: additional potentially relevant info, like sex, age, or lifestyle\n",
    "\n",
    "It is crucial to understand that any method used to obtain the required data will require informed consent and ethical approval. Achieving this can be quite challenging in practice, which is why publicly available biobanks are so widely utilized.\n",
    "\n",
    "GWAS can be conducted using data from resources such as biobanks, cohorts with disease-focused or population-based recruitment, or direct-to-consumer studies. Several excellent public resources provide access to large cohorts with genotypic and phenotypic information, and the majority of GWAS are conducted using these preexisting resources. Some notable examples include the UK Biobank, FinnGen, Biobank Japan, and the All of Us Research Program. \n",
    "\n",
    "Recruitment strategies must be carefully considered for all study designs as these can induce various forms of bias. For example, widely used research cohorts such as the UK Biobank recruit participants through a volunteer-based strategy. What this means in practice is that participants are, on average, healthier, wealthier, and more educated than the general population. Furthermore, cohorts that enroll participants from hospitals based on their disease status (such as BioBank Japan [@nagai_overview_2017]) will have different selection biases to cohorts recruited from the general population. Unlike research studies that focus on one disease or group of people, the new American initiative known as All of Us is building a diverse database designed to inform thousands of studies on a variety of health conditions. Different ethnicities, like the example just mentioned, can be included in the same study to make better predictions for people with different backgrounds, as long as the population substructure is considered to avoid false positive results.\n",
    "\n",
    "Finally, study annotation is essential for rigorous scientific practice. This involves detailing the chosen study design, providing a thorough description of the study, and including specifics such as sample inclusion criteria (e.g., ancestry, clinical features) and the phenotype of interest in your association analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b465c5",
   "metadata": {},
   "source": [
    "# Genotyping\n",
    "\n",
    "Genotyping efficiently captures genetic variation by selecting informative SNPs, often in high linkage disequilibrium (LD), which reduces redundancy. Focusing on these SNPs minimizes computational load and improves cost-efficiency for a specific population.\n",
    "\n",
    "Genotypic data can be obtained through microarrays to detect common variants, or through next-generation sequencing techniques for whole-genome sequencing (WGS) or whole-exome sequencing (WES). Microarray-based genotyping is the most commonly used method for obtaining genotypes for GWAS owing to the current cost of next-generation sequencing. However, as shown in @fig-cost,  the decreasing cost per human genome is expected to make WGS the preferred method. Nevertheless, the choice of genotyping platform depends on many factors and tends to be guided by the purpose of the GWAS. For example, in a consortium-led GWAS, it is usually wise to have all individual cohorts genotyped on the same genotyping platform (to avoid problems with batch bias). \n",
    "\n",
    "To enhance the power of GWAS, large reference panels are used to impute genotype data. This statistical technique predicts unobserved genotypes in the study sample based on observed genotypes and a reference panel. In other words, imputation fills in missing genotypes, increasing the number of variants that can be tested for association with traits. As mentioned before, it is crucial for the reference panel to be large and diverse to capture the genetic diversity of the entire population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fbd9e",
   "metadata": {},
   "source": [
    "![The trend of cost of sequencing an entire genome through the years. This shows a development faster than what would be predicted by Moore's Law, which suggests that every two years, our computational power should double.](Images/Cost.jpg){label:fig-cost}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152cedf",
   "metadata": {},
   "source": [
    "# Data files\n",
    "\n",
    "After alignment and variant calling, genetic variation data is typically stored in formats like VCF and PLINK. While VCF is a detailed, text-based format, PLINK uses a more compact binary format that is faster and more efficient for large-scale analyses, such as GWAS. These formats are interchangeable, but we will focus on PLINK due to its common use and optimized performance for GWAS.\n",
    "\n",
    "When raw or genotype-level data is available, the genotyping parser extracts key information for each sample from the study annotation files, including:\n",
    "\n",
    "* Family ID\n",
    "* Sample ID\n",
    "* Paternal ID (for family-based studies)\n",
    "* Maternal ID (for family-based studies)\n",
    "* Sex\n",
    "* Phenotype (discrete or quantitative)\n",
    "* Group/cluster (eg, geographical region) to assess possible effects of population stratification\n",
    "\n",
    "The PLINK format consists of 3 different binary files: \n",
    "\n",
    "- `.bed`: a binary file containing genotype data.\n",
    "- `.bim`: plain text file information about each SNP in the dataset (chr, snpId, genetic position, alleles). The order of the SNPs is the same as in the bed file.\n",
    "- `.fam`: plain text file with information about the samples (family ID, individual ID, sex).\n",
    "\n",
    "Visit the [PLINK website](https://www.cog-genomics.org/plink/1.9/) for information on various file formats and helpful command lines for manipulating, processing, and analyzing genomic data.\n",
    "\n",
    "## Description of the Data\n",
    "\n",
    "To demonstrate all analysis steps with realistic genetic data, we will use a simulated dataset (N = 165) with a binary outcome measure, based on the publicly available data from the International HapMap Project [@gibbs_international_2003]. For this tutorial, we only included Utah residents with ancestry from Northern and Western Europe (CEU) to create an **ethnically homogenous** dataset. Because of the relatively small sample size of the HapMap data, genetic effect sizes in these simulations were set at values larger than usually observed in genetic studies of complex traits. It is important to note that larger sample sizes (e.g., at least in the order of thousands but likely even tens or hundreds of thousands) will be required to detect genetic risk factors of complex traits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125acfe-3b57-4d67-ba80-213c72913483",
   "metadata": {},
   "source": [
    "<img src=\"Images/bash.png\" alt=\"Bash\" width=\"40\"> Choose the Bash kernel.\n",
    "\n",
    "First, we link the data folder to easily access it by using the `ln -sf` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e877d39-1dca-43d3-b547-cfbdb9103cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln -sf ../Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba99c2",
   "metadata": {},
   "source": [
    "### Fam file - Info on individuals\n",
    "\n",
    "We begin by looking at `HapMap_3_r3_1.fam`, which you can do using the command below (`head`), which prints and selects the first 10 lines of a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a04f8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328 NA06989 0 0 2 2\n",
      "1377 NA11891 0 0 1 2\n",
      "1349 NA11843 0 0 1 1\n",
      "1330 NA12341 0 0 2 2\n",
      "1444 NA12739 NA12748 NA12749 1 -9\n",
      "1344 NA10850 0 NA12058 2 -9\n",
      "1328 NA06984 0 0 1 2\n",
      "1463 NA12877 NA12889 NA12890 1 -9\n",
      "1418 NA12275 0 0 2 1\n",
      "13291 NA06986 0 0 1 1\n"
     ]
    }
   ],
   "source": [
    "head -10 Data/HapMap_3_r3_1.fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b1c0f",
   "metadata": {},
   "source": [
    "It is just a plain text file with six columns separated by the others using the so-called *tab spacing* and no header. What information does each column contain? \n",
    "\n",
    "- 1st column (FID) is the **family identification** abbreviated as FID. The PLINK software was primarily developed for genomic analyses in humans, which is reflected in the naming terminology and default settings. As an example, in the goat Adatapt project (AdaptMap), the use of this column is to specify breed identity. Since this field is required, you can organize your data into any meaningful grouping that suits your needs, or repeat the sample ID if no other category fits better.\n",
    "- 2nd column (IID) is the \"within family ID\" or **\"individual ID\"** and is abbreviated as IID which is unique to each individual.\n",
    "- 3rd and 4th columns: the father and mother IDs are recorded in the third and fourth columns if genotyped. If parents are unknown or not available, their entries are set to 0.\n",
    "- 5th column (sex) contains the **sex information** of the individual in the IID column. According to the built-in coding, 1 is for males, 2 for females, and 0 is unknown. Similar to parent information, this is also many times missing, usually not a problem, but specific PLINK options need to be included in case any issues come up.\n",
    "- 6th column: denotes the **phenotype** of individuals in the IID column, with 1 for controls, 2 for cases, and other values or continuous measurements for other phenotypes. Missing values are represented by 0 or -9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce8f80",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "\n",
    "The exercises provide solutions below. However, you should try to solve the questions on your own. **Feel free to use online search and AI tools to ask questions and find the answers.**\n",
    "\n",
    "- **Q1. How many individuals are represented in the `fam` file?** Find a command that counts the number of lines in the file.\n",
    "- **Q2. How many unique fathers and mothers are there in the population?** Try to extract column 3 and count the unique occurrences of each ID of the fathers. Do the same with column 4 for the mothers.\n",
    "Hint: there is a white-space between columns. \n",
    "- **Q3. How many individuals do not have phenotype information?** Search for missing values in column 6.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3a996-cc11-430f-95db-c65dfed1705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7d28eab-9d1a-4fec-a053-a545fe326c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here - Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a96fd-e33f-49da-b2d8-ee5b9e6ab7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here - Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b300252-52c3-4df5-ad9b-f9c788f5fe41",
   "metadata": {},
   "source": [
    ":::{.callout-tip title=\"Solution\"}\n",
    "\n",
    "The command `wc` (which stands for Word Count) can count the words in a file. With the option `-l` it will instead count the lines of the file. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76132d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 Data/HapMap_3_r3_1.fam\n"
     ]
    }
   ],
   "source": [
    "wc -l Data/HapMap_3_r3_1.fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3cfe14-91ad-4ce2-b92d-f89cac28a63e",
   "metadata": {},
   "source": [
    "**Q1: There are 165 individuals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30104d58-8849-482c-971c-00393ae869b8",
   "metadata": {},
   "source": [
    "To see how many unique fathers there are, we need a sequence of commands. Each command has an output, which is sent to the next command using the pipe `|` symbol. We will:\n",
    "- `cut` the 3rd column of the text file setting the space as a separator for the columns,\n",
    "- `sort` the column extracted, so multiple occurrences of the same fathers are grouped together and not counted as separate groups\n",
    "- count how many times each father is shown using the command `uniq` with the option `-c` for counting\n",
    "- displays the first 5 rows of the file, allowing you to preview the data and check its format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6803ef-ca78-43eb-9ea0-cad921ec962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    115 0\n",
      "      1 NA06986\n",
      "      1 NA06993\n",
      "      1 NA06994\n",
      "      1 NA07051\n"
     ]
    }
   ],
   "source": [
    "cut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc92cdf-2fc4-4b41-8f3a-dd224d071d96",
   "metadata": {},
   "source": [
    "You can see how there are 115 unknown fathers (0s), and all the others occur only once. To count how many fathers there are, we can simply run the same commands and add `wc -l` at the end. There are 51 lines, meaning 50 known fathers if we remove the unknown ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00884ad-d2a0-40c8-af8d-dacd3026757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "cut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a9dcd-c952-499b-85bc-73cbb0d5ae51",
   "metadata": {},
   "source": [
    "You can observe a similar thing for the mothers, where we have one less which is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16816aa2-74cc-4eba-83d3-f5d1f2402715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "cut -f4 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42e6a1",
   "metadata": {},
   "source": [
    "**Q2: There are 50 unique fathers and 51 unique mothers in the dataset.**\n",
    "\n",
    "Finally, we will count the occurrences of `0` and `-9` in column 6 using the `awk` command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2a8a535-1549-4b8a-99e1-7a24c7769784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "awk '{if ($6 == 0 || $6 == -9) print $0}' Data/HapMap_3_r3_1.fam | wc -l \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e2ddf-6607-4784-8280-c8a87911d66b",
   "metadata": {},
   "source": [
    "**Q3: There are 53 individuals with missing phenotypes in the dataset.**\n",
    "\n",
    "End of solution\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c88418-02b2-4750-85fb-56d69015bda2",
   "metadata": {},
   "source": [
    "### Bim file - SNP location info\n",
    "\n",
    "The `.bim` file contains the genomic locations of all SNPs in the data, and looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945feb7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\trs2185539\t0\t556738\tT\tC\n",
      "1\trs11510103\t0\t557616\tG\tA\n",
      "1\trs11240767\t0\t718814\tT\tC\n",
      "1\trs3131972\t0\t742584\tA\tG\n",
      "1\trs3131969\t0\t744045\tA\tG\n",
      "1\trs1048488\t0\t750775\tC\tT\n",
      "1\trs12562034\t0\t758311\tA\tG\n",
      "1\trs12124819\t0\t766409\tG\tA\n",
      "1\trs4040617\t0\t769185\tG\tA\n",
      "1\trs2905036\t0\t782343\tC\tT\n"
     ]
    }
   ],
   "source": [
    "head -10 Data/HapMap_3_r3_1.bim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606605b9",
   "metadata": {},
   "source": [
    "Similar to the .fam file, the bim file has six columns.\n",
    "\n",
    "- 1st column contains the **chromosome number** where the SNP is located. You can see that the first 10 SNPs are located on Chromosome 1. \n",
    "- 2nd column is the **SNP name**. This name is predefined during the construction of the SNP chip. If you ever want to compare versions of different SNP chips for the same species, overlapping the SNP name is an excellent way to start.\n",
    "- 3rd column is the **position of the SNP** in Morgans or centimorgans (cM), with zero value if you do not know or care. For most of the analyses, this could be kept as zero. \n",
    "- 4th column is the **base pair coordinate of the SNP**. In other words, you start to count from the beginning of the chromosome, and for each SNP write down its exact location. At the beginning of each new chromosome, the counter resets and starts from one again. \n",
    "\n",
    "**In the remaining two columns 5th and 6th** are the **alleles for respective SNPs**. All SNPs on chips are biallelic, meaning each row shows only two alleles, with missing genotypes represented by zero (not shown in the .bim file). Genotypes in column five usually represent the minor allele, and column six shows the major allele (more about allele frequencies in data quality control).\n",
    "\n",
    "Similar to `.fam` files, you can extract useful information just by looking at the file. Here, each row contains information about a particular SNP.\n",
    "\n",
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "- **Q4. What is the total number of variants in the HapMap dataset?**\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ad9cb-d3bf-4deb-97d0-2a0834dd9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here - Q4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c1db9-eede-4f24-90a4-fa6b888cb0ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "Did you also get 1,457,897 SNPs for the HapMap data with the `wc -l Data/HapMap_3_r3_1.bim` command?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3e18a",
   "metadata": {},
   "source": [
    "### Bed file - Individual genotypes\n",
    "\n",
    "So far, we know that the files you downloaded contain genotypes for 165 individuals, each of them genotyped for 1,457,897 SNPs. But where are the genotypes for the individual samples?\n",
    "\n",
    "These are located in the binary file called `HapMap_3_r3_1.bed file`, but unfortunately, opening it as a normal text looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74f86693-3f60-4753-b93e-736692ba075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\u001b\u0001�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003��λ������������/����������������������\u0003��λ������������/�����������������������\u0003��λ������������/����������������������\u0003��������?�������������������������������\u0002������������������������⸿Ͼ��,��\u0002z�\u0003��ο������������/�����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003���������ﮪ���������+���������������\u0003����������������������������������������\u0003�����誮����\u000fΫ������������:���*�?����\u0003��������������﫿����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003���?�������￿�����;�����������������\u0003//���������﮿������;����ή����������\u0002���?�������ʯϿ�\u000f����;����Ϯ�����������\u0002�����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003����������ʯ￾�����;����Ϯ���<�������\u0002����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003��뿌�������\u000fϿ������:���Ϫ���<�.�?����\u0002�����������������������������������������\u0003����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002������������������������������β�����.�\u0003�����������������������������������������\u0003����������?������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0002�����������������(������/����������\n"
     ]
    }
   ],
   "source": [
    "head -1 Data/HapMap_3_r3_1.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655d9d4-f88b-4fc2-868e-a419882024b8",
   "metadata": {},
   "source": [
    "This is because the genotypes are stored in a *binary format*, which saves disk space and allows faster processing by the computer, as it's already in a **machine-readable format**. It is often useful to check out the individual genotypes, for that, you will need a new command called `xxd` to open the file which can then be pipeped into the `head` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7660e6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000: 01101100 00011011 00000001 11111111 11111111 11111111  l.....\n",
      "00000006: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "0000000c: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "00000012: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "00000018: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "0000001e: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "00000024: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "0000002a: 11111111 11111111 00000011 11111111 11111111 11111111  ......\n",
      "00000030: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n",
      "00000036: 11110011 11111111 11111111 11111111 11111111 11111111  ......\n"
     ]
    }
   ],
   "source": [
    "xxd -b Data/HapMap_3_r3_1.bed | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d408f",
   "metadata": {},
   "source": [
    "The non-binary file format for the genotype is stored in the so-called `.ped` and `.map` files. These are also some well-known formats and widely used in various programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93447262-270d-4b42-898f-1ca892d2b6bd",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Challenge yourself with the command line programs\"}\n",
    "\n",
    "We have real mice data from the [heterogeneous stock data](https://wp.cs.ucl.ac.uk/outbredmice/heterogeneous-stock-mice/) with an example phenotype. The datasets are with extensions `.bed, .bim, .fam, .pheno` and name prefix `Data/mice`. The `mice.pheno` file contains an example phenotype per individual. \n",
    "\n",
    "1. Find out how many individuals and how many SNPs there are in the mice data. Which chromosomes are considered in the data? Is it possible to check it for sex discrepancy?\n",
    "\n",
    "2. Are there any parents in the `fam` file? Hint: the `fam` file has just a backspace as a separator and is not tab-separated. This needs the specific option `-d' '` for the `cut` command.\n",
    "\n",
    "3. Is there any data for sex and phenotype in the `.fam` file? Is this data from a case-control study or a sample-based study?\n",
    "\n",
    "4. How can you find the minimum and maximum value of the phenotype (last column) using only the command line?\n",
    "\n",
    "Answer the questions by creating all the code cells you need for the code to check your answers.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605d431-a43f-4f40-9a92-eb2560db0822",
   "metadata": {},
   "source": [
    "::: {.callout-note appearance=\"minimal\"}\n",
    "# Click to view answers\n",
    "<i class=\"bi bi-journal-code\"></i> [Download mice-solutions.ipynb](exercises/gwas2-mice.ipynb)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8096dfa-9f39-4a2b-a865-e5bb1caad823",
   "metadata": {},
   "source": [
    ":::{.callout-note title=\"Wrapping up\"}\n",
    "\n",
    "We have learned about the principles of study design for GWAS and the genotyping process. Now you are also able to use some basic commands to show the content of typical GWAS file formats. \n",
    "\n",
    ":::\n",
    "\n",
    "# Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38895c-ada8-4fbf-ad9e-e4cab3943125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
