{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cd805a",
   "metadata": {
    "Rmd_chunk_options": "setup, include=FALSE",
    "jupyter": {
     "output_hidden": true,
     "source_hidden": true
    },
    "kernel": "R",
    "tags": [
     "scratch"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "set.seed(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d63c00",
   "metadata": {},
   "source": [
    "This document is licensed under a\n",
    "[Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "The slide set referred to in this document is \"GWAS 2\".\n",
    "\n",
    "\n",
    "\n",
    "A GWAS conducted by the additive regression model returns three quantities for each variant:\n",
    "\n",
    "- $\\widehat{\\beta}$, the effect size estimate for allele 1, also called *effect allele*;\n",
    "- SE of $\\widehat{\\beta}$, describing uncertainty in $\\widehat{\\beta}$;\n",
    "- P-value.\n",
    "\n",
    "We saw earlier how to interpret $\\beta$ as a difference between the means of the adjacent\n",
    "genotype groups, and how SE describes the uncertainty of the estimate $\\widehat{\\beta}$ (slide 2).\n",
    "These two parameters tie the data to the actual phenotypic change in a concrete way.\n",
    "For example, from these quantities we could infer\n",
    "that a variant increases LDL levels by 0.5 mmol/L (95%CI 0.42..0.58)\n",
    "or that another variant increases odds of MS-disease by 20% (95%CI 16%...24%).\n",
    "While these are the most concrete and detailed information about the effect of a variant\n",
    "available in GWAS output,\n",
    "still, typically, the first statistic we look at is the P-value.\n",
    "\n",
    "P-value has a central role in GWAS because\n",
    "the null hypothesis of exactly zero effects is (thought to be) a realistic\n",
    "hypothesis for a large majority of all variants tested, and a crude assessment of\n",
    "zero vs. non-zero effect can be done\n",
    "based on the P-value.\n",
    "Additionally, a genotype-phenotype association is interesting\n",
    "primarily because it points to biology behind the phenotype whereas its\n",
    "effect size may be considered secondary to the existence of an association.\n",
    "This is also true because typically individual GWAS findings\n",
    "have effect sizes that are so small\n",
    "that they alone do not have any direct clinical use.\n",
    "Therefore, the magnitude of the effect size has a smaller role in statistical\n",
    "inference in the GWAS context than in many other contexts,\n",
    "such as, e.g., in social sciences,\n",
    "where it is unrealistic to expect that any effect is\n",
    "exactly zero. In those other research fields,\n",
    "the focus should be on the size of the effect\n",
    "whereas there P-value is only a secondary quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001dbc7",
   "metadata": {},
   "source": [
    "### 2.1 What is a P-value? (slides 3-6 & 18-21)\n",
    "The purpose for using P-value is to evaluate whether the observed data seem\n",
    "inconsistent with the null hypothesis.\n",
    "Typically, the null hypothesis states that the\n",
    "variant is not important, or technically, that its effect size is 0.\n",
    "We have one null hypothesis per each variant.\n",
    "P-value is a\n",
    "probability of getting something \"at least as extreme\" as what has been observed,\n",
    "if the null hypothesis was true. Therefore, small P-value is taken as\n",
    "evidence that the null hypothesis may not be true.\n",
    "Logic goes that if P-value is very small, then it would be very unlikely\n",
    "to observe the data at hand under the null hypothesis -- and therefore either\n",
    "null hypothesis is not true or we have encountered an unlikely event.\n",
    "P-value is thus a simple numerical summary of the consistency between\n",
    "the null hypothesis and the observed data.\n",
    "But note that P-value is **NOT** a probability that the null hypothesis is true:\n",
    "P-value is probability of data given a hypothesis not a probability of the hypothesis given data\n",
    "(slides 8-9).\n",
    "\n",
    "Let's do one linear regression and put its P-value in its place in the null distribution of t-statistic.\n",
    "The goal is to study whether the effect $\\beta$ of the additive GWAS\n",
    "model $y=\\mu + x \\beta + \\varepsilon$\n",
    "is zero. The null hypothesis is $H_0: \\beta =0$. Here P-value tells that\n",
    "if the true slope $\\beta=0$, what is the probability that we\n",
    "observe a data set from which the\n",
    "computed slope is at least as large (in absolute value)\n",
    "as the observed estimate $\\widehat{\\beta}$.\n",
    "Most often we don't look at the null distribution of\n",
    "$\\widehat{\\beta}$, which depends on\n",
    "sample size and variances of $x$ and $\\varepsilon$,\n",
    "but instead we look at the null distribution\n",
    "of the t-statistics $t=\\widehat{\\beta}/\\textrm{SE}$ which has distribution\n",
    "$t(n-2)$, i.e., t-distribution with $n-2$ degrees of freedom, where $n$ is the sample size.\n",
    "When $n>50$,\n",
    "we can approximate $t(n-2)$ with the standard normal distribution\n",
    "$\\mathcal{N}(0,1)$, and this approximation is typically done in GWAS setting\n",
    "where t-statistic is often called z-score that refers to standard normal variable.\n",
    "The other way to express the same normal approximation is to say that\n",
    "the square of the t-statistic follows a chi-square distribution with\n",
    "1 degree of freedom: $t^2 \\sim \\chi_1^2$.\n",
    "By squaring $t$,\n",
    "this approach ignores the sign of the estimate, which is not a problem\n",
    "in the GWAS setting, since we do not by default have any prior knowledge\n",
    "on the direction of the effect.\n",
    "Let's draw pictures about P-values using both $t$ and $t^2$ statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd6e197",
   "metadata": {
    "Rmd_chunk_options": "fig.height=4",
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "f = 0.3 #MAF\n",
    "x = rbinom(n, 2, f) #example genotypes for n individuals\n",
    "y = rnorm(n) #outcome that is independent of x\n",
    "lm.fit = lm( y ~ x )\n",
    "par( mfrow = c(1,2) ) #draw 2 panels on the grid with 1 row and 2 cols\n",
    "#1st on t-statistic's scale\n",
    "x.grid = seq(-3, 3, 0.05) #we need this to define the plotting region\n",
    "plot(x.grid, dt(x.grid, df = n-2), lty = 2, lwd = 2, t = \"l\",\n",
    "     xlab = expression( hat(beta)/SE ), ylab = \"density\", main=\"NULL DISTR of t\") #null distr. of t-stat.\n",
    "t.stat = summary(lm.fit)$coeff[2,3] #t-statistic: Estimate/SE\n",
    "points(t.stat, 0, pch = 19, cex = 1.5, col = \"red\")\n",
    "segments(t.stat*c(1,-1), c(0,0), t.stat*c(1,-1), rep( dt( t.stat, df = n-2), 2 ), col = \"red\")\n",
    "text(2, 0.25, paste0(\"P=\",signif(summary(lm.fit)$coeff[2,4],3)), col = \"red\")\n",
    "\n",
    "#2nd on t^2 statitstic's scale\n",
    "x.grid = seq(0, 10, 0.05) #we need this to define the plotting region\n",
    "plot(x.grid, dchisq( x.grid, df = 1 ), lty = 2, lwd = 2, t = \"l\",\n",
    "     xlab = expression(( hat(beta)/SE)^2 ), ylab = \"density\", main = \"NULL DISTR of t^2\") #null distribution of t^2-stat.\n",
    "t2.stat = summary(lm.fit)$coeff[2,3]^2 #t^2-statistic: (Estimate/SE)^2\n",
    "points(t2.stat, 0, pch = 19, cex = 1.5, col = \"red\")\n",
    "segments(t2.stat, 0, t2.stat, dchisq(t2.stat, df = 1), col = \"red\")\n",
    "text(2.5, 0.25, paste0(\"P=\", signif(summary(lm.fit)$coeff[2,4],3)), col = \"red\")\n",
    "legend(\"topright\", pch = 19, col = \"red\", leg = \"observed\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2708e",
   "metadata": {},
   "source": [
    "P-value is the probability mass outside the red segments, i.e., on the left\n",
    "panel it is the sum of the\n",
    "two tail probabilities and on the right panel it is the right tail probability.\n",
    "It tells how probable, under the null,\n",
    "it is to get at least as extreme (from 0) observation as we have got here.\n",
    "Note that chi-square distribution leads to a simpler setting\n",
    "since we need to consider\n",
    "only the right tail of the distribution to compute the P-value.\n",
    "For the normal distribution we need to account also for the other\n",
    "tail that has the different sign from the observed value of the statistic\n",
    "(here the left tail).\n",
    "\n",
    "Let's make sure that we understand where the P-value came from\n",
    "and let's compute it manually\n",
    "from both the standard normal distribution and\n",
    "from the chi-square distribution using the cumulative density functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1137617",
   "metadata": {
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "z = summary(lm.fit)$coeff[2,3] #t-statistic also called z-score under Normal approximation\n",
    "pnorm(-abs(z), 0, 1, lower = T) + pnorm(abs(z), 0, 1, lower = F) #P-value from N(0,1): left + right tail\n",
    "pchisq(z^2, df = 1, lower = F) #P-value from chi-square is the upper tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b51439",
   "metadata": {},
   "source": [
    "In this example, the P-value was 0.26.\n",
    "To interpret this value through a frequentist inference framework,\n",
    "we imagine an experiment where we were repeatedly to sample new\n",
    "data at this SNP without a real genotype-phenotype association\n",
    "(i.e. the true effect size was exactly zero).\n",
    "We would observe that in about 26% of those data sets\n",
    "the effect size estimate would be\n",
    "at least as large in absolute value as what we have observed here.\n",
    "We conclude that these data do not\n",
    "make us believe strongly in a true genotype-phenotype association, because\n",
    "effect size estimates at least this large in absolute value\n",
    "are present already in about 1/4 of the null data sets.\n",
    "Hence these data\n",
    "seem completely plausible to have originated from the null.\n",
    "\n",
    "**IMPORTANT**: Make sure you understand how the above\n",
    "interpretation of P-value is different\n",
    "from a **wrong interpretation** that based on the\n",
    "P-value only we could say that the probability that this SNP is null is 26%\n",
    "(slides 8-9).\n",
    "\n",
    "If P=0.26 is not yet a convincing association, then\n",
    "how small a P-value should make us reasonably\n",
    "convinced about an interesting genotype-phenotype association?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db67bbc",
   "metadata": {},
   "source": [
    "### 2.2 Distribution of P-values\n",
    "Let's make data on 1000 null variants (i.e. zero effects) measured on 100 individuals\n",
    "and look at their P-value distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce33631",
   "metadata": {
    "Rmd_chunk_options": "fig.height=4",
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "set.seed(39)\n",
    "n = 100 #individuals\n",
    "p = 1000 #variants measured on each individual\n",
    "f = 0.4 #MAF is assumed the same for all variants; doesn't actually matter here\n",
    "X = matrix(rbinom(n*p, 2, f), nrow = n, ncol = p) #just random genotypes\n",
    "y = rnorm(n) #phenotype that is not associated with any of genotypes\n",
    "\n",
    "#apply lm to each column of X separately and collect results for genotype (row 2 of coeff)\n",
    "lm.res = apply(X, 2 , function(x) summary(lm(y ~ x))$coeff[2,])\n",
    "#result has 4 rows: beta, SE, t-stat and pval\n",
    "pval = lm.res[4,] #pick pvalues\n",
    "\n",
    "par(mfrow = c(1,2))\n",
    "plot(density(lm.res[3,]), sub = \"\", xlab = \"t-stat\", main = \"\", lwd = 2) #should be t with n-2 df\n",
    "x.seq = seq(-4,4,0.1) #x-coordinates for plotting\n",
    "lines(x.seq, dt(x.seq, df = n-2), col = \"blue\", lty = 2) #t distribution in blue\n",
    "lines(x.seq, dnorm(x.seq), col = \"red\", lty = 3) #normal distribution in red\n",
    "hist(pval, breaks = 10, xlab = \"P-value\", main = \"\", col = \"limegreen\") #should be uniformly distributed\n",
    "par(mfrow = c(1,2)) #Let's make qqplots for t-stats and for P-values\n",
    "qqnorm(lm.res[3,], cex = 0.5, pch = 3) #t with ~100 df ~ normal, hence qqnorm()\n",
    "qqline(lm.res[3,], col = \"red\")\n",
    "\n",
    "#For P-values, we want to compare to the Uniform(0,1) distribution:\n",
    "#We use ppoints(p) to get\n",
    "#p equally spaced values in (0,1) to represent quantiles of Uniform(0,1).\n",
    "#we take -log10 transformation to see the small P-values particularly well\n",
    "qqplot(-log10(ppoints(p)), -log10(pval), xlab = \"theoretical\",\n",
    "       ylab = \"obs'd\", main = \"Q-Q Plot for -log10 Pval\", cex = 0.5, pch = 3)\n",
    "abline(0, 1, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7990d0",
   "metadata": {},
   "source": [
    "What are [QQ-plots](http://data.library.virginia.edu/understanding-q-q-plots/)?\n",
    "\n",
    "Why are P-values distributed as Uniform(0,1) under the null?\n",
    "$$\\textrm{Pr}(P \\leq q_0)=\\textrm{Pr(test stat falls within the most extreme region of prob. mass }q_0\\, |\\, \\textrm{NULL}) = q_0,$$\n",
    "which shows that the cumulative distribution function (cdf) of P-value is the cdf of Uniform(0,1).\n",
    "\n",
    "**Conclusion:** We have just seen that under the null hypothesis\n",
    "the t-statistic of effect size estimate is essentially\n",
    "standard normal (shown by both the density function and QQ-plot)\n",
    "and that the P-values under the null hypothesis are\n",
    "uniformly distributed between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d55d5b",
   "metadata": {},
   "source": [
    "#### Significance threshold\n",
    "P-value quantifies incompatibility between observed data and the null\n",
    "hypothesis.\n",
    "Throughout applied statistics, it is also common to use P-value\n",
    "to label some of the observations as showing\n",
    "\"**statistically significant**\" discrepancy from the null.\n",
    "This happens by fixing a reference threshold for P-value\n",
    "**before data are observed**, and then calling the observations\n",
    "that reach the reference threshold as\n",
    "\"significant\" or \"discoveries\".\n",
    "The idea is to highlight those observations that\n",
    "seem interesting given their possible inconsistency with the null hypothesis.\n",
    "But the idea is NOT that some fixed \"significance\" threshold should be used to\n",
    "declare truth (slide 10).\n",
    "Additionally, the exact P-value is always a more valuable piece of information\n",
    "than the binary classification into \"significant\" or \"non-significant\" P-value.\n",
    "\n",
    "For such significance testing, the P-value threshold of 0.05\n",
    "has become the most common reference threshold\n",
    "(also called significance threshold or significance level).\n",
    "By definition, we expect that 1/20 of the null data sets will yield\n",
    "a P-value lower than 0.05.\n",
    "Let's see in practice\n",
    "which proportion of P-values of the random genotypes at 1000 SNPs\n",
    "we generated earlier reach each significance threshold.\n",
    "We plot an empirical cumulative distribution function (ecdf) of the P-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0a321e",
   "metadata": {
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "par(pty=\"s\")\n",
    "plot(ecdf(pval), xlab=\"sig thresh\", ylab=\"proportion Pval < thresh\",main=\"ECDF of Pvalues\")\n",
    "#e.g. how many are < 0.05\n",
    "sum( pval < 0.05 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7261367",
   "metadata": {},
   "source": [
    "So this looks like the CDF of the Uniform(0,1), as expected, and\n",
    "if we used a standard significance threshold $\\alpha=0.05$ to label\n",
    "SNPs as \"statistically significant\",\n",
    "we would label about 50 variants\n",
    "out of all 1,000 as significant\n",
    "even though these were all just results from random data generation.\n",
    "If we had analyzed $p=1,000,000$ variants, as is typical in  a GWAS,\n",
    "we would expect 50,000 of them to reach $P<0.05$ even in the case that none\n",
    "of them truly had a non-zero effect. This flood of false positives\n",
    "is the **multiple testing problem** arising from the standard\n",
    "significant testing framework.\n",
    "This is a considerable problem particularly\n",
    "when the number of true positives is small compared to the number of tests\n",
    "(as in GWAS) because, in that case, almost all \"significant\" discoveries\n",
    "will be false discoveries.\n",
    "\n",
    "As a side note,\n",
    "conceptually, \"multiple testing\" is a slightly misleading term\n",
    "in the GWAS context, since there the problem of\n",
    "a large proportion of false discoveries for liberal thresholds like 0.05\n",
    "would not occur primarily because of \"multiple tests\"\n",
    "but rather because a liberal\n",
    "threshold would not account properly for the small\n",
    "prior probability of any one variant\n",
    "to be truly associated with the phenotype.\n",
    "(We'll talk more about this later.)\n",
    "\n",
    "After we have seen how the P-values of null variants behave,\n",
    "let's make things more interesting and add some number ($m$)\n",
    "of variants that truly have an effect on the phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6240ef",
   "metadata": {
    "Rmd_chunk_options": "fig.height=4",
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "set.seed(49)\n",
    "n = 1000 #individuals\n",
    "p = 1000 #genotypes measured on each individual\n",
    "m = 50 #number of variants that have an effect: they are x_1,...,x_m.\n",
    "f = 0.4 #MAF\n",
    "b = 0.5 #effect size of variants that have an effect\n",
    "X = matrix(rbinom(n*p, 2, f), nrow = n, ncol = p) #just random genotypes at SNPs\n",
    "y = X[,1:m] %*% rep(b,m) + rnorm(n) #phenotype that is associated with x_1,...,x_m\n",
    "\n",
    "#apply lm to each column of X separately\n",
    "lm.res = apply(X, 2 , function(x) summary(lm(y ~ x))$coeff[2,])\n",
    "#has 4 rows: beta, SE, t-stat and pval\n",
    "pval = lm.res[4,]\n",
    "\n",
    "par(mfrow = c(1,2))\n",
    "plot(density(lm.res[3,]), sub = \"\", xlab = \"t-stat\", main = \"\", lwd = 2) #under null is t with n-2 df\n",
    "lines(seq(-4,4,0.1), dnorm(seq(-4,4,0.1)), col = \"red\", lty = 3) #normal distribution in red\n",
    "hist(pval, breaks = 10, xlab = \"P-value\", main = \"\", col=\"skyblue\") #under null is uniformly distributed\n",
    "par(mfrow = c(1,2)) #Let's make qqplots for t-stats and for P-values\n",
    "qqnorm(lm.res[3,], cex = 0.5, pch = 3)\n",
    "qqline(lm.res[3,], col = \"red\")\n",
    "qqplot(-log10(ppoints(p)), -log10(pval), xlab = \"theoretical\", ylab = \"obs'd\",\n",
    "       main = \"Q-Q Plot for -log10 Pval\", cex = 0.5, pch = 3)\n",
    "abline(0, 1, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e7924",
   "metadata": {},
   "source": [
    "We see a strong deviation from the null distribution, as expected,\n",
    "since there are now $m=50$ true effects among $p=1000$ SNPs.\n",
    "This is what we would like to see in our GWAS as well:\n",
    "Some clear effects and most SNPs seem to follow the null (slide 13).\n",
    "Ideally, we would like to have an inference procedure that could tell which are the\n",
    "true effects and which are the null effects.\n",
    "We will next look at\n",
    "how a multiple testing framework conceptualizes this goal.\n",
    "\n",
    "Note also the usefulness of QQ-plot as a visual comparison of two empirical distributions,\n",
    "which comes from the fact that each observation can be seen on its own. By comparing\n",
    "density plots or cumulative distribution functions between two distributions,\n",
    "the differences caused by a set of points, that are far in the tail,\n",
    "are more difficult to see than in the QQ-plot, especially when the number of exceptional\n",
    "points is small compared to the number of all points.\n",
    "\n",
    "For GWAS Manhattan plots see slides 14-15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be6ee1",
   "metadata": {},
   "source": [
    "### 2.3 Multiple testing framework\n",
    "Let's introduce some notation using traditional terminology from hypothesis testing.\n",
    "Let $H_j = \\textrm{variant } j \\textrm{ is null}$, be the null hypothesis for variant $x_j,$ $j=1,\\ldots,p$. We \"reject $H_j$\" if there is enough statistical evidence that $x_j$ is not null, otherwise we \"accept $H_j$\". Another names for \"rejecting null\" are labeling variant \"statistically significant\" or \"significant\", or calling it a \"discovery\". Typically we mean by these that the predictor is interesting enough to deserve further examination/replication attempts etc. We test $p$ variants and assume that $p_0$ of them are truly null (but of course we can't know $p_0$). Let's use the following symbols:\n",
    "\n",
    "Test result / Truth| null | not null|Total\n",
    "-|-|-|-\n",
    "significant|$FD$|$TD$|$D$\n",
    "not significant|$TN$|$FN$|$p-D$\n",
    "Total|$p_0$|$p-p_0$|$p$\n",
    "\n",
    "* $p$ is the total number of hypotheses tested.\n",
    "* $p_0$ is the number of true null hypotheses, an unknown parameter.\n",
    "* $p - p_0$ is the number of true not null (\"alternative\")\" hypotheses.\n",
    "* $FD$ is the number of false discoveries or false positives. (Type I error).\n",
    "* $TD$ is the number of true discoveries, true positives.\n",
    "* $FN$ is the number of false negatives or false non-discoveries.  (Type II error)\n",
    "* $TN$ is the number of true negatives or true non-discoveries.\n",
    "* $D = FD + TD$ is the number of discoveries, i.e., rejected null hypotheses or significant variants.\n",
    "\n",
    "Of these we only observe $p$ and $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9aadc",
   "metadata": {},
   "source": [
    "#### P-values and family-wise error rate\n",
    "As we discussed before,\n",
    "the simplest inference procedure is to fix a\n",
    "statistical significance threshold $\\alpha$\n",
    "before data are observed, and call each variant\n",
    "significant if its P-value turns out to be\n",
    "$\\leq \\alpha$.\n",
    "We just saw that under the null the distribution of P-values is uniform, i.e., $\\textrm{Pr}(P\\leq \\alpha | \\textrm{ Null}) = \\alpha$ for all $\\alpha \\in[0,1]$.\n",
    "Thus $\\alpha$ is also the **Type I error rate**, the rate at which null variants are\n",
    "labelled as significant.\n",
    "\n",
    "As we saw earlier, the common significance threshold $\\alpha=0.05$\n",
    "means that $1/20$ null variants will reach $P\\leq\\alpha$ and therefore we\n",
    "expect that $\\alpha p_0$ variants reach significance level $\\alpha$,\n",
    "when we test $p_0$ independent null variants.\n",
    "If, in a GWAS, we test $p_0 \\approx 10^6$ null variants, we expect 50,000 significant\n",
    "results at significance level $\\alpha=0.05$ already when\n",
    "there are no true positives at all.\n",
    "Since increasing number of false discoveries is a problem,\n",
    "methods that control much more stringent **family-wise error rate (FWER)** are often used.\n",
    "\n",
    "FWER is the probability of making at least one false discovery across all the\n",
    "tests carried out in the multiple testing setting:\n",
    "$$\\textrm{FWER}=\\textrm{Prob}(FD \\geq 1).$$\n",
    "If we use an inference procedure that keeps FWER very small, then we are\n",
    "confident that there are not many, if any, false discoveries being made.\n",
    "\n",
    "**Example 2.1. (See also slide 11.)**\n",
    "Suppose that 5 groups test the same missense variant\n",
    "(a mutation that changes the amino acid sequence of a protein)\n",
    "for association with MS-disease\n",
    "in five independent case-control data sets.\n",
    "Assume that\n",
    "one of the groups reports an effect at significance threshold 0.05\n",
    "and publishes the result (while other groups don't see the effect at this threshold).\n",
    "What is the FWER of such a procedure under the null hypothesis that there is no true\n",
    "association in any data set? That is,\n",
    "what is the probability for the observation\n",
    "\"at least one P-value $\\leq$ 0.05 out of 5 independent P-values\",\n",
    "under the null hypothesis that there is no real effect in any study?\n",
    "$$\\textrm{Prob}(\\textrm{at least one } P \\leq 0.05\\, |\\, \\textrm{NULL}) = 1 - \\textrm{Prob}(\\textrm{all }P > 0.05\\,|\\, \\textrm{NULL}) = 1- (1-0.05)^5=0.226.$$\n",
    "Thus, in more often than in 1 out of 5 null variants at least one of the 5 studies reports\n",
    "a P-value $\\leq$ 0.05. The correct Type I error rate of this multiple testing procedure\n",
    "is 0.226 not 0.05 that any one study group might erroneously think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d8a21a",
   "metadata": {},
   "source": [
    "#### Bonferroni correction\n",
    "The simplest way to control FWER at level $\\alpha$ is to apply significance threshold $\\alpha_B=\\alpha/p$ for each test, i.e., to report as significant the variants whose P-value $\\leq \\alpha_B$. This is called the Bonferroni correction for multiple testing. Proof that it does the job is\n",
    "$$\n",
    "\\textrm{FWER} = \\textrm{Pr}\\left( \\bigcup_{j=1}^{p_0} \\left\\{ P_j \\leq \\alpha_B \\right\\}\\,\\middle|\\, \\textrm{NULL} \\right) \\leq \\sum_{j=1}^{p_0} \\textrm{Pr}\\left(P_j \\leq \\alpha_B\\,\\middle|\\, \\textrm{NULL} \\right) = p_0 \\alpha_B = p_0 \\frac{\\alpha}{p} \\leq p \\frac{\\alpha}{p} = \\alpha.\n",
    "$$\n",
    "This procedure does not assume anything about the dependency between separate tests or the proportion of truly null hypotheses. Its advantages are thus complete generality and very simple form that is easy to apply in practice.\n",
    "\n",
    "**Genome-wide significance (GWS).** In GWAS literature,\n",
    "a significance threshold $5\\times 10^{-8}$ is commonly used\n",
    "as a reference value of a convincing association.\n",
    "It is often thought as a result of Bonferroni correction to achieve FWER of 0.05 for a GWAS,\n",
    "when the GWAS tests about one million *independent* variants.\n",
    "The term *genome-wide significant association* is used for variants that reach this threshold.\n",
    "An interpretation is that, on average, 1 in 20 GWAS that uses the\n",
    "significance threshold $5\\times 10^{-8}$\n",
    "will report (at least one) false discovery\n",
    "whereas the remaining 19 out of 20 do not report any false\n",
    "discoveries.\n",
    "\n",
    "In practice, 5e-8 has proven out to work well in the sense that there are not many\n",
    "false positives that reach this level in GWAS.\n",
    "Since the concept of GWS is typically introduced as Bonferroni corrected\n",
    "significance threshold for one million tests,\n",
    "some studies take approach to apply in their GWAS their own Bonferroni corrected\n",
    "threshold adjusted by the number of SNP they test in their own data,\n",
    "which is typically much less than one million.\n",
    "This does not seem a scientifically sound way to\n",
    "think about the GWAS analysis as the next example shows.\n",
    "\n",
    "**Example 2.2.**  Suppose that I plan to test $10^6$ genetic variants for\n",
    "association with heart disease. The machine in the lab breaks up\n",
    "and produces data only for one chromosome\n",
    "and I only have $10^2$ variants to analyze. I do\n",
    "the statistics for each of 100 variants available and for one of them,\n",
    "variant $v$, I observe a P-value of $10^{-4}$. Should I call $v$ significant?\n",
    "\n",
    "**Discussion.** Let's use FWER control because then we would seem to have\n",
    "control over how likely we are to make any false discoveries.\n",
    "If I had observed all $10^6$ variants and had done that many\n",
    "tests, then FWER would say that significance threshold should be $0.05/10^6 =\n",
    "5\\times 10^{-8}$, our typical GWS threshold.\n",
    "However, if I compute the Bonferroni corrected threshold for the observed 100\n",
    "variables, it is 10,000 times higher, $0.05/100 = 5\\times 10^{-4}$. It seems\n",
    "that whether I label this variant as a discovery depends on whether my lab\n",
    "machine happened to work for other chromosomes, which seems unsatisfactory,\n",
    "if my goal is simply to determine whether I have enough evidence\n",
    "that this particular variant $v$ is interesting.\n",
    "It does not seem conceptually sound that for the same observed data for\n",
    "variant $v$, my inference on whether I think it is interesting depends\n",
    "on how many other things have been tested \"in the same experiment\".\n",
    "Deciding a significance threshold\n",
    "based only on the number of tests done \"simultaneously\"\n",
    "is rarely conceptually satisfactory.\n",
    "It may work well in practice, but the real reason for that\n",
    "is likely elsewhere than in the correction for the number of simultaneous tests.\n",
    "(And we come to that real reason later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282bc3c",
   "metadata": {},
   "source": [
    "#### Which quantity would we ideally want to have (instead of P-value)?\n",
    "P-value is defined through\n",
    "**frequentist** properties of data generating procedure of the null hypothesis.\n",
    "Namely,\n",
    "observing a P-value of 0.023 means that under the null hypothesis the probability of\n",
    "getting at least as extreme data set (in terms of a particular test statistic)\n",
    "as the one we have observed, is 0.023.\n",
    "\n",
    "This definition seems quite clumsy. In the end, we just want to know what is\n",
    "the evidence that the null hypothesis holds for this particular variant $j$\n",
    "after we have observed GWAS data, i.e.,\n",
    "we want to know a probability $P(H_j|\\textrm{Data})$.\n",
    "P-value does not answer this question. Any conceptually sound answer requires\n",
    "more information than is used for computation of P-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147a5ae",
   "metadata": {},
   "source": [
    "#### Significance threshold and probability of the null hypothesis\n",
    "\n",
    "Let's approach the probability of the null hypothesis by revealing\n",
    "how a standard inference procedure based on a fixed significance\n",
    "threshold $\\alpha$ relates to the probability of null hypothesis. This inference\n",
    "procedure is simply to reject null hypothesis $H_j$ and call variable $j$\n",
    "significant if the corresponding P-value is $\\leq\\alpha$. Let's take as our\n",
    "observed data simply the event of a significant P-value: $S=\\{P_j \\leq \\alpha\n",
    "\\}.$ Let's also define event for a true effect as $T=\\{H_j \\textrm{ does not\n",
    "hold}\\}$ and its complement of a null effect: $N=\\{H_j \\textrm{ holds}\\}$.\n",
    "Naturally $P(T)=1-P(N)$ and we are interested in $P(T|S)$, i.e., probability that\n",
    "there is a true effect given that we observe a significant association.\n",
    "Bayes rule gives\n",
    "$$P(T|S)=\\frac{P(T)P(S|T)}{P(S)} \\textrm{ and}$$\n",
    "$$P(N|S)=\\frac{P(N)P(S|N)}{P(S)}.$$ By dividing the first equation by the second\n",
    "we have $$\\frac{P(T|S)}{P(N|S)}=\\frac{P(T)P(S|T)}{P(N)P(S|N)}.$$ This says that\n",
    "the odds of there being a true effect, after we have observed a significant P-value,\n",
    "are the prior odds of a true effect ($P(T)/P(N)$) times the ratio of probabilities\n",
    "of getting a significant result under the alternative model vs. the null model.\n",
    "By definition, $P(S|N)=\\alpha$, i.e., under the null we get significant results\n",
    "with probability $\\alpha$. The term $P(S|T)$ is called **statistical power** of\n",
    "the study to observe a true effect. Thus,\n",
    "$$\\frac{P(T|S)}{P(N|S)}=\\textrm{prior-odds} \\times\n",
    "\\frac{\\textrm{power}}{\\textrm{significance threshold}}.$$ If we assume that we\n",
    "have a well-powered study to detect effects we are interested in, say power is\n",
    "above 80\\%, we can replace power by $\\approx 1$ and ignore it for now (but we will\n",
    "focus on power next week). We see\n",
    "that whether a significant result is more likely to be a true positive than a\n",
    "false positive depends on the ratio of prior-odds of true effect and\n",
    "significance threshold. If we want our inference procedure to produce\n",
    "significant results only for almost certain cases of true positives, we need to\n",
    "choose our significance threshold small enough that it can overcome a possible\n",
    "small prior odds of a true effect in GWAS. Note, however,\n",
    "that power will also drop when we decrease the significance threshold so we\n",
    "cannot ignore it forever.\n",
    "\n",
    "**Example 2.3.** Suppose that we are looking for common genetic variants that\n",
    "increase the odds of heart disease by at least 20%\n",
    "compared to the other allele at that position of\n",
    "genome. We think that there are not many such variants around, maybe\n",
    "only 10 or so among the $10^7$ common variants.\n",
    "Thus we say that our prior\n",
    "probability that any one variant is this kind of a risk variant is\n",
    "$P(T) = 10/10^7 = 10^{-6}$.\n",
    "What should be our significance threshold if we want to be over 95\\% certain\n",
    "that an (average) significant finding is truly a real effect?\n",
    "(Here \"average\" because this consideration does not consider the exact properties\n",
    "of the variant but only average properties of those variants\n",
    "that reach significance threshold;\n",
    "next week we will dive into more precise inference for\n",
    "the particular individual variant that has been observed.)\n",
    "\n",
    "We have that\n",
    "$$\\textrm{significance threshold }\\alpha = \\textrm{power} \\times\n",
    "\\frac{\\textrm{prior-odds}}{\\textrm{posterior odds}} \\leq \\frac{\\textrm{prior-odds}}{\\textrm{posterior odds}}.$$\n",
    "We don't know power as it depends on the significance threshold $\\alpha$,\n",
    "but we can bound power from above by 1, and hence get an upper bound for $\\alpha.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646f378a",
   "metadata": {
    "kernel": "R",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p.T = 1e-6\n",
    "prior.odds = p.T/(1-p.T)\n",
    "pwr = 1 #upper bound for power --> upper bound for alpha\n",
    "post.odds = 0.95/(1-0.95)\n",
    "alpha = prior.odds*pwr/post.odds\n",
    "paste(signif(alpha,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23b5e5",
   "metadata": {},
   "source": [
    "This is the standard genome-wide significance threshold arrived from\n",
    "a different angle compared to the direct Bonferroni correction.\n",
    "On the other hand, there is an obvious connection between the two approaches,\n",
    "since above we used the number of variants in the genome\n",
    "to derive the prior probability of a true effect and this may\n",
    "coincide with the number of tests carried out in a GWAS,\n",
    "which then drives the Bonfferroni approach. However, a large\n",
    "conceptual difference is that the derivation of $\\alpha$ above is independent of\n",
    "actual number of tests carried out by any one researcher/GWAS.\n",
    "This derivation makes clear that the\n",
    "requirement of a small significance threshold, that we encounter in\n",
    "GWAS, is not primarily because of number of tests carried\n",
    "out in any one GWAS, but because of a small prior probability that\n",
    "any one of our measured variant is a non-zero effect.\n",
    "Importantly, this derivation removes the problem\n",
    "in the earlier Example: the significance threshold required should not change\n",
    "with the number of tests done, but should be determined by the properties of\n",
    "prior-odds and power of the study. In particular, the threshold does not\n",
    "change depending whether I analyse 100 or $10^6$ variants \"in the same experiment\".\n",
    "Note, however, that if there is prior knowledge that the 100 variants are\n",
    "more likely to be non-zero because of their functional\n",
    "annotations or other properties by which they have been pre-screened from\n",
    "among all $10^6$ variants, then I could loosen the significance threshold for them,\n",
    "but that is because prior-odds is now different,\n",
    "not because the number of tests is different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c913d4",
   "metadata": {},
   "source": [
    "#### What do we do with the GWS variants?\n",
    "Even if GWS threshold of 5e-8 has proven out to be so stringent\n",
    "that the number of false positives is very small, the GWS variants\n",
    "are just starting points for further work:\n",
    "\n",
    "* **Replication** should always be done in an independent cohort, and preferrably\n",
    "in several different populations, to see that the association is not due to some\n",
    "technical or methodological bias in one study, and to assess whether the association\n",
    "exists also in other populations. (slide 16)\n",
    "\n",
    "* **Biological effect** behind a new GWAS locus may be challenging to figure out\n",
    "because there are often even hundreds of correlated GWS variants in the GWAS region (slide 17),\n",
    "of which only a few may truly have a causal effect,\n",
    "and we still know only a little about the functional consequences of the DNA variation.\n",
    "This area of reserach is in rapid expansion thanks to the new technologies to\n",
    "produce data on functional genomics, which provides us with\n",
    "exciting times for the interpretation of GWAS results.\n",
    "Examples of detective work on some GWAS loci: [*C4* and schizophrenia by Sekar et al. 2016 ](https://www.nature.com/articles/nature16549) and\n",
    "[*RNF186* and ulcerative colitis by Rivas et al. 2016](https://www.nature.com/articles/ncomms12342)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb765b",
   "metadata": {},
   "source": [
    "#### Statement of statistical significance and P-values (slide 12)\n",
    "\n",
    "We have seen how P-values are used in GWAS context and how we account for multiple\n",
    "tests in defining the significance threshold.\n",
    "In recent years, with a flood of new data, the issues of multiple testing and resulting\n",
    "false positive findings have become a problem throughout many fields of science.\n",
    "This has created a [\"replicability crisis\"](https://en.wikipedia.org/wiki/Replication_crisis),\n",
    "where far too many published results do not seem to be replicable, and partly this is due to\n",
    "a misinterpretation of P-values, in particular,\n",
    "in the amount of evidence that they provide against the null hypothesis.\n",
    "In 2016, The American Statistical Association published a\n",
    "[statement about P-values](https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108)\n",
    "which is a good one to read interpreting statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd34f3a",
   "metadata": {},
   "source": [
    "### Extra: How to compute a P-value\n",
    "\n",
    "The test statistics from the same statistical model can be derived in many ways.\n",
    "For models with a likelihood function, such as regression models in GWAS,\n",
    "there are three main tests that are widely used.\n",
    "In the order of increasing computational demands, they are\n",
    "\n",
    "1. **Score test.**\n",
    "Based on the distribution of the score statistic, i.e., the derivative\n",
    "of the log-likelihood function with respect to the parameters to be tested evaluated at\n",
    "the null value of the parameters (typically 0). This is often\n",
    "simple to compute because there is no need to find the optimal parameters under the alternative model\n",
    "but only evaluate the score statistic under the null.\n",
    "Downside is that this is very inaccurate when the likelihood is not very close to the\n",
    "shape of the Normal density.\n",
    "Normal approximation is not good when we are testing low-frequency variants (MAF < 1%),\n",
    "or we have unbalanced\n",
    "case-control data (proportion of cases < 20%) or sample size is small.\n",
    "In those cases the other two tests must be used, and unfortunately this seems not\n",
    "to be well known/appreciated in the GWAS community.\n",
    "\n",
    "2. **Wald's test.**\n",
    "This is the default method to compute P-values\n",
    "in the output of R's `summary()` function. It is based on the t-statistic,\n",
    "i.e., the ratio $\\widehat{\\beta}/\\textrm{SE}$, that under the null has an approximate\n",
    "standard normal distribution. (Multivariate version also exist; we'll look at that later in the course.)\n",
    "Wald's test requires finding the maximum likelihood estimate $\\widehat{\\beta}$\n",
    "and its standard error which in turn requires computing the second derivative of the log-likelihood\n",
    "at the maximum.\n",
    "\n",
    "3. **Likelihood ratio test.**\n",
    "This is typically the most accurate way to compute P-value out of these three.\n",
    "It is based on the likelihood ratio test statistic (LRT)\n",
    "$2L(\\widehat{\\beta};\\textrm{DATA}) - 2L(\\beta_0;\\textrm{DATA})$\n",
    "where $\\beta_0$ are the fixed values of $\\beta$ under the null and $L$\n",
    "is the log-likelihood function. LRT follows approximately $\\chi^2_k$ under the null,\n",
    "where $k$ is the dimension of the tested parameter vector."
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Matti Pirinen, University of Helsinki",
   "date": "Updated 28-Oct-2020; 1st ver. 15-Jan-2019",
   "output": {
    "html_document": "default"
   },
   "title": "GWAS 2: P-values in GWAS",
   "urlcolor": "blue"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
