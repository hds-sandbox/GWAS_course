[
  {
    "objectID": "develop/general-intro.html",
    "href": "develop/general-intro.html",
    "title": "Getting Started with the GWAS Module",
    "section": "",
    "text": "In this course, we will use JupyterLab, an open-source interactive development environment (IDE) for working with Jupyter Notebooks. If you’re not familiar with this interface, check out the JupyterLab Documentation. It includes numerous screenshots and videos showcasing the cool features of JupyterLab.\nIn particular, we suggest reviewing:\n\nWorking (manage) files\nHow to edit files\nHow to use Terminals\nManing kernels and terminals\n\n\nGeneral note on how to make the notebooks work\n\nWe will primarily use R and bash command line programming languages, where R is used for statistical analysis of the output from various tools running in bash.\nSince we use multiple coding languages, you need to choose a kernel every time we shift from one language to another. A kernel contains a programming language and the necessary packages to run the course material. To choose a kernel, go to the menu at the top of the page, select Kernel --&gt; Change Kernel, and then select the preferred one.\nWe will shift between two kernels, and along the notebook, you will see a picture indicating when to change the kernel. The two pictures are shown below:\n\n\n Choose the Bash kernel  Choose the R kernel\n\n\nYou can run the code in each cell (grey background) by clicking the run cell sign in the toolbar, or simply by pressing Shift+Enter. When the code is done running, a small green check mark will appear on the left side.\nYou need to run the cells sequentially to execute the analysis. Please do not run a cell until the one above is done running, and do not skip any cells.\nTextual descriptions accompany the code to help you understand what is happening. Please try not to focus on understanding the code itself in too much detail, but rather focus on the explanations and commands’ output.\n\nYou can create new code cells by pressing + in the Menu bar above or by pressing B after selecting a cell.\n\n\n\n\n\n\n\nWarning\n\n\n\n\nIf a cell fails to run, verify the kernel in use, shown in the top-right corner.\nYou don’t know the answer to the exercises? You can use Generative AI to help with the code. It can assist you when the tutorial alone isn’t enough or if you want to explore additional concepts beyond the exercise.\n\n\n\n\n\n\n\nCopyrightCC-BY-SA 4.0 license",
    "crumbs": [
      "Tutorials",
      "Instructions"
    ]
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html",
    "href": "develop/GWAS5-AssociationTesting.html",
    "title": "Association testing",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAfter QC and generating MDS components as covariates to address population structure, the data is ready for association tests. In this tutorial, we provide scripts for association tests suitable for binary traits (e.g., alcohol-dependent patients vs. healthy controls) or quantitative traits (e.g., number of alcoholic beverages consumed per week).\n\n\n\nDiscuss different types of association tests\nIdentify the suitable association test for your data\n\n\n\n\n\nIn this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel\nIn GWAS, linear models have been typically used for continuous phenotypes (e.g. BMI, height, blood pressure) and logistic models for binary traits (e.g. disease presence). These models account for fixed effects (such as genotype) but also need to consider random effects, represented as an error term, \\(e\\), to minimize the influence of covariates, like sex of population structure.\nLinear mixed models (LMMs) are increasingly popular as an alternative to standard linear models and have proven to be effective for analyzing complex traits. They adjust for confounding factors such as population stratification, family structure, and cryptic relatedness, resulting in more reliable test statistics. However, they are usually more computationally demanding.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Association testing"
    ]
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html#learning-outcomes",
    "href": "develop/GWAS5-AssociationTesting.html#learning-outcomes",
    "title": "Association testing",
    "section": "",
    "text": "Discuss different types of association tests\nIdentify the suitable association test for your data",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Association testing"
    ]
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS5-AssociationTesting.html#how-to-make-this-notebook-work",
    "title": "Association testing",
    "section": "",
    "text": "In this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Association testing"
    ]
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html#manhattan-and-qq-plots",
    "href": "develop/GWAS5-AssociationTesting.html#manhattan-and-qq-plots",
    "title": "Association testing",
    "section": "Manhattan and QQ-plots",
    "text": "Manhattan and QQ-plots\nA common approach to identify high-association alleles is to plot the association results and look for peaks visually. One such method is the Manhattan plot, where each SNP is plotted against the negative log of its p-value from the association test (Gibson 2010). This can be done using the manhattan() function from the qqman package in R. To customize the plots (adjust colors, font sizes, etc.), check the package vignette here.\n\n# Setup to avoid long messages and plot on screen\noptions(warn=-1)\noptions(jupyter.plot_mimetypes = 'image/png')\n\n# Load GWAS package qqman\nsuppressMessages(library(\"qqman\"))\n\n# Manhattan plot using --logistic results\nresults_log &lt;- read.table(\"Results/GWAS5/logistic_results.assoc_2.logistic\", head=TRUE)\nmanhattan(results_log, main = \"Manhattan plot: logistic\", cex.axis=1.1)\n\n# Manhattan plot using --assoc\nresults_as &lt;- read.table(\"Results/GWAS5/assoc_results.assoc\", head=TRUE)\nmanhattan(results_as, main = \"Manhattan plot: assoc\", cex.axis=1.1)  \n\n# Zoom-in version in a significant region in chromosome 3\nmanhattan(subset(results_as, CHR==3), xlim = c(8.1e7, 8.5e7), chr=\"CHR\", \n          main = \"Manhattan plot: assoc, chr 3\", cex.axis=1.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThe blue line represents the threshold for significance (in the two plots, \\(10^{-5}\\)). We see no significant SNPs associated with the phenotype when we use the --logistic command (first plot). However, when we use the --assoc command (second plot), we obtain significant SNPs.\nWhy is there a difference?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall from the beginning of this chapter that the --assoc command does not correct for covariates. So even though we have promising (and hopefully publishable!) results, this form of analysis may be flawed by the underlying population stratification, which is taken into account with the --logistic model.\n\n\n\nThe second method of visually determining significance is to use a QQ-plot. This plots the expected \\(-\\log_{10}p\\) value against the observed \\(-\\log_{10}p\\) value. It’s a good way to observe not only outliers that could have significant associations but also peculiarities within our data. For example, if a plot suggests an extreme deviation between the x- and y-axes, then there might be an error with our analyses or data.\nWe will create these plots using the qq() function from the qqman package in R.\n\n# Setup to avoid long messages and plot on-screen\noptions(warn=-1)\noptions(jupyter.plot_mimetypes = 'image/png')\n\n# Install and load GWAS package qqman\nsuppressMessages(library(\"qqman\")) \n\n# QQ plot for --logistic\nresults_log &lt;- read.table(\"Results/GWAS5/logistic_results.assoc_2.logistic\", head=TRUE)\nqq(results_log$P, main = \"Q-Q plot of GWAS p-values (log) using --logistic\")\n\n# QQ plot for --assoc\nresults_as &lt;- read.table(\"Results/GWAS5/assoc_results.assoc\", head=TRUE)\nqq(results_as$P, main = \"Q-Q plot of GWAS p-values (log) using --assoc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nGiven the two Q-Q plots (based on logistic regression and basic association test), how do the observed p-values compare to the expected p-values under the null hypothesis? Write a short interpretation based on your observations\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBecause of the relatively small sample size of the HapMap data, the genetic effect sizes in these simulations were set higher than what is typically observed in genetic studies of complex traits. In reality, detecting genetic risk factors for complex traits requires much larger sample sizes—typically in the thousands, and often in the tens or even hundreds of thousands. Finally, it is important to remember that this is a simulated dataset designed to mimic real data but remains very limited in size.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIn the first plot (--logistic), the observed values are lower than the expected ones (consistent with what we saw in the Manhattan plot). This suggests an unexpected lack of significant findings. This could be due to overly conservative corrections, biases in the dataset, or poor study power (small sample size or very small effect sizes).\nOn the other hand, in the assoc QQ-plot, some SNPs show stronger associations than expected (observed p-values lower than expected), deviating from the diagonal which suggests a potential true association. Although the top-right corner typically continues deviating upward with observed values higher than expected, here it follows an unexpected pattern. However, before trusting any result, we must conduct further analyses, particularly to assess population stratification. Even if we have confidence in our association test and sufficient power to detect associated variants, careful evaluation is necessary to rule out confounding factors.\n\nMoreover, it is important to remember that, while this suggests an association between these SNPs and the studied phenotype, there isn’t sufficient information here to determine the causal variant. In fact, there could potentially be multiple causal variants and the causal variants could be in LD with some of the significant variants. Identifying the causal variants would require further investigation using biological methods. However, this analysis has significantly reduced the number of SNPs that need to be studied.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Association testing"
    ]
  },
  {
    "objectID": "develop/cards/SamueleSoraggi.html",
    "href": "develop/cards/SamueleSoraggi.html",
    "title": "Samuele Soraggi",
    "section": "",
    "text": "Samuele is a Sandbox data scientist based at the university of Aarhus. During his academic activity he has gained experience in population genomics, transcriptomics, single cell multiomics and spans his knowledge across various themes of advanced computational statistics.\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html",
    "href": "develop/GWAS1-WhatIsAGWAS.html",
    "title": "What is a GWAS?",
    "section": "",
    "text": "Information about this notebook\n\n\n\nOver the past two decades, there has been an increasing interest in investigating the influence of genetic risk factors on various human traits. The technical and analytic tools required to conduct genetic studies have become increasingly accessible, which holds great promise. However, performing genetic association studies properly is complex and requires specific knowledge of genetics, statistics, and (bio)informatics.\nThis course will introduce key concepts and provide guidelines for building a reusable workflow for Genome-Wide association studies (GWAS) by progressively describing all necessary steps in a typical GWAS analysis. This notebook is read-only, while the others are hands-on practical exercises using R and the Linux command line.\n\n\n\nRecognize and discuss the basic terminology and GWAS principles\nIdentify the main steps of a typical GWAS analysis\nA Genome-Wide Association Study (GWAS) aims to link genotype and phenotype information by identifying genetic variants that have a statistical association with a trait. A phenotype, also called trait, can be any measured or observed property of an individual. Phenotypes can include quantitative traits, like standing height or body mass index (BMI), as well as binary traits, such as diagnoses of multiple sclerosis or schizophrenia.\nGWAS are used to explore the genetic architecture of complex traits and address questions about the distribution of variants contributing to the resulting phenotype, and their associated effect size on the trait. To understand GWAS, it is important to familiarise yourself with the key components and terminology involved in these studies:",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "What is a GWAS?"
    ]
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#learning-outcomes",
    "href": "develop/GWAS1-WhatIsAGWAS.html#learning-outcomes",
    "title": "What is a GWAS?",
    "section": "",
    "text": "Recognize and discuss the basic terminology and GWAS principles\nIdentify the main steps of a typical GWAS analysis",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "What is a GWAS?"
    ]
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#gwas-examples",
    "href": "develop/GWAS1-WhatIsAGWAS.html#gwas-examples",
    "title": "What is a GWAS?",
    "section": "GWAS examples",
    "text": "GWAS examples\nNow, let’s look at some recent examples of GWAS. There are two primary types, a) studies focusing on quantitative traits and b) those investigating disease phenotypes.\n\nExample 1 QT-GWAS\nGWAS on body-mass index (BMI) (Locke et al. 2015) combined data from 339,000 individuals from 125 studies around the world to explore the relationship between genetic variants and BMI. This study identified 97 genomic regions strongly associated with BMI. Pathway analyses provided evidence supporting the involvement of the central nervous system in obesity susceptibility. Some of the newly identified candidates are genes involved in pathways related to synaptic function, glutamate signaling, insulin secretion/action, energy metabolism, lipid biology, and adipogenesis.\n\n\n\nFigure 1: Manhattan plot displaying the \\(–log_{10}\\) P-value of each SNP tested in a GWAS, such as the BMI study by Locke et al. (2015). Although Manhattan plots will be explained later in the course, the key idea is that by setting a genome-wide significance threshold at p=5e-8, equivalent to \\(–log_{10}(p)\\) = 7.3, we can identify variants significantly associated with the phenotype under study. In this plot, previously identified loci are shown in blue, new discoveries are in red, and each locus is labeled with a nearby gene (though the labeled gene may not necessarily be the causal one).\n\n\n\n\nExample 2 Disease GWAS\nGWAS on migraine (Gormley et al. 2016) combined genetic data on 60,000 cases (individuals with migraine) and 315,000 controls (individuals with no known migraine) originating from 22 studies. Genetic data was available on millions of genetic variants. At each variant, the genotype distribution between cases and controls was compared. This study identified 38 regions of the genome that showed a significant statistical association with migraine. Downstream analyses integrated these genes into pathways and cell types, revealing an enrichment of signals near genes that are active in the vascular system.\n\n\n\nFigure 2: Manhattan plot from GWAS study on migraines by Gormley et al. (2016).\n\n\nA third type of GWAS, known as Trait GWAS, focuses on investigating variants linked to specific traits or characteristics that are not quantitative but may not necessarily be a disease (e.g., eye color, hair texture, response to medicaments, etc. ).",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "What is a GWAS?"
    ]
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#overview-of-gwas-steps",
    "href": "develop/GWAS1-WhatIsAGWAS.html#overview-of-gwas-steps",
    "title": "What is a GWAS?",
    "section": "Overview of GWAS Steps",
    "text": "Overview of GWAS Steps\nThe aim of genome‐wide association studies (GWAS) is to identify single nucleotide polymorphisms (SNPs)-of which the allele frequencies vary systematically-as a function of phenotypic trait values (e.g., between cases with schizophrenia and healthy controls, or between individuals with high vs. low scores on neuroticism). The identification of trait‐associated SNPs can provide new insights into the biological mechanisms underlying these phenotypes. Advances in technology have made it possible to study the effects of numerous SNPs spread across the genome. Before diving into the procedure, let’s review some essential concepts. The typical steps involved in a GWAS are illustrated in the figure below:\n\n\n\nFigure 3: Overview of GWAS Steps (Uffelmann et al. 2021)\n\n\n\na) Data Collection: Data can be collected from study cohorts, but there is also valuable genetic and phenotypic information that can be used from biobanks or repositories. Depending on the study’s focus, various data collection methods will be used, including questionnaires, clinical assessments, biological samples, or anthropometric measurements. Comprehensive data will allow researchers to investigate the relationships between genetic factors, environmental exposures, and health outcomes. Confounders need to be carefully considered and recruitment strategies must not introduce biases such as collider bias.\nb) Genotyping: Genotypic data can be collected using microarrays to capture common variants, or next-generation sequencing methods for whole-genome sequencing (WGS) or whole-exome sequencing (WES). The data is saved in specific file formats that can be used for downstream analyses.\nc) Quality control: Quality control includes steps both at the wet-laboratory stage, such as genotype calling and DNA switches, and dry-laboratory steps on called genotypes, involving filtering both at the sample and variant level. For instance, poor single-nucleotide polymorphisms (SNPs) and samples will be filtered out. It is also important to detect population strata in the cohort using principal components analyses (PCA). Panel c) of the figure, captures the overall genetic diversity and relatedness within the study cohort by clustering individuals who are more genetically similar.\nd) Imputation: Genotypic data can be phased, and missing (“untyped”) genotypes are often imputed using data from reference populations like the 1000 Genomes Project or TopMed. It is crucial that the reference panel closely matches the ancestry of the individuals being imputed for optimal accuracy, while also being diverse enough to represent the entire population. In panel d) of the figure above, genotypes of SNP1 and SNP3 are imputed based on the directly assayed genotypes of other SNPs. Examples of widely used imputation software include SHAPEIT, BEAGLE, and IMPUTE2.\ne) Association testing: Genetic association tests are conducted for each genetic variant, using an appropriate model (for example, additive, non-additive, linear, or logistic regression). Regardless, of the approach used, it is important to correct for confounders (including population stratification) and control for multiple testing. Outputs are scrutinized for unusual patterns, and summary statistics are generated.\nf) Meta-analysis: A very large number of individuals is required to achieve powerful GWAS. Commonly, to increase sample size, GWAS are typically conducted within consortia such as the Psychiatric Genomics Consortium, the Genetic Investigation of Anthropometric Traits (GIANT) consortium, or the Global Lipids Genetics Consortium. This can be especially relevant in under-studied populations. These consortia analyze data from multiple cohorts using tools such as METAL or GWAMA.\ng) Replication: Results can be validated using internal replication or external replication in an independent cohort. External replication requires the cohort to be ancestrally matched and not share individuals or family members with the discovery cohort.\nh) Post-GWAS analyses: In silico analyses involve fine mapping, SNP-to-gene mapping, gene-to-function mapping, pathway analysis, genetic correlation analysis, mendelian randomization, and polygenic risk prediction. Functional hypotheses can be further tested using experimental techniques such as CRISPR or massively parallel reporter assays, and results can be validated in human trait/disease models (not shown in the figure).",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "What is a GWAS?"
    ]
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#software-overview-for-each-gwas-steps",
    "href": "develop/GWAS1-WhatIsAGWAS.html#software-overview-for-each-gwas-steps",
    "title": "What is a GWAS?",
    "section": "Software overview for each GWAS Steps",
    "text": "Software overview for each GWAS Steps\nNumerous software tools are available for conducting GWAS. This table by Uffelmann et al. (2021) provides an overview of state-of-the-art tools, categorized by each step in the analysis process.\n\n\n\n\n\n\nWrapping up\n\n\n\nThis course will cover data collection and genotyping, quality control (which will look at factors such as relatedness, population structure, and summary statistics), and association testing.\nModern GWAS involves analyzing tens of thousands of individuals and millions of genetic variants, requiring specialized software capable of handling specific file formats. Among the most commonly used tools for this purpose is PLINK, which we will use in the upcoming notebooks. Additionally, we will explore advanced tools designed for beyond-standard GWAS analysis.\n\n\n\n\n\n\n\n\nPowerful and robust tools\n\n\n\nThere are more advanced tools such as LDAK, BOLT-LMM and Regenie.\n\nLDAK contains non-standard models for GWAS and PRS analysis which are periodically updated.\nBOLT-LMM is highly efficient for large datasets and more powerful at controlling for false positives due to the mixed model approach.\nRegenie is written in C++ and fast at whole genome regression models on very large genome-wide association studies. These tools are computationally more intensive but necessary when the size of a study scales up considerably.",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "What is a GWAS?"
    ]
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html",
    "href": "develop/GWAS0-geneticTheory.html",
    "title": "Genetic Theory Review",
    "section": "",
    "text": "Information about this notebook\n\n\n\n\n\nThis section reviews basic genetic theory terminology to help you better understand GWAS principles. Feel free to skip it if you’re already familiar with the concepts.\n\n\n\nReview the basic terminology of genetic theory (DNA and genetic variation)\nDiscuss sources of human genetic variation databases",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Genetic Theory Review"
    ]
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html#learning-outcomes",
    "href": "develop/GWAS0-geneticTheory.html#learning-outcomes",
    "title": "Genetic Theory Review",
    "section": "",
    "text": "Review the basic terminology of genetic theory (DNA and genetic variation)\nDiscuss sources of human genetic variation databases",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Genetic Theory Review"
    ]
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html#quick-review-of-genetic-theory",
    "href": "develop/GWAS0-geneticTheory.html#quick-review-of-genetic-theory",
    "title": "Genetic Theory Review",
    "section": "Quick Review of Genetic Theory",
    "text": "Quick Review of Genetic Theory\nWe all carry two nuclear genomes (i.e. genomes located in the cell nucleus), one inherited from each of our two parents. Additionally, we have a small mitochondrial genome, assumed to be inherited exclusively from the mother, but in this course, the term ‘genome’ refers to the nuclear genome.\nThe human genome is a 3.2 billion nucleotide (or base pair or DNA letter A, C, G, T) long sequence (see yourgenome.org), that is divided into separate physical pieces called chromosomes (see yourgenome.org). There are 22 autosomal (non-sex related) chromosomes and two sex chromosomes (X and Y chromosomes). Commonly, humans have two copies of each autosome. Individuals with one copy of X and one of Y are males, whereas those with two copies of X are females. An abnormal number of chromosomes, known as aneuploidy, typically leads to severe consequences or early death when present in all cells of an individual. However, a notable non-lethal exception is Down syndrome, characterized by the presence of three copies of chromosome 21. Another condition, mosaicism, occurs when only some cells in the body have abnormal chromosome numbers, a phenomenon often observed in cancer cells.\nWhen we analyze genomes, we encounter three types of pairings:\n\nDNA is typically a double-stranded molecule, where two strands (i.e. the two DNA molecules) are glued together by the chemical base pairings: A-T and C-G. This base pairing is crucial for DNA replication, which is necessary before any cell division see yourgenome.org. The two DNA molecules connected through base pairing contain identical information though their sequences are complementary: A pairs with T and C pairs with G. To distinguish between the two DNA molecules, it is conventionally agreed that one is the forward strand (or positive strand) and the other is the reverse strand (or negative strand). Therefore, if the forward strand contains base A, the corresponding base on the reverse strand is T, and vice versa.\nThe two homologous chromosomes of an individual (for example, paternal chromosome 13 with maternal chromosome 13, or in males, maternal X and paternal Y) are considered a pair. Therefore, the human genome consists of 22 autosomes plus X and Y chromosomes. Each individual possesses two copies of each homologous chromosome, resulting in a total of 46 unique chromosomes organized into 23 pairs of homologous chromosomes.\nBefore any cell division each of the 46 unique chromosomes of an individual undergoes replication (“copies itself”). The two resulting copies (known as sister chromatids) physically pair with each other to form an X-like shape often used in chromosome pictures. This pairing of sister chromatids after replication is crucial for ensuring that each resulting cell receives the correct set of chromosomes during cell division. In mitosis (ordinary cell division), each of the two new cells receives a complete set of 46 unique chromosomes. However, in meiosis, which forms gametes (sperm and eggs), each gamete ends up with only one copy of each homologous chromosome, resulting in 23 unique chromosomes per gamete. During meiosis, the process of recombination shuffles the homologous copies of paternal and maternal chromosomes. This shuffling ensures that each offspring’s chromosomes are a mixture of segments from its grandparents’ chromosomes.\n\n\nOther important terms\n\nGenes: are segments of DNA that encode for proteins (see yourgenome.org). Variations in the physical structure of proteins or the timing and location of protein synthesis can lead to observable traits. Therefore, understanding how genetic variation impacts gene function and the phenotypic consequences is crucial, although much of this remains to be explored. Protein-coding genes constitute less than 2% of the entire human genome, while the remaining 98% plays a critical role in regulating gene activity through various mechanisms.\nLocus (pl. loci): refers to a continuous region of the genome, which can vary greatly in size from a single nucleotide site (1 base pair) to a region spanning millions of base pairs (e.g., 10 Mbp).\nGWAS loci: are regions of the genome that exhibit a significant statistical association with a particular phenotype of interest.\n\n\n\nGenetic variants\nAt any given position in the genome (e.g., nucleotide site at position 13,475,383 of chromosome 1, denoted as chr1:13,475,383), variations can exist between individuals in the population. For instance, my paternal chromosome might have a base A, while my maternal chromosome has a base G (on the + strand of DNA) at that position. Such a single-nucleotide difference, at that specific position in the genome, is known as a single-nucleotide variant (SNV), and these two versions are called alleles. In this example, I would carry both allele A and allele G at that SNV, while you might have two copies of allele A at the same SNV. My genotype would be AG, and yours would be AA.\nAn individual who has different alleles on their two genomes is heterozygous at that locus, whereas someone with two copies of the same allele is homozygous at that locus. If neither allele is very rare in the population—specifically if the minor allele frequency (MAF) is &gt; 1%—the variant is referred to as a single-nucleotide polymorphism (SNP). SNPs are used as markers in evolutionary biology and constitute the most common form of variation that may have consequences at the phenotypic level and be associated with certain diseases. There are over 10 million SNPs identified in the human genome.\nMore complex genetic variations include structural variation (SV) such as copy number variants (CNVs), which include duplications or deletions of genomic regions, as well as rearrangements of the genome, like inversions or translocations of DNA segments (see yourgenome.org).\n\n\n\nFigure 1: SNPs are DNA differences at a specific location (image source)\n\n\nA defined set of 500,000 to 1,000,000 SNPs can be measured reliably and affordably (less than 50 euros per sample) using DNA microarrays, which has been pivotal in enabling GWAS. In this course, we primarily focus on SNPs as the standard type of genetic variation. Typically, SNPs are biallelic, meaning there are only two alleles present in the population, which is the assumption we follow. In principle, however, all four possible alleles of a SNP could be present in the population.\n\nAmbiguous SNPs\nIf the two alleles of an SNP are either (C,G) or (A,T) we call the SNP ambiguous because the strand information must be available (and accurate) to correctly interpret the genotypes at such SNP. For instance, allele C on the positive strand would be equivalent to allele G on the negative strand. If different studies report the SNP with respect to different strands, it can lead to mixed-up results. This issue does not occur with SNPs whose alleles are A, and C, because alleles T and G would correspond on the opposite strand, allowing unambiguous matching of A to T and C to G across studies. Ambiguous SNPs can generally be resolved reliably based on allele frequencies, as long as the minor allele frequency is not close to 50%. When combining multiple studies, it is crucial to begin by plotting allele frequencies between studies. This helps ensure that the alleles are consistently matched across studies before comparing frequencies to verify consistency.\n\n\n\nSome catalogs of genetic variation\nThe human genome map is constantly improving, leading to updates in SNV/SNP coordinates and new discoveries with each new build. The current build is GRCh38 (hg38), published in 2013, while its predecessor, GRCh37 (hg19), is still in use for some data sets. Always specify the genome build when sharing genomic coordinates, as positions can differ between builds. There are tools like LiftOver that can help map coordinates between builds.\nA large part of the genetics research over the last 30 years has been driven by international projects aiming to catalog genetic variation in the public domain.\n\n\n\nDatabase\nYear\nDescription\n\n\n\n\nThe Human Genome Project\n1990-2003\nEstablished a first draft of a human genome sequence. Collins and Fink (1995).\n\n\nThe HapMap project\n2002-2009\nStudied the correlation structure of the common SNPs. Gibbs et al. (2003).\n\n\nThe 1000 Genomes project\n2008-2015\nExpanded HapMap to genome sequence information across the globe and currently remains a widely-used reference for global allele frequency information. 1000G project was able to characterize well common variation in different populations, but missed many rare variants of single individuals because the costs of very accurate sequencing were too high. The tremendous impact of the 1000G project stems from the fact that everyone can download the individual-level genome data of the 1000G samples from the project’s website and use it in their research. Auton et al. (2015).\n\n\nExome Aggregation Consortium (ExAC)\n2014-2016\nConcentrated only on the protein-coding parts of the genome, so-called exons, that make up less than 2% of the genome and was able to provide accurate sequence data for the exomes of over 60,000 individuals. This effort has been particularly important for the medical interpretation of rare variants seen in clinics that diagnose patients with severe disease. ExAC provides summary-level information through browsers and downloads but individual-level data cannot be downloaded. Lek et al. (2016).\n\n\nGenome Aggregation Database (gnomAD)\n2016-2020\nIs expanding the ExAC database and also includes additional whole genome sequencing information. It is the current state-of-the-art among the public genome variation databases. Chen et al. (2024).",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Genetic Theory Review"
    ]
  },
  {
    "objectID": "develop/exercises/gwas7-prs.html",
    "href": "develop/exercises/gwas7-prs.html",
    "title": "PRSice exercise",
    "section": "",
    "text": "Explore the base GWAS and compute polygenic scores for height in Europeans using PRSice2.\n Bash kernel.\n\nln -sf ../../Data\nln -sf ../Results\n\n R kernel.\n\n# Setup to avoid long messages and plot on screen\noptions(warn=-1)\noptions(jupyter.plot_mimetypes = 'image/png')\n\n# Load GWAS package qqman\nsuppressMessages(library(\"qqman\"))\n\n# Manhattan plot using --logistic results\nheight_eur &lt;- read.table(\"./Data/Height.QC.gz\", head=TRUE)\nmanhattan(height_eur, main = \"Manhattan plot height GWAS\", cex.axis=1.1)\n\n## QQ plot \nqq(height_eur$P, main = \"Q-Q plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes the plot surprise you? You can notice extreme deviations in the QQ-plot and an overwhelming number of significant variants. To refine your analysis and avoid false positives, you should perform MAF and INFO filtering to exclude rare variants and poorly imputed or uncertain variants that could lead to false associations.\n Bash kernel.\nYou need to perform the PRS analysis on the simulated dataset in the following way:\n\nPRSice --base ./Data/Height.QC.gz \\\n    --target ./Data/EUR.QC \\\n    --binary-target F \\\n    --pheno ./Data/EUR.height \\\n    --cov ./Data/EUR.covariate \\\n    --base-maf MAF:0.01 \\\n    --base-info INFO:0.8 \\\n    --stat BETA \\\n    --out Results/GWAS7/EUR.PRSice\n\nPRSice 2.3.5 (2021-09-20) \nhttps://github.com/choishingwan/PRSice\n(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\nGNU General Public License v3\nIf you use PRSice in any published work, please cite:\nChoi SW, O'Reilly PF.\nPRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\nGigaScience 8, no. 7 (July 1, 2019)\n2025-03-20 14:10:43\nPRSice \\\n    --a1 A1 \\\n    --a2 A2 \\\n    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n    --base ./Data/Height.QC.gz \\\n    --base-info INFO:0.8 \\\n    --base-maf MAF:0.01 \\\n    --beta  \\\n    --binary-target F \\\n    --bp BP \\\n    --chr CHR \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --cov ./Data/EUR.covariate \\\n    --interval 5e-05 \\\n    --lower 5e-08 \\\n    --num-auto 22 \\\n    --out Results/GWAS7/EUR.PRSice \\\n    --pheno ./Data/EUR.height \\\n    --pvalue P \\\n    --seed 3599109867 \\\n    --snp SNP \\\n    --stat BETA \\\n    --target ./Data/EUR.QC \\\n    --thread 1 \\\n    --upper 0.5\n\nInitializing Genotype file: ./Data/EUR.QC (bed) \n\nStart processing Height.QC \n================================================== \n\nBase file: ./Data/Height.QC.gz \nGZ file detected. Header of file is: \nCHR BP  SNP A1  A2  N   SE  P   BETA    INFO    MAF \n\nReading 100.00%\n499617 variant(s) observed in base file, with: \n499617 total variant(s) included from base file \n\nLoading Genotype info from target \n================================================== \n\n483 people (232 male(s), 251 female(s)) observed \n483 founder(s) included \n\n489805 variant(s) included \n\nPhenotype file: ./Data/EUR.height \nColumn Name of Sample ID: FID+IID \nNote: If the phenotype file does not contain a header, the \ncolumn name will be displayed as the Sample ID which is \nexpected. \n\nThere are a total of 1 phenotype to process \n\nStart performing clumping \n\nClumping Progress: 100.00%\nNumber of variant(s) after clumping : 193758 \n\nProcessing the 1 th phenotype \n\nHeight is a continuous phenotype \n11 sample(s) without phenotype \n472 sample(s) with valid phenotype \n\nProcessing the covariate file: ./Data/EUR.covariate \n============================== \n\nInclude Covariates: \nName    Missing Number of levels \nSex 0   - \nPC1 0   - \nPC2 0   - \nPC3 0   - \nPC4 0   - \nPC5 0   - \nPC6 0   - \n\nAfter reading the covariate file, 472 sample(s) included in \nthe analysis \n\n\nStart Processing\nProcessing 77.31%\n\n\nBy looking at the output file .summary, we can conclude that:\n\nBest-fit P-value is ~0.4\nPhenotypic variation explained by the best-fitting model is ~0.16\n\n\ncat Results/GWAS7/EUR.PRSice.summary\n\nPhenotype   Set Threshold   PRS.R2  Full.R2 Null.R2 Prevalence  Coefficient Standard.Error  P   Num_SNP\n-   Base    0.13995 0.214442    0.391467    0.225349    -   36115   3212.41 3.81121e-26 85982\n\n\n R kernel.\nBelow is an example of how you could create a plot in R to visualize height PGS differences across sex:\n\nlibrary(ggplot2)\n\n# Read in the files\nprs &lt;- read.table(\"./Results/GWAS7/EUR.PRSice.best\", header=T)\nheight &lt;- read.table(\"./Data/EUR.height\", header=T)\nsex &lt;- read.table(\"./Data/EUR.cov\", header=T)\n\n# Rename the sex\nsex$Sex &lt;- as.factor(sex$Sex)\nlevels(sex$Sex) &lt;- c(\"Male\", \"Female\")\n\n# Merge the files\ndat &lt;- merge(merge(prs, height), sex)\n\n# Start plotting\nggplot(dat, aes(x=PRS, y=Height, color=Sex))+\n    geom_point()+\n    theme_bw()+\n    labs(x=\"Polygenic Score\", y=\"Height\") +\n    theme(axis.text=element_text(size=12), axis.title=element_text(size=12), legend.text=element_text(size=12),legend.title=element_text(size=14))\n\nWarning message:\n“package ‘ggplot2’ was built under R version 4.2.3”\n\n\n\n\n\n\n\n\n\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "develop/exercises/gwas2-mice.html",
    "href": "develop/exercises/gwas2-mice.html",
    "title": "Mice data exercise",
    "section": "",
    "text": "1. Find out how many individuals and how many SNPs there are in the mice data. Which chromosomes are considered in the data? Is it possible to check it for sex discrepancy?\nThere are 1940 individuals and 2984 SNPs. There is only data from chromosomes 1-4. You cannot look for chromosome X inbreeding\n2. Are there any parents in the fam file? Hint: the fam file has just a backspace as a separator and is not tab-separated. This needs the specific option -d' ' for the cut command.\nNo parents’ information.\n4. Is there any data for sex and phenotype in the .fam file? Is this data from a case-control study or a sample-based study?\nNo information in the fam file.\n6. How can you find the minimum and maximum value of the phenotype (last column) using only the command line?\nThe minimum value is -4.13 and the maximum is 3.60.\n Bash kernel.\nCommands for the solutions:\n\nln -sf ../../Data\n\n\n# Number of individuals \nwc -l Data/mice.fam\n\n1940 Data/mice.fam\n\n\n\n# Number of variants\nwc -l Data/mice.bim\n\n2984 Data/mice.bim\n\n\n\n# Chromosomes info\ncut -f1 Data/mice.bim | sort | uniq -c \n\n    870 1\n    757 2\n    684 3\n    673 4\n\n\n\n# Mother and father info \ncut -f3 -d\" \" Data/mice.fam | sort | uniq -c \ncut -f4 -d\" \" Data/mice.fam | sort | uniq -c \n\n   1940 0\n   1940 0\n\n\n\n# View .fam file \nhead -n 5 Data/mice.fam \n\nA048005080 A048005080 0 0 0 0.000000\nA048006063 A048006063 0 0 0 0.000000\nA048006555 A048006555 0 0 0 0.000000\nA048007096 A048007096 0 0 0 0.000000\nA048010273 A048010273 0 0 0 0.000000\n\n\n\n# sex \ncut -f6 -d\" \" Data/mice.fam | sort | uniq -c \n\n   1940 0.000000\n\n\n\n# phenotype \ncut -f6 -d\" \" Data/mice.fam | sort | uniq -c \n\n   1940 0.000000\n\n\n\n# phenotype lowest value\ncut -f3 -d\" \" Data/mice.pheno | sort -n | head -n1\n\n-4.124257\n\n\n\n# phenotype highest value\ncut -f3 -d\" \" Data/mice.pheno | sort -n | tail -n1\n\n3.594109\n\n\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html",
    "href": "develop/GWAS4_extra_population_structure.html",
    "title": "Population structure",
    "section": "",
    "text": "With the advent of SNP data it is possible to precisely infer the genetic distance across individuals or populations. As written in the book, one way of doing it is by comparing each SNP from each individual against every other individual. This comparison produces the so called: covariance matrix, which in genetic terms means the number of shared polymorphisms across individuals. There are many ways to visualize this data, in this tutorial you will be exposed to Principal Component Analysis and Admixture software.\nWe will use the R package SNPRelate, which can easily handle vcf files and do the PCA. If you want to explore a bit more on the functionality of the package access here."
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS4_extra_population_structure.html#how-to-make-this-notebook-work",
    "title": "Population structure",
    "section": "How to make this notebook work",
    "text": "How to make this notebook work\n\nIn this notebook we will use both the command line bash commands and R to setup the file folders.\nHaving to shift between two languages, you need to choose a kernel every time we shift from one language to another. A kernel contains a programming language and the necessary packages to run the course material. To choose a kernel, go on the menu on the top of the page and select Kernel --&gt; Change Kernel, and then select the preferred one. We will shift between two kernels, and along the code in this notebook you will see a picture telling you to change kernel. The two pictures are below:\n\n Shift to the Bash kernel\n Shift to the R kernel"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#learning-outcomes",
    "href": "develop/GWAS4_extra_population_structure.html#learning-outcomes",
    "title": "Population structure",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nAt the end of this tutorial you will be able to\n\nExtract information from a vcf file and create a PCA projection\nLook at the effect of LD pruning to reveal population structure"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#setting-up-folders",
    "href": "develop/GWAS4_extra_population_structure.html#setting-up-folders",
    "title": "Population structure",
    "section": "Setting up folders",
    "text": "Setting up folders\nHere we setup a link to the Data folder and create the Results folder.\n Choose the Bash kernel\n\nln -sf ../Data\n\n\nunzip Data/hapmap.zip -d  Data"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#import-data-and-calculate-pca",
    "href": "develop/GWAS4_extra_population_structure.html#import-data-and-calculate-pca",
    "title": "Population structure",
    "section": "Import data and calculate PCA",
    "text": "Import data and calculate PCA\nWe read the metadata about the samples (geographic locations) and transform the vcf file into gds format, from which the package SNPRelate can calculate the PCA projection of the data.\n\n# Reading the metadata information \ninfo = read.csv(\"Data/sample_infos_accessionnb.csv\", header = T, sep = ';')\n\n# Setting the directory of the VCF file \nvcf.fn &lt;- \"Data/Allvariants_135_145_chr2.vcf\"\n\n# Transforming the vcf file to gds format\nsnpgdsVCF2GDS(vcf.fn, \"Data/Allvariants_135_145_chr2_2.gds\", method=\"biallelic.only\")\n\n#Read the file and calculate the PCA\ngenofile &lt;- snpgdsOpen(\"Data/Allvariants_135_145_chr2_2.gds\",  FALSE, TRUE, TRUE)\npca &lt;- snpgdsPCA(genofile)\nsummary(pca)\n\nQ.1 How many individuals and snps does this dataset have? What is an eigenvector and an eigenvalue?\nThe pca object just created is a list containing various elements.\n\nls(pca)\n\nWe use pca$eigenvect to plot the PCA. We extract also pca$sample.id to match the geographic locations in the metadata with the samples in pca.\n\neigenvectors = as.data.frame(pca$eigenvect[,1:5])\ncolnames(eigenvectors) = as.vector(sprintf(\"PC%s\", seq(1:ncol(eigenvectors))))\npca$sample.id = sub(\"_chr2_piece_dedup\", \"\", pca$sample.id)\n\n# Matching the sample names with their origin and population\nrownames(info) &lt;- info[,\"ENA.RUN\"]\neigenvectors &lt;- cbind(eigenvectors, info[pca$sample.id, c(\"population\",\"region\")])\n\nIn the end, we have created a table called eigenvectors containing the PCA coordinates and some metadata\n\nhead(eigenvectors)\n\nLet’s first look at how much of the variance of the data is explained by each eigenvector:\n\n# Variance proportion:\npca$pca_percent &lt;- pca$varprop*100\nggplot( NULL, aes(x=seq(1, length(pca$eigenval)), y=pca$pca_percent, label=sprintf(\"%0.2f\", round(pca$pca_percent, digits = 2))) ) +\n        geom_line() + geom_point() + \n        geom_text(nudge_y = .3, nudge_x = 1.5, check_overlap = T)\n\nQ.2 How many PC’s do we need in order to explain 50% of the variance of the data? Can you make an accumulative plot of the variance explained PC?"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#visualization",
    "href": "develop/GWAS4_extra_population_structure.html#visualization",
    "title": "Population structure",
    "section": "Visualization",
    "text": "Visualization\nWe plot now the first two PCA coordinates and label them by Population, with color by region. We can see how only africans are separated from the rest, but the PCA is quite confused and cannot distinguish EastAsia and WestEurasia.\n\nggplot(data = eigenvectors, aes(x = PC1, y = PC2, col = region)) + \n        geom_point(size=3,alpha=0.5) + geom_text( aes(label=population), col=\"black\") +\n        scale_color_manual(values = c(\"#FF1BB3\",\"#A7FF5B\",\"#99554D\")) +\n        theme_bw()\n\nQ.3 Try to plot PC2 and PC3. Do you see the same patterns? What is the correlation between PC2 and PC3 (hint use the function cor())?\nQ.4 Try also to color the graph based on population. What do you observe?"
  },
  {
    "objectID": "develop/GWAS4_extra_population_structure.html#ld-pruning",
    "href": "develop/GWAS4_extra_population_structure.html#ld-pruning",
    "title": "Population structure",
    "section": "LD pruning",
    "text": "LD pruning\nWe implement LD pruning to eliminate those SNPs that are in high linkage disequilibrium. What happens is that the structure of the populations will change. According to (Bergovich et al, 2024, Biorxiv), this is not good practice and removes a lot of the population information.\n\nset.seed(1000)\n\n# This function prune the snps with a thrshold of maximum 0.3 of LD\nsnpset &lt;- snpgdsLDpruning(genofile, ld.threshold=0.3)\n\n# Get all selected snp's ids\nsnpset.id &lt;- unlist(snpset)\n\npca_pruned &lt;- snpgdsPCA(genofile, snp.id=snpset.id, num.thread=2)\n\n#add metadata\neigenvectors = as.data.frame(pca_pruned$eigenvect)\ncolnames(eigenvectors) = as.vector(sprintf(\"PC%s\", seq(1:nrow(pca$eigenvect))))\npca_pruned$sample.id = sub(\"_chr2_piece_dedup\", \"\", pca$sample.id)\neigenvectors &lt;- cbind(eigenvectors, info[pca$sample.id, c(\"population\",\"region\")])\n\n#plot\nggplot(data = eigenvectors, aes(x = PC3, y = PC2, col = region, label=population)) + \n        geom_text(hjust=1, vjust=0, angle=45) +\n        geom_point(size=3,alpha=0.5) +\n        scale_color_manual(values = c(\"#FF1BB3\",\"#A7FF5B\",\"#99554D\")) +\n        theme_bw() + coord_flip()\n\nQ.5 Implement different LD thresholds (0.1, 0.2, 0.3, 0.4, 0.5). How many SNPs are left after each filtering threshold? Are these SNPs linked?\nNow we are going to convert this GDS file into a plink format, to be later used in the admixture exercise:\n\nsnpgdsGDS2BED(genofile, \"Data/chr2_135_145_flt_prunned.gds\", sample.id=NULL, snp.id=snpset.id, snpfirstdim=NULL, verbose=TRUE)\n\nSave the data for later\n\nsave(pca, pca_pruned, info, genofile, file = \"Results/data.Rdata\")"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html",
    "href": "develop/GWAS8-LDAK-Extra.html",
    "title": "Association models with LDAK",
    "section": "",
    "text": "Tutorial modified from the LDAK creator Doug Speed\nFor these practicals, we will use the les: human.bed, human.bim and human.fam - 1000 Genomes Project SNP data for 424 humans, 3289 SNPs (Chromosomes 21 & 22). quant.pheno, binary.pheno, multi.pheno and covar.covar are phenotypes and covariates for these.\nhapmap.bed, hapmap.bim and hapmap.fam - SNP data for 1184 humans, 1016 SNPs (from HapMap Project). mice.bed, mice.bim, mice.fam and mice.pheno - SNP and phenotype data for 1940 mice, 2984 SNPs.\nwget https://www.dropbox.com/s/5vcfcree3xnvhew/data.zip\nunzip data.zip -d LDAKdata\nchmod -R 777 LDAKdata"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#single-snp-association-analysis",
    "href": "develop/GWAS8-LDAK-Extra.html#single-snp-association-analysis",
    "title": "Association models with LDAK",
    "section": "Single SNP association analysis",
    "text": "Single SNP association analysis\nWe wish to test each of the 3289 SNPs stored in the dataset human individually for association with the continuous phenotype contained within quant.pheno (using the model \\(Y = + alpha_j X_j\\)). For this we use the main argument --linear Each main argument requires di erent options. Documentation is provided at www.ldak.org, but typically the easiest way is to run LDAK using just the main argument, then it will tell you what options you require So here we type\n\nldak --linear linear\n\nFirst LDAK tells us we need to provide phenotypes, so we add that\n\nldak --linear linear --pheno LDAKdata/quant.pheno\n\nNow LDAK tells us we need to provide data les, so we add them\n\nldak --linear linear --pheno LDAKdata/quant.pheno --bfile LDAKdata/human\n\n\n\n\n\n\n\nAlways pay attention at the output screen\n\n\n\nIt will tell you what options are required and why there are errors. It will also update you on progress (as will the file .progress) and tell you where the results are saved. For the linear regression, the main results are in linear.assoc. We will use linear.summaries for summary-statistic methods, linear.pvalues for clumping, while linear.score provides the polygenic risk score prediction model.\n\n\nSome extra options we might wish to use are --keep (to use only a subset of individuals), --extract (to use only a subset of predictors) and --covar (to include covariates, such as age, sex, population axes).\nTo achieve the same in PLINK, you would use\nplink --linear --out linear_plink --bfile LDAKdata/human --pheno LDAKdata/quant.pheno \nNote that by default PLINK ignores individuals without sex (add --allow-no-sex to continue). If your phenotype is binary, you might prefer logistic regression (use --logistic instead of --linear).\n Choose the R kernel\n\nassoc=read.table(\"linear.assoc\",head=T)\n\n\nhead(assoc,4)\n\n\nwhich.min(assoc[,7])\n\n\nassoc[71,]\n\n\noptions(repr.plot.width=14, repr.plot.height=8)\n\npar(mfrow=c(1,2)) \nplot(-log10(assoc[,7]), \n     col=assoc[,1], \n     pch=19,\n     xlab=\"Chromosome\", \n     ylab=expression(paste(\"-log\"[10],\" p-value\",sep=\"\")), \n     main=\"A Pretty Manhattan Plot\",axes=F) \nmarks=array(0,23) \nfor(i in 1:22){\n    a=which(assoc[,1]==i)\n    marks[i+1]=marks[i]+length(a)\n} \n\nmarks2=(marks[-1]+marks[-23])/2 \n\naxis(1,at=marks,rep(\"\",23));\n\naxis(1,at=marks2,lab=1:22,tick=F) \n\naxis(2);abline(h=-log10(5e-8),lwd=3,lty=2) \n\nord=order(assoc[,7])\n\nobsP=assoc[ord,7] \n\nN=nrow(assoc)\n\nexpP=1:N/(N+1) \n\nplot(-log10(expP), \n     -log10(obsP),\n     pch=19,\n     xlab=\"Expected-log10 P\", \n     ylab=\"Observed-log10 P\",\n     main=\"A Less Pretty QQ-Plot\") \n\nabline(a=0,b=1,col=2,lwd=3,lty=3) \n\ngif=qchisq(median(assoc[,7]),1,lower=F)/qchisq(.5,1) \n\ntext(1.5,15,paste(\"Genomic Inflation Factor:\",round(gif,2)),cex=1.3)\n\n Choose the Bash kernel\nTo identify genome-wide associated SNPs we can use awk\n\nawk &lt; linear.assoc '($7&lt;5e-8){print$0}' \n\nTo identify the independent loci, use the command --thin-tops; this will find then prune all SNPs with p-values below a specified threshold. --thin-tops requires lots of options, butagain, LDAK will walk you through them…\n\nldak --thin-tops top --bfile LDAKdata/human --pvalues linear.pvalues \\\n--cutoff 5e-8 --window-cm 1 --window-prune .2\n\n\ncat top.in\n\n\nawk '(NR==FNR){arr[$1];next}($2inarr){print$0}' top.in linear.assoc | head -n 10"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#preparing-a-gwas",
    "href": "develop/GWAS8-LDAK-Extra.html#preparing-a-gwas",
    "title": "Association models with LDAK",
    "section": "Preparing a GWAS",
    "text": "Preparing a GWAS\nThe steps are as follows:\n1 - Remove poorly genotyped samples and SNPs 2 - Remove ethnic outliers 3 - Imputation 4 - Remove poorly imputed samples and SNPs 5 - Remove related individuals\nSteps 1, 2 & 3 are fairly constant. Steps 4 & 5 depend on the aim of the GWAS; heritability analyses generally require much stricter quality control than single-SNP analysis, and are designed for unrelated individuals. One would also increase QC if studying a binary phenotype. E.g., for a single-SNP analysis, I might use an info score threshold of &gt;0.5 or &gt;0.8, but for heritability analysis require info &gt;0.99.\n\nStandard QC steps on the human data\nWe run some predefined thresholds on the human data\n\nplink --bfile LDAKdata/human \\\n    --geno 0.02 \\\n    --make-bed \\\n    --out Results/human1 --silent\n\nplink --bfile Results/human1 \\\n    --mind 0.02 \\\n    --make-bed \\\n    --out Results/human2 --silent\n    \nplink --bfile Results/human2 \\\n    --maf 0.05 \\\n    --make-bed  \\\n    --out Results/human3 --silent\n\n\n\nEthnic outliers and overlapping to a reference\nGenerally we wish to identify and exclude population outliers (the exception is mixed-model association analysis). For this, we will compute a kinship matrix (also referred to as a relatedness matrix/allelic correlations).\nThe command for computing a kinship matrix is --calc-kins-direct. You must use either --weights or --ignore-weights YES to specify SNP weightings, and --power to specify how to standardize SNPs.\nPeople normally use (in-sample) principal component analysis (PCA) in this way:thin the SNPs, calculate a kinship matrix, perform PCA then plot, and find outliers.\nHowever, you cna also project the data onto population axes derived from a diverse reference panel (e.g., HapMap):\n1 - Find overlap of SNPs between dataset and reference panel 2 - Using the reference panel, calculate a kinship matrix, perform PCA and compute SNP loadings for the principal components 3 - Project the data onto these principal components, then plot\n\nEthnic outliers\n\n#thin for LD \nldak --bfile Results/human3 --thin prune \\\n    --window-prune .2 --window-cm 1 \n\nThis produces prune.in and prune.out\n\n#compute unweighted kinships \nldak --calc-kins-direct prune --bfile Results/human3 \\\n    --ignore-weights YES --power -1 --extract prune.in \\\n    --kinship-raw YES \n\nThe kinship matrix is stored with stem prune\n\n#calculate 5 principal components \nldak --pca prune --grm prune --axes 5\n\nHaving computed the PCAs, we can plot and identify outliers\n Choose the R kernel\n\ndatapca=read.table(\"prune.vect\")\nplot(datapca[,3:4],xlab=\"PC1\",ylab=\"PC2\")\nabline(v=.07,col=2,lwd=3,lty=2)\n\n\n\n\nProjection from reference\n Choose the bash kernel\n\n#get overlap between human and hapmap, then thin hapmap \nawk '(NR==FNR){arr[$2];next}($2 in arr){print $2}' \\\n    Results/human3.bim LDAKdata/hapmap.bim &gt; overlap.txt \n\nldak --thin thin --bfile LDAKdata/hapmap \\\n    --window-prune .2 --window-kb 1000 \\\n    --extract overlap.txt \n    \n\n\n#compute kinships, pcas and loadings \nldak --calc-kins-direct hapmap --bfile LDAKdata/hapmap \\\n    --extract thin.in --ignore-weights YES --power -1 \n\n\nldak --pca hapmap --grm hapmap --axes 20\n\n\nldak --calc-pca-loads hapmap --bfile LDAKdata/hapmap \\\n    --grm hapmap --pcastem hapmap\n    \n\n\n#project human onto these loadings \nldak --calc-scores project --bfile Results/human3 \\\n    --scorefile hapmap.load --power 0\n\nPlot the HapMap PCs, project onto these our data, then identify outliers. Save a list of individuals to keep to goodpop.keep\n Choose the R kernel\n\nhappca=read.table(\"hapmap.vect\") \nproj=read.table(\"project.profile\",head=T) \npar(mfrow=c(1,2)) \nplot(happca[,3:4],col=\"light grey\",pch=19,xlab=\"Proj 1\",ylab=\"Proj 2\") \ntext(c(-.04,.02,.02),c(0,.05,-.04),c(\"African\",\"European\",\"Asian\")) \nplot(happca[,3:4],col=\"light grey\",pch=19,xlab=\"Proj 1\",ylab=\"Proj 2\") \npoints(proj[,c(5,7)],col=2,pch=19) \nabline(v=.005,col=2,lwd=3,lty=2) \nabline(h=.025,col=2,lwd=3,lty=2) \nkeep=which(proj[,5]&gt;.005&proj[,7]&gt;.025) \nwrite.table(proj[keep,1:2],\"goodpop.keep\",row=F,col=F,quote=F)\n\nNote that when using a proper number of individuals, the clusters will be much tighter. Also, for convenience, here we used HapMap, but better to use 1000 Genomes Project (see www.ldak.org/reference-panel)\nBelow we plot both the PCA of the data itself and the PCA of the projection on the reference dataset.\n\ndatapca=read.table(\"prune.vect\") \nhappca=read.table(\"hapmap.vect\") \nproj=read.table(\"project.profile\",head=T) \nsites=rep(1,nrow(proj)) \na=grep(\"AFR\",proj[,2])\nsites[a]=2 \na=grep(\"EAS\",proj[,2])\nsites[a]=3\na=grep(\"SAS\",proj[,2])\nsites[a]=4 \na=grep(\"EUR\",proj[,2])\nsites[a]=5\na=grep(\"AMR\",proj[,2])\nsites[a]=6 \na=grep(\"FIN\",proj[,2])\nsites[a]=7\npar(mfrow=c(1,2)) \nplot(datapca[,3:4],col=sites,pch=19,xlab=\"PCA 1\",ylab=\"PCA 2\") \nplot(happca[,3:4],col=\"light grey\",pch=19,xlab=\"Proj 1\",ylab=\"Proj 2\") \npoints(proj[,c(5,7)],col=sites,pch=19)\n\nWe want to create a covariate le to use in subsequent regressions. Generally include as covariates sex plus 10 principal components (5 from in-sample PC, 5 from population projections, from the two plots above). If you have imputed the data, repeat the PCA using that before using the PCA as covariates.\n\n#can get sex from Column 5 of the fam file \nfam=read.table(\"LDAKdata/human.fam\") \n#use match() to ensure samples are aligned \nm1=match(fam[,1],datapca[,1]) \nm2=match(fam[,1],proj[,1]) \ncovar=cbind(fam[,c(1,2,5)],datapca[m1,3:7],proj[m2,c(5,7,9,11,13)]) \nwrite.table(covar,\"covar.covar\",row=F,col=F,quote=F)"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#remove-relatedness",
    "href": "develop/GWAS8-LDAK-Extra.html#remove-relatedness",
    "title": "Association models with LDAK",
    "section": "Remove relatedness",
    "text": "Remove relatedness\nRemove Relatedness To estimate relatedness we can use the kinship matrix computed when performing PCA (i.e., from thinned SNPs). Ideally you would first remove population outliers. Notice that allelic correlation kinships are distributed around expected values (e.g., 1/2 for full-sibs, 0 for unrelateds ), and there are values above 1 and below 0. (For proper sample sizes, spread will be smaller). The general assumption is if we find identical individuals, these are accidental duplicates, so we want to remove one of each pair. We can do this using filter:\n Choose the Bash kernel\n\nldak --filter dups --grm prune --keep goodpop.keep --max-rel .8\n\n(Of course, duplicates may be twins, so check clinical data if possible).\nIf our aim is single-SNP analysis, we normally want to remove close relatedness; a typical cut-off is 0.185, half-way between half-sibs and cousins:\n\nldak --filter close --grm prune --keep goodpop.keep --max-rel .375\n\n(This is not necessary if performing mixed-model association analysis).\nFor heritability analyses, we generally require unrelated individuals, so we lter based on estimated relatedness. As a threshold, you can use an arbitrary value (say 0.025 or 0.05) or second cousins (1/32=0.03125), but prefer to use the negative of the smallest value observed (the default in LDAK)\n\nldak --filter filter --grm prune --keep goodpop.keep\n\nIn this (unrealistic example), the minimum kinship is -0.176; using this threshold results in removal of 9 individuals, so that 397 remain (stored in filter.keep)"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#snp-weights",
    "href": "develop/GWAS8-LDAK-Extra.html#snp-weights",
    "title": "Association models with LDAK",
    "section": "SNP weights",
    "text": "SNP weights\nThe simple way to do this is using --cut-weights and --calc-weights-all. This can take a lot of time and you need to be patient.\n Choose the bash kernel\n\nldak --bfile LDAKdata/human --cut-weights sections \\\n    --keep goodpop.keep \n\nldak --bfile LDAKdata/human --calc-weights-all sections \\\n    --keep goodpop.keep"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#weighted-kinship-matrix",
    "href": "develop/GWAS8-LDAK-Extra.html#weighted-kinship-matrix",
    "title": "Association models with LDAK",
    "section": "Weighted Kinship matrix",
    "text": "Weighted Kinship matrix\nFor this, we use --calc-kins-direct\n\nldak --calc-kins-direct kins --bfile LDAKdata/human \\\n    --weights sections/weights.all\\\n    --power -.25 --kinship-raw YES"
  },
  {
    "objectID": "develop/GWAS8-LDAK-Extra.html#estimate-variance-components",
    "href": "develop/GWAS8-LDAK-Extra.html#estimate-variance-components",
    "title": "Association models with LDAK",
    "section": "Estimate variance components",
    "text": "Estimate variance components\nFirst we consider the phenotype quant.pheno and use REML. Remember to include --keep so that we only use unrelated individuals. The main output file is quant.reml, but there are many additional files.\n\nldak --reml quant --grm kins\\\n    --pheno LDAKdata/quant.pheno\\\n    --keep filter.keep\n\nNote, large efect SNPs should be included as top predictors!\nHeritability is estimated to be 0.73 +- 0.08\n\ncat quant.reml"
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html",
    "href": "develop/GWAS4-QualityControlB.html",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAs we have already mentioned, quality control (QC) analyses are crucial to ensure the reliability and validity of the results. In this section, we will explore confounding factors in GWAS that can lead to spurious associations if not properly controlled, including:\n\nRelatedness\n\nPopulation Stratification/Structure\n\n\n\n\nDiscuss confounding factors that lead to spurious associations\nDetect related individuals\nIdentify population substructure\nCorrect for population stratification\n\n\n\n\nIn this notebook, we will both use R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. * We will first run Bash commands.\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: Relatedness & Population Stratification"
    ]
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#learning-outcomes",
    "href": "develop/GWAS4-QualityControlB.html#learning-outcomes",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "Discuss confounding factors that lead to spurious associations\nDetect related individuals\nIdentify population substructure\nCorrect for population stratification",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: Relatedness & Population Stratification"
    ]
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS4-QualityControlB.html#how-to-make-this-notebook-work",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "In this notebook, we will both use R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. * We will first run Bash commands.\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: Relatedness & Population Stratification"
    ]
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#a.-relatedness",
    "href": "develop/GWAS4-QualityControlB.html#a.-relatedness",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "A. Relatedness",
    "text": "A. Relatedness\nRelatedness refers to the presence of genetically related individuals in a study sample, which can introduce confounding factors into association analyses. Since most statistical methods assume that samples are independent, including related individuals, like siblings, violates this assumption. Addressing relatedness is crucial as a quality control step to ensure that genomes in the dataset are no more similar than expected for unrelated individuals. This process is essential to preserve the validity of the study’s findings.\nWhile all humans share some genetic relatedness, the degree of relatedness varies among individuals. In genome-wide association studies (GWAS), these variations must be accounted for to avoid biasing the statistical associations between genotypes and phenotypes. Cryptic relatedness (genetic relatedness of individuals not expected to be in a family relationship) can interfere with the association analysis (Voight and Pritchard 2005).\nIn a family-based study (e.g., parent-offspring), you do not need to remove related pairs, but the statistical analysis should account for family relatedness. However, for a population-based study, we suggest using the KING estimator (Manichaikul et al. 2010) with a threshold of 0.06.\nDifferently from the IBD estimator (called pi_hat \\(\\hat{\\pi}\\)), which assumes that individuals come from homogeneous population, KING derives a kinship estimate for a pair of individuals without reference to the population allele frequencies. Instead, it gets the relatedness information from the difference between the counts of loci where both individuals are heterozygotes and counts of loci where they are different homozygotes, normalized by the sum of the heterozygous loci of the individuals. This makes KING robust to population structure and useful to check genotyping quality.\nThus, values for KING are\n\n0.25 for parent-child or full siblings: they share exactly 50% of their alleles by descent (IBD). For full siblings it can vary slightly (e.g. recombination events).\n0.125 for half siblings: they have 25% IBD (one parent is common).\n0.065 for 1st cousins: IBD is 12.5% since they share one set of grandparents and not parents.\n\nKING values need to be multiplied by 2 to match the corresponding IBD probability\n\nWe use ln -sf to link the data folder and create a directory for output files.\n\nln -sf ../Data\nmkdir -p Results/GWAS4\n\n\nAnalysis with PLINK\nWe will use the set of independent SNPs (generated in the previous section) and the --make-king-table option in PLINK2 for our analysis, so that we generate pairwise KING estimators. Note that we use version 2 of PLINK because this one has implemented the KING estimator.\nThe HapMap dataset is known to contain parent-offspring relationships. We will check the KING estimator values and exclude all individuals above a chosen threshold (to remove at least related individuals).\n\nplink2 --bfile Results/GWAS3/HapMap_3_r3_7 \\\n       --extract Results/GWAS3/indepSNP.prune.in --make-king-table \\\n       --out Results/GWAS4/KING\n\nPLINK v2.00a5.12LM 64-bit Intel (25 Jun 2024)  www.cog-genomics.org/plink/2.0/\n(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/KING.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_7\n  --extract Results/GWAS3/indepSNP.prune.in\n  --make-king-table\n  --out Results/GWAS4/KING\n\nStart time: Thu Mar 20 10:26:22 2025\n385567 MiB RAM detected, ~348835 available; reserving 192783 MiB for main\nworkspace.\nUsing up to 64 threads (change this with --threads).\n161 samples (84 females, 77 males; 110 founders) loaded from\nResults/GWAS3/HapMap_3_r3_7.fam.\n1073788 variants loaded from Results/GWAS3/HapMap_3_r3_7.bim.\n1 binary phenotype loaded (55 cases, 55 controls).\n--extract: 104129 variants remaining.\n104129 variants remaining after main filters.\n--make-king-table pass 1/1: Scanning for rare variants... done.\n0 variants handled by initial scan (104129 remaining).\n--make-king-table pass 1/1: Writing... done.\n--make-king-table: 104129 variants processed.\nResults written to Results/GWAS4/KING.kin0 .\nEnd time: Thu Mar 20 10:26:23 2025\n\n\nThe table from PLINK2 contains various things:\n\nFID1: Family ID of the first individual.\nIID1: Individual ID of the first individual.\nFID2: Family ID of the second individual.\nIID2: Individual ID of the second individual.\nNSNP: The number of SNPs used to calculate the kinship between the two individuals.\nHETHET: The number of heterozygous sites used in the kinship calculation (often useful for checking genotyping quality).\nIBS0: The number of identical-by-state (IBS) 0 SNPs, which are variants where the two individuals do not share the same allele.\nKINSHIP: The kinship coefficient (or pihat) between the two individuals, which is the proportion of alleles shared by descent.\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nWhat assumption in association studies is violated when individuals are related?\nHow would you recognize if the same sample is duplicated in your dataset?\nAre there closely related individuals? How many individuals show close relatedness (KING &gt; 0.2)?\nWhat relationships are found by PLINK?\n\n\n\n\n# Write your code here (add more cells if needed)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf you have related individuals, you will lose the independence of individuals at each SNP. This is a problem because many models used in GWAS analysis do not include handling family relationships.\nCalculating the KING coefficient and looking for a value close to 0.5.\nWe will look for unique values in column 8 (KINSHIP), rounding to two decimals\nWe will examine KINSHIP values in column 8.\n\nLet’s print the first few rows of KING.kin0 and then, the unique relatioship categories in the file:\n\ncat Results/GWAS4/KING.kin0 | head -5\n\n#FID1   IID1    FID2    IID2    NSNP    HETHET  IBS0    KINSHIP\n1377    NA11891 1328    NA06989 102710  0.145088    0.0717846   -0.000964635\n1349    NA11843 1328    NA06989 103818  0.144696    0.0721744   -0.000456018\n1349    NA11843 1377    NA11891 102869  0.143843    0.0717126   -0.00162819\n1330    NA12341 1328    NA06989 103575  0.148395    0.0704417   0.00856727\n\n\nNow, let’s calculate how many samples are in a pair with KING KINSHIP parameter (column 8) larger than 0.06, 0.12, 0.2 (to account for small variations in relevant thresholds). Note that the file contains one individual of a pair, so some samples might be shown many times. Thus we make those samples unique.\n\nawk '{ if ($8 &gt; 0.06) print $2}' Results/GWAS4/KING.kin0 | sort | uniq | wc -l\n\n77\n\n\n\nawk '{ if ($8 &gt; 0.12) print $2}' Results/GWAS4/KING.kin0 | sort | uniq | wc -l\n\n77\n\n\n\nawk '{ if ($8 &gt; 0.2) print $2}' Results/GWAS4/KING.kin0 | sort | uniq | wc -l\n\n77\n\n\nThere are 76 individuals with KINSHIP larger than all thresholds. So we might have 76 half siblings, cousins and siblings mixed in the data. There are potentially some family ties in this data!\n\n\n\n\n Switch to the R-GWAS kernel.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nWrite some R code to calculate the summary of the distribution of KINSHIP values. What do you observe?\nhint: use the hist() command.\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMany parent-offspring (PO) relationships have a parameter close to 0.5, and the maximum value for unrelated (UN) individuals is also unexpectedly high relatedness.\nWe read in the matrix (Note that the header starts with # in the file KING.kin0, so we need comment.char = '|' to avoid the header being excluded as a comment)\n\n# Generate a plot to assess the type of relationship.\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nrelatedness &lt;- read.table(\"Results/GWAS4/KING.kin0\", header=TRUE, comment.char = '|')\n\nhead(relatedness)\n\n\nA data.frame: 6 × 8\n\n\n\nX.FID1\nIID1\nFID2\nIID2\nNSNP\nHETHET\nIBS0\nKINSHIP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1377\nNA11891\n1328\nNA06989\n102710\n0.145088\n0.0717846\n-0.000964635\n\n\n2\n1349\nNA11843\n1328\nNA06989\n103818\n0.144696\n0.0721744\n-0.000456018\n\n\n3\n1349\nNA11843\n1377\nNA11891\n102869\n0.143843\n0.0717126\n-0.001628190\n\n\n4\n1330\nNA12341\n1328\nNA06989\n103575\n0.148395\n0.0704417\n0.008567270\n\n\n5\n1330\nNA12341\n1377\nNA11891\n102623\n0.146877\n0.0706957\n0.002694440\n\n\n6\n1330\nNA12341\n1349\nNA11843\n103735\n0.147337\n0.0719333\n0.002062960\n\n\n\n\n\nNow we look at how many pairs have specific relatedness values. You can see there are around 100 pairs of cousins/half siblings/siblings. Those correspond to the 76 unique samples observed before.\n\nhist.king &lt;- ggplot(relatedness, aes(x=relatedness[,8])) +\n  geom_histogram(binwidth = 0.02, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Histogram of relatedness (KING)\") + \n  xlab(\"KING kinship\") + \n  ylab(\"Log Frequency\") + \n  theme_bw() +\n  scale_y_log10() +\n  theme(axis.title=element_text(size=14), \n        axis.text=element_text(size=13),\n        plot.title=element_text(size=15)) \n\n#Extract coordinates of the plot\nbin_data &lt;- ggplot_build(hist.king)$data[[1]]\n\n#Adding text labels to  each bar, \n#accounting for log scale\nhist.king + \n  geom_text(data = bin_data, \n            aes(x = xmin + (xmax - xmin) / 2, \n                y = log10(count+1),  # Apply log10\n                label = count), \n                vjust = -5, #Vertical adjustment of text\n                size = 4, \n                color = \"black\")\n\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message:\n“Removed 6 rows containing missing values or values outside the scale range\n(`geom_bar()`).”\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also plot the number of SNPs used to calculate relatedness VS the KING relatedness itself. Pairs with very low number of SNPs and anomalous KING estimator might simply contain badly genotyped sample(s). This is not at all our case.\n\n# Relatedness plot\nplot.relatedness &lt;- ggplot(relatedness) +\n  geom_point(aes(x=NSNP, y=KINSHIP), size=5, alpha=.25) + \n  ylim(-.1,.4) +\n  labs(x = \"Number of SNPs used\", y = \"KING kinship\", title = \"Check for genotyping quality\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=14), \n        axis.text=element_text(size=13), \n        legend.text= element_text(size=13), \n        legend.title=element_text(size=14), \n        plot.title=element_text(size=15))\n\nshow(plot.relatedness)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nUse PLINK options to filter out related individuals, using a relatedness threshold of 0.1.\n\nFirst of all you need to create a file with the IDs of the samples to remove. You can use the command awk as we did before in this exercise.\nAfterwards you need PLINK with the option --remove to use the file with IDs. Name the output --out Results/GWAS4/king_exercise.\n\n\n\n Switch to the Bash kernel.\n\n# Write your code here (PLINK command)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe use awk to print IDs to remove and then the option --remove of PLINK.\n We print out all family and sample IDs for which the column KINSHIP (column 8) is &gt;0.1. Note we print both samples in the pair with high relatedness, using the awk command twice.\n\nawk '{ if ($8 &gt; 0.1) print $1, $2 }' Results/GWAS4/KING.kin0 &gt; Results/GWAS4/filter_king.txt\n\nNow each sample is identified uniquely ba family and sample ID. Some samples are repeated more than once because we have selected the first sample in related pairs, so same samples appear more than once. We use the option --remove to produce a new set of plink files. We will be warned about sample repetitions because we have been having some duplicates from the KINSHIP pairs\n\nplink --bfile Results/GWAS3/HapMap_3_r3_7 \\\n    --make-bed \\\n    --remove Results/GWAS4/filter_king.txt \\\n    --out Results/GWAS4/king_exercise\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/king_exercise.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_7\n  --make-bed\n  --out Results/GWAS4/king_exercise\n  --remove Results/GWAS4/filter_king.txt\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073788 variants loaded from .bim file.\n161 people (77 males, 84 females) loaded from .fam.\n110 phenotype values loaded from .fam.\n--remove: 85 people remaining.\nWarning: At least 17 duplicate IDs in --remove file.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 67 founders and 18 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate in remaining samples is 0.997765.\n1073788 variants and 85 people pass filters and QC.\nAmong remaining phenotypes, 34 are cases and 33 are controls.  (18 phenotypes\nare missing.)\n--make-bed to Results/GWAS4/king_exercise.bed + Results/GWAS4/king_exercise.bim\n+ Results/GWAS4/king_exercise.fam ... done.\n\n\nWe have gone from 161 to 85 samples, removing 76 related ones.\n\n\n\n\n Switch to the Bash kernel.\nSo far, you’ve learned how to filter individuals using KING kinship thresholds. Now, we’ll demonstrate that most of the relatedness was due to parent-offspring relationships. We will achieve this by using the --filter-founders option to create a new filtered dataset that includes only the founders (individuals without listed parents in the data). This generates .bed, .bim, and .fam files, which are then used to create a .kin0 file containing relatedness values. Note again we use plink2 to create the KING matrix.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_7 \\\n    --filter-founders \\\n    --make-bed \\\n    --out Results/GWAS4/HapMap_3_r3_8 \\\n    --silent\n\nplink2 --bfile Results/GWAS4/HapMap_3_r3_8 \\\n    --extract Results/GWAS3/indepSNP.prune.in \\\n    --make-king-table \\\n    --out Results/GWAS4/KING_founders\n\nPLINK v2.00a5.12LM 64-bit Intel (25 Jun 2024)  www.cog-genomics.org/plink/2.0/\n(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/KING_founders.log.\nOptions in effect:\n  --bfile Results/GWAS4/HapMap_3_r3_8\n  --extract Results/GWAS3/indepSNP.prune.in\n  --make-king-table\n  --out Results/GWAS4/KING_founders\n\nStart time: Thu Mar 20 10:28:05 2025\n385567 MiB RAM detected, ~348812 available; reserving 192783 MiB for main\nworkspace.\nUsing up to 64 threads (change this with --threads).\n110 samples (55 females, 55 males; 110 founders) loaded from\nResults/GWAS4/HapMap_3_r3_8.fam.\n1073788 variants loaded from Results/GWAS4/HapMap_3_r3_8.bim.\n1 binary phenotype loaded (55 cases, 55 controls).\n--extract: 104129 variants remaining.\n104129 variants remaining after main filters.\n--make-king-table pass 1/1: Scanning for rare variants... done.\n0 variants handled by initial scan (104129 remaining).\n--make-king-table pass 1/1: Writing... done.\n--make-king-table: 104129 variants processed.\nResults written to Results/GWAS4/KING_founders.kin0 .\nEnd time: Thu Mar 20 10:28:05 2025\n\n\n Switch to the R kernel.\nLet’s plot the results from the KING_founders.kin0 file. We can see how there is only 1 pair with high kinship amongst the founders.\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\nrelatedness &lt;- read.table(\"Results/GWAS4/KING_founders.kin0\", header=TRUE, comment.char = '|')\n\nhist.king &lt;- ggplot(relatedness, aes(x=relatedness[,8])) +\n  geom_histogram(binwidth = 0.02, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Histogram of relatedness (KING) in founders-only data\") + \n  xlab(\"KING kinship\") + \n  ylab(\"Log Frequency\") + \n  theme_bw() +\n  scale_y_log10() +\n  theme(axis.title=element_text(size=14), \n        axis.text=element_text(size=13),\n        plot.title=element_text(size=15)) \n\n#Extract coordinates of the plot\nbin_data &lt;- ggplot_build(hist.king)$data[[1]]\n\n#Adding text labels to  each bar, \n#accounting for log scale\nhist.king + \n  geom_text(data = bin_data, \n            aes(x = xmin + (xmax - xmin) / 2, \n                y = log10(count+1),  # Apply log10\n                label = count), \n                vjust = -10, #Vertical adjustment of text\n                size = 4, \n                color = \"black\")\n\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message in scale_y_log10():\n“log-10 transformation introduced infinite values.”\nWarning message:\n“Removed 9 rows containing missing values or values outside the scale range\n(`geom_bar()`).”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\n1. Do you observe anything unexpected in the plot?\n2. Can you identify the IIDs of the sample pair? Hint: filter for KINSHIP values.\n3. Based on the KINSHIP, what is the most likely relationship between the pair?\n4. What would you do about it? Hint: remove one or both in the pair?\n\n\n\n\n# Write your answer here\n\n\n# R code here\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n1. The file KING_founders.kin0 shows that, after excluding all non-founders, one individual pair removed in the exercise remains in the HapMap data.\n2. Below, we can look at the individual from the table by setting KINSHIP &gt; 0.2. Even if labeled as unrelated, it has high relatedness. The IIDs of the pair are NA07045 and NA12813.\n\n\nrelatedness[relatedness$KINSHIP &gt; 0.2,]\n\n\nA data.frame: 1 × 8\n\n\n\nX.FID1\nIID1\nFID2\nIID2\nNSNP\nHETHET\nIBS0\nKINSHIP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2729\n1454\nNA12813\n13291\nNA07045\n103649\n0.213779\n0.0186302\n0.247556\n\n\n\n\n\n\n3. This remaining individual is likely to be related with sibling relationship, even though they were not given the same family identity (FID) in the HapMap data.\n4. We don’t need to remove both individuals from the dataset (IID1=NA07045; IID2=NA12813). It’s enough to remove just one, and the individual with the highest missing rate (lowest quality) could be chosen. Let’s calculate the missing rates using PLINK.\n\n\n\n\n\n Switch to the Bash kernel.\n\nplink --bfile Results/GWAS4/HapMap_3_r3_8 \\\n    --missing \\\n    --out Results/GWAS4/HapMap_3_r3_8 \\\n    --silent\n\nThen, find the two individuals from the output file using grep and sorting descendingly by missing rate (EZ, column 6)\n\n# Let's look at the output\ncat Results/GWAS4/HapMap_3_r3_8.imiss | grep -E 'NA07045|NA12813' | sort -k6,6nr\n\n  13291   NA07045          N     2560  1073788 0.002384\n   1454   NA12813          N     1956  1073788 0.001822\n\n\nNA07045 is the individual to be removed. Once this is removed, their offspring can still be used in analyses that don’t involve trios, such as family-related studies.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nPlot the distribution of missing rates from HapMap_3_r3_8. What is the value for NA07045?\nRemove NA07045 from the PLINK files\n\nHint:\n\nUse the .imiss file to plot a histogram of the missing scores from the file HapMap_3_r3_8.imiss in R (check previous notebooks for help). Is the score of NA07045 amongst the higher/lower ones? You can add a vertical line in the histogram representing the value for NA07045 using geom_vline.\nCreate a file with the sample ID to remove and use the --remove option in PLINK.\n\n\n\n Switch to the R kernel.\n\n# Write your code here\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can extract the column from the file and observe in the histogram that the individual NA07045 has a missing rate closer which is in the bulk of other samples.\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nsmiss &lt;- read.table(\"Results/GWAS4/HapMap_3_r3_8.imiss\", header=T)\n\nhead(smiss)\n\nhist.relatedness &lt;- ggplot(data=smiss, aes(F_MISS)) +\n  geom_histogram(col = \"black\", fill = \"tomato\") + \n  geom_vline(xintercept = 0.002384, color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  labs(title = \"Histogram of missing rates\") + \n  xlab(\"Missing rate\") + \n  ylab(\"Frequency\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13),plot.title=element_text(size=15))\n\nshow(hist.relatedness)\n\n\nA data.frame: 6 × 6\n\n\n\nFID\nIID\nMISS_PHENO\nN_MISS\nN_GENO\nF_MISS\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1328\nNA06989\nN\n2202\n1073788\n0.0020510\n\n\n2\n1377\nNA11891\nN\n13607\n1073788\n0.0126700\n\n\n3\n1349\nNA11843\nN\n821\n1073788\n0.0007646\n\n\n4\n1330\nNA12341\nN\n3708\n1073788\n0.0034530\n\n\n5\n1328\nNA06984\nN\n6484\n1073788\n0.0060380\n\n\n6\n1418\nNA12275\nN\n2740\n1073788\n0.0025520\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n Switch to the Bash kernel.\nTo remove the individual from the data, we create a file containing its number and ID, and provide it to PLINK with the option --remove\n\necho \"13291  NA07045\" &gt; Results/GWAS4/id_remove.txt\n\n\nplink --bfile Results/GWAS4/HapMap_3_r3_8 \\\n    --remove Results/GWAS4/id_remove.txt \\\n    --make-bed \\\n    --out Results/GWAS4/HapMap_3_r3_9 \\\n    --silent",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: Relatedness & Population Stratification"
    ]
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#b.-population-stratification",
    "href": "develop/GWAS4-QualityControlB.html#b.-population-stratification",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "B. Population Stratification",
    "text": "B. Population Stratification\nPopulation stratification presents a significant source of systematic bias in GWAS, arising when subpopulations exhibit systematic differences in allele frequencies. Research indicates that even subtle degrees of population stratification can exist within a single ethnic population (Abdellaoui et al. 2013). Thus, testing and controlling for the presence of population stratification is an essential QC step.\nThe population structure (or in other words, the ancestral relationship of the populations) is a so-called confounding factor. This means that it affects both the dependent and independent variables, as shown in the figure below, where both the genotype and traits are influenced by population structure (e.g., the distribution of north and south European individuals in the PCA space and the height of those individuals).\n\n\n\n\n\nWhy is a bias introduced? Population structure can influence allele frequencies and produce false positives/negatives when doing association testing. Graphically, consider the example in the figure below. Case and control for population 1 and 2 have specific MAFs. Removing the barrier between populations will change MAFs drastically for the two confitions.\n\n\n\n\n\nThe same problem arises in population studies without Case-control categories. Imagine having a population of randomly sampled individuals, each from a different ethnicity (the blue and red minor alleles in the example below). The final group of individuals will have a different proportion of MAFs depending on the sampling of various ethnicities.\n\n\n\n\n\nThere are several methods to correct for population stratification Alkes L. Price et al. (2006). Here, we illustrate a method integrated into PLINK: the multidimensional scaling (MDS) approach. MDS calculates the genome-wide average proportion of shared alleles between any pair of individuals to generate quantitative indices (components) of the genetic variation for each individual. The individual component scores can be visualized to identify groups of genetically similar individuals. For instance, in a genetic study including subjects from Asia and Europe, MDS analysis would reveal that Asians are genetically more similar to each other than to Europeans and Africans. The figure below shows another example of MDS using HapMap, Genome diversity project, and authors’ data:\n\n\n\nExample of MDS plot of the first two MDS components scores on integrated datasets in Somers et al. (2017). Here TWN, a past isolated population in the Netherlands, is separated from the other individuals from the same country (NDL). Sardinians, notoriously different from continental Italians, are also grouped far away from them. Central European populations colocalize as expected.\n\n\nTo investigate which individuals the generated component scores deviate from in the target population, plotting the scores of the dataset under investigation and a population of known ethnic structure (e.g., HapMap/1KG data) is helpful: this step is called anchoring (Rietveld et al. 2013). This enables the researcher to obtain ethnic information on their data and to determine possible ethnic outliers. For example, in the figure above, if TSI (Tuscans from Italy) is the anchor population, one can hypothesize that the yellow dots might be ethnically similar (as in the example).\nOutliers identified based on MDS analysis should be excluded from further analyses. Following their removal, a new MDS analysis must be conducted, and its primary components are utilized as covariates in association tests to correct for any residual population stratification within the population. The number of components to include depends on the population structure and sample size (usually 10-20).\nThe MDS from Cortellari et al. (2021) shows a distinct goat population outlier. The second axis is dominated by this outlier, obscuring structure in the other populations. Removing the outlier reveals a clearer structure among the remaining populations.\n\n\n\n\n\n\nAnalysis\nWe aim to merge the HapMap and 1000GP datasets, using 1000GP Phase I as the anchor for HapMap. Our goal is to check if we can identify the ethnicity of the HapMap data based on the ethnicities in the 1000GP dataset. There are several steps to ensure compatibility between the datasets, so stay with us!\n\n1000GP data download\nHere are some commands to download and convert the 1000GP data for GWAS analysis. You don’t need to run them, as we’ve already processed the data.\n\n1000 Genomes Project - Phase I: genetic information for 629 individuals from various ethnic groups (&gt;60GB). Phase III is now available, and we recommend using it for research purposes.\n\nwget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz\nThe data was converted from the vcf file (Variant Call Format) to plink format (bim, fam, bed):\nplink2 --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out ALL.2of4intersection.20100804.genotypes\n\n\n\n\n\n\nNote\n\n\n\nThe 1000 Genomes data downloaded above is rather large so the commands are not executable and are shown for reference only. To save time, we’ve provided the .bed, .bimand .fam files in the Data folder.\n\n\nLet’s unzip the files and see how many samples we have.\n\nunzip -o Data/1000genomes.zip -d Results/GWAS4\n# count lines in fam \nwc -l Results/GWAS4/1000genomes.genotypesA.fam\n\nArchive:  Data/1000genomes.zip\n  inflating: Results/GWAS4/1000genomes.genotypesA.bed  \n  inflating: Results/GWAS4/1000genomes.genotypesA.bim  \n  inflating: Results/GWAS4/1000genomes.genotypesA.fam  \n  inflating: Results/GWAS4/1000genomes.genotypesA.log  \n  inflating: Results/GWAS4/1000genomes.genotypesA.nosex  \n37 Results/GWAS4/1000genomes.genotypesA.fam\n\n\nWe have a subset of 37 individuals. Now, let’s explore the bim file.\n\ncat Results/GWAS4/1000genomes.genotypesA.bim | head -5\n\n1   rs112750067 0   10327   C   T\n1   .   0   11508   A   G\n1   .   0   12783   G   A\n1   .   0   13116   G   T\n1   .   0   14933   A   G\n\n\nOne should note that the file 1000genomes.genotypes.bim contains SNPs without an rs-identifier (or Reference SNP cluster ID). The missing rs-identifiers (noted as .) are not a problem for this tutorial. However, for good practice, we will assign unique identifiers to the SNPs (using available information):\n\nplink --bfile Results/GWAS4/1000genomes.genotypesA \\\n    --set-missing-var-ids @:#[b37]\\$1,\\$2 \\\n    --make-bed \\\n    --out Results/GWAS4/1000genomes.genotypesA_no_missing_IDs \\\n    --silent\n\nNow, let’s visualize the data to check the SNP names assigned. These are derived from the format @:#[b37]\\$1,\\$2 in the command above, which PLINK interprets as chromosome:locus[b37]Allele1,Allele2:\n\n# Show changes on the bim file\ncat Results/GWAS4/1000genomes.genotypesA_no_missing_IDs.bim | head -5\n\n1   rs112750067 0   10327   C   T\n1   1:11508[b37]A,G 0   11508   A   G\n1   1:12783[b37]A,G 0   12783   G   A\n1   1:13116[b37]G,T 0   13116   G   T\n1   1:14933[b37]A,G 0   14933   A   G\n\n\nPretty neat, right?\n\n\nQC on 1000GP data\nAs we covered in the GWAS3 notebook, it’s important to account for missingness, sex discrepancies, and minor allele frequency. We’ll apply standard QC thresholds to the 1000 GP data before merging it with HapMap data.\n\nplink --bfile Results/GWAS4/1000genomes.genotypesA_no_missing_IDs \\\n    --geno 0.02 \\\n    --make-bed \\\n    --out Results/GWAS4/1kG_MDS --silent\n\nplink --bfile Results/GWAS4/1kG_MDS \\\n    --mind 0.02 \\\n    --make-bed \\\n    --out Results/GWAS4/1kG_MDS2 --silent\n    \nplink --bfile Results/GWAS4/1kG_MDS2 \\\n    --maf 0.05 \\\n    --make-bed  \\\n    --out Results/GWAS4/1kG_MDS3 --silent\n\n\n\nSNPs matching between datasets\nN.B: Ensure that the datasets you want to merge share the same genomic build! Otherwise, you’ll need to include a liftover step.\nWe want to only consider SNPs that both datasets have in common. First, extract SNP names from the HapMap data and filter the 1000GP data to include only matching SNPs.\n\n#Print out SNPs from the HapMap data\nawk '{print$2}' Results/GWAS4/HapMap_3_r3_9.bim &gt; Results/GWAS4/HapMap_SNPs.txt\n\n#Extract the HapMap SNPs from the 1000GP data\nplink --bfile Results/GWAS4/1kG_MDS3 \\\n    --extract Results/GWAS4/HapMap_SNPs.txt \\\n    --make-bed \\\n    --out Results/GWAS4/1kG_MDS4\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/1kG_MDS4.log.\nOptions in effect:\n  --bfile Results/GWAS4/1kG_MDS3\n  --extract Results/GWAS4/HapMap_SNPs.txt\n  --make-bed\n  --out Results/GWAS4/1kG_MDS4\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n2232052 variants loaded from .bim file.\n37 people (0 males, 0 females, 37 ambiguous) loaded from .fam.\nAmbiguous sex IDs written to Results/GWAS4/1kG_MDS4.nosex .\n--extract: 376560 variants remaining.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 37 founders and 0 nonfounders present.\nCalculating allele frequencies... done.\n376560 variants and 37 people pass filters and QC.\nNote: No phenotypes present.\n--make-bed to Results/GWAS4/1kG_MDS4.bed + Results/GWAS4/1kG_MDS4.bim +\nResults/GWAS4/1kG_MDS4.fam ... done.\n\n\nThis is how part of the list of SNP names looks like:\n\ncat Results/GWAS4/HapMap_SNPs.txt | head -5\n\nrs3131972\nrs3131969\nrs1048488\nrs12562034\nrs12124819\n\n\nNow we take the variants from the reduced 1000GP data, and go the other way around. We extract 1000GP variants from the HapMap data. In other words, the two extraction passages will intersect the SNPs. Below is the code to use the SNPs of the 1000GP data to reduce the HapMap data.\n\n#Print out SNPs from the HapMap data\nawk '{print$2}' Results/GWAS4/1kG_MDS4.bim &gt; Results/GWAS4/1kG_MDS4_SNPs.txt\n\n#Extract the HapMap SNPs from the 1000GP data\nplink --bfile Results/GWAS4/HapMap_3_r3_9 \\\n    --extract Results/GWAS4/1kG_MDS4_SNPs.txt \\\n    --make-bed \\\n    --out Results/GWAS4/HapMap_MDS\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/HapMap_MDS.log.\nOptions in effect:\n  --bfile Results/GWAS4/HapMap_3_r3_9\n  --extract Results/GWAS4/1kG_MDS4_SNPs.txt\n  --make-bed\n  --out Results/GWAS4/HapMap_MDS\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073788 variants loaded from .bim file.\n109 people (55 males, 54 females) loaded from .fam.\n109 phenotype values loaded from .fam.\n--extract: 376560 variants remaining.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 109 founders and 0 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998017.\n376560 variants and 109 people pass filters and QC.\nAmong remaining phenotypes, 54 are cases and 55 are controls.\n--make-bed to Results/GWAS4/HapMap_MDS.bed + Results/GWAS4/HapMap_MDS.bim +\nResults/GWAS4/HapMap_MDS.fam ... done.\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nLook at the two outputs below a bit more carefully. The names are all matching. Is there any other problem?\n\n\n\nhead Results/GWAS4/HapMap_MDS.bim\n\n1   rs3131969   0   744045  A   G\n1   rs12562034  0   758311  A   G\n1   rs4970383   0   828418  A   C\n1   rs4475691   0   836671  T   C\n1   rs1806509   0   843817  C   A\n1   rs28576697  0   860508  C   T\n1   rs3748595   0   877423  A   C\n1   rs13303118  0   908247  G   T\n1   rs1891910   0   922320  A   G\n1   rs3128097   0   970323  G   A\n\n\n\nhead Results/GWAS4/1kG_MDS4.bim\n\n1   rs3131969   0   754182  A   G\n1   rs12562034  0   768448  A   G\n1   rs4970383   0   838555  A   C\n1   rs4475691   0   846808  T   C\n1   rs1806509   0   853954  A   C\n1   rs28576697  0   870645  C   T\n1   rs3748595   0   887560  A   C\n1   rs13303118  0   918384  T   G\n1   rs1891910   0   932457  A   G\n1   rs3128097   0   980460  G   A\n\n\n\n\nBuild matching\nGenomic data is based on a reference genome, and our datasets use different human reference versions. Since the reference genome improves over time, SNP positions may differ between datasets from different versions.\nWe extract SNP names and positions from the HapMap data and align the 1000GP data to match these SNPs using the --update-map option in PLINK.\n\n#Extract the HapMap variant coordinates\nawk '{print$2,$4}' Results/GWAS4/HapMap_MDS.bim &gt; Results/GWAS4/buildhapmap.txt\n\nThis is how the list of SNPs look like:\n\ncat Results/GWAS4/buildhapmap.txt | head -5\n\nrs3131969 744045\nrs12562034 758311\nrs4970383 828418\nrs4475691 836671\nrs1806509 843817\n\n\nWe run PLINK to update the 1000GP variant coordinates based on HapMap, ignoring the warning about unsorted positions:\n\nplink --bfile Results/GWAS4/1kG_MDS4 \\\n    --update-map Results/GWAS4/buildhapmap.txt \\\n    --make-bed \\\n    --out Results/GWAS4/1kG_MDS5\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/1kG_MDS5.log.\nOptions in effect:\n  --bfile Results/GWAS4/1kG_MDS4\n  --make-bed\n  --out Results/GWAS4/1kG_MDS5\n  --update-map Results/GWAS4/buildhapmap.txt\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n376560 variants loaded from .bim file.\n37 people (0 males, 0 females, 37 ambiguous) loaded from .fam.\nAmbiguous sex IDs written to Results/GWAS4/1kG_MDS5.nosex .\n--update-map: 376560 values updated.\nWarning: Base-pair positions are now unsorted!\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 37 founders and 0 nonfounders present.\nCalculating allele frequencies... done.\n376560 variants and 37 people pass filters and QC.\nNote: No phenotypes present.\n--make-bed to Results/GWAS4/1kG_MDS5.bed + Results/GWAS4/1kG_MDS5.bim +\nResults/GWAS4/1kG_MDS5.fam ... done.\n\n\n\n\nMerging datasets and performing MDS\nBefore merging the HapMap and 1000 Genomes datasets, we ensure compatibility through 3 steps:\n\nVerify the reference genome is compatible in both datasets.\nAlign SNP orientations (strand) across datasets.\nRemove SNPs that still differ after these steps.\n\nThe next steps are technical but ensure the datasets correspond correctly.\n1. We’ve matched SNP positions, but we also need to ensure the reference alleles align. Remember that most PLINK analyses consider the A1 allele (typically the minor allele) as the reference allele, which is logical when dealing exclusively with biallelic variants.\nBelow, we generate a list of SNPs ID and ‘reference alleles’ (corresponding to A1, column 5 of the .bim file) from 1000GP.\n\n#Extract variant coordinates and reference alleles from 1000GP data\nawk '{print$2,$5}' Results/GWAS4/1kG_MDS5.bim &gt; Results/GWAS4/1kg_ref-list.txt\n\nHow the list looks like:\n\nhead -5 Results/GWAS4/1kg_ref-list.txt\n\nrs3131969 A\nrs12562034 A\nrs4970383 A\nrs4475691 T\nrs1806509 A\n\n\nThen, we assign them to the HapMap data --ref-allele option. Note a lot fo warnings in A1 allele assignment. This is usually because you have a strand issue, where the data uses a complement\n\nplink --bfile Results/GWAS4/HapMap_MDS  \\\n    --make-bed \\\n    --reference-allele Results/GWAS4/1kg_ref-list.txt  \\\n    --out Results/GWAS4/HapMap-adj \n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/HapMap-adj.log.\nOptions in effect:\n  --a1-allele Results/GWAS4/1kg_ref-list.txt\n  --bfile Results/GWAS4/HapMap_MDS\n  --make-bed\n  --out Results/GWAS4/HapMap-adj\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n376560 variants loaded from .bim file.\n109 people (55 males, 54 females) loaded from .fam.\n109 phenotype values loaded from .fam.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 109 founders and 0 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998017.\nWarning: Impossible A1 allele assignment for variant rs11488462.\nWarning: Impossible A1 allele assignment for variant rs28635343.\nWarning: Impossible A1 allele assignment for variant rs28456011.\nWarning: Impossible A1 allele assignment for variant rs28487995.\nWarning: Impossible A1 allele assignment for variant rs760925.\nWarning: Impossible A1 allele assignment for variant rs2234167.\nWarning: Impossible A1 allele assignment for variant rs35383955.\nWarning: Impossible A1 allele assignment for variant rs34283457.\nWarning: Impossible A1 allele assignment for variant rs35357981.\nWarning: Impossible A1 allele assignment for variant rs35025175.\nWarning: Impossible A1 allele assignment for variant rs35974482.\nWarning: Impossible A1 allele assignment for variant rs34835780.\nWarning: Impossible A1 allele assignment for variant rs10753374.\nWarning: Impossible A1 allele assignment for variant rs11260657.\nWarning: Impossible A1 allele assignment for variant rs4661727.\nWarning: Impossible A1 allele assignment for variant rs35614701.\nWarning: Impossible A1 allele assignment for variant rs34131388.\nWarning: Impossible A1 allele assignment for variant rs35260034.\nWarning: Impossible A1 allele assignment for variant rs34201264.\nWarning: Impossible A1 allele assignment for variant rs34734086.\nWarning: Impossible A1 allele assignment for variant rs35593799.\nWarning: Impossible A1 allele assignment for variant rs35047308.\nWarning: Impossible A1 allele assignment for variant rs36053581.\nWarning: Impossible A1 allele assignment for variant rs34405972.\nWarning: Impossible A1 allele assignment for variant rs35294772.\nWarning: Impossible A1 allele assignment for variant rs12118489.\nWarning: Impossible A1 allele assignment for variant rs1023098.\nWarning: Impossible A1 allele assignment for variant rs209603.\nWarning: Impossible A1 allele assignment for variant rs10524.\nWarning: Impossible A1 allele assignment for variant rs697594.\nWarning: Impossible A1 allele assignment for variant rs1889603.\nWarning: Impossible A1 allele assignment for variant rs12145114.\nWarning: Impossible A1 allele assignment for variant rs2391154.\nWarning: Impossible A1 allele assignment for variant rs17123142.\nWarning: Impossible A1 allele assignment for variant rs12125356.\nWarning: Impossible A1 allele assignment for variant rs3765501.\nWarning: Impossible A1 allele assignment for variant rs1011297.\nWarning: Impossible A1 allele assignment for variant rs34444588.\nWarning: Impossible A1 allele assignment for variant rs509587.\nWarning: Impossible A1 allele assignment for variant rs17701857.\nWarning: Impossible A1 allele assignment for variant rs3795743.\nWarning: Impossible A1 allele assignment for variant rs34158997.\nWarning: Impossible A1 allele assignment for variant rs35808016.\nWarning: Impossible A1 allele assignment for variant rs34187970.\nWarning: Impossible A1 allele assignment for variant rs3820624.\nWarning: Impossible A1 allele assignment for variant rs2897454.\nWarning: Impossible A1 allele assignment for variant rs1127975.\nWarning: Impossible A1 allele assignment for variant rs35729322.\nWarning: Impossible A1 allele assignment for variant rs35565142.\nWarning: Impossible A1 allele assignment for variant rs3007405.\nWarning: Impossible A1 allele assignment for variant rs11553746.\nWarning: Impossible A1 allele assignment for variant rs1384491.\nWarning: Impossible A1 allele assignment for variant rs17045393.\nWarning: Impossible A1 allele assignment for variant rs6545238.\nWarning: Impossible A1 allele assignment for variant rs17792521.\nWarning: Impossible A1 allele assignment for variant rs989586.\nWarning: Impossible A1 allele assignment for variant rs7558635.\nWarning: Impossible A1 allele assignment for variant rs1139829.\nWarning: Impossible A1 allele assignment for variant rs35061433.\nWarning: Impossible A1 allele assignment for variant rs838069.\nWarning: Impossible A1 allele assignment for variant rs967381.\nWarning: Impossible A1 allele assignment for variant rs2138486.\nWarning: Impossible A1 allele assignment for variant rs13393016.\nWarning: Impossible A1 allele assignment for variant rs17180544.\nWarning: Impossible A1 allele assignment for variant rs13417895.\nWarning: Impossible A1 allele assignment for variant rs12467878.\nWarning: Impossible A1 allele assignment for variant rs6726184.\nWarning: Impossible A1 allele assignment for variant rs4973697.\nWarning: Impossible A1 allele assignment for variant rs6605267.\nWarning: Impossible A1 allele assignment for variant rs7421596.\nWarning: Impossible A1 allele assignment for variant rs1689581.\nWarning: Impossible A1 allele assignment for variant rs711730.\nWarning: Impossible A1 allele assignment for variant rs7652667.\nWarning: Impossible A1 allele assignment for variant rs9864701.\nWarning: Impossible A1 allele assignment for variant rs1522553.\nWarning: Impossible A1 allele assignment for variant rs17280613.\nWarning: Impossible A1 allele assignment for variant rs277646.\nWarning: Impossible A1 allele assignment for variant rs1259321.\nWarning: Impossible A1 allele assignment for variant rs6765489.\nWarning: Impossible A1 allele assignment for variant rs1113277.\nWarning: Impossible A1 allele assignment for variant rs9880098.\nWarning: Impossible A1 allele assignment for variant rs7611483.\nWarning: Impossible A1 allele assignment for variant rs10936388.\nWarning: Impossible A1 allele assignment for variant rs11546878.\nWarning: Impossible A1 allele assignment for variant rs4686566.\nWarning: Impossible A1 allele assignment for variant rs884309.\nWarning: Impossible A1 allele assignment for variant rs3806620.\nWarning: Impossible A1 allele assignment for variant rs6801044.\nWarning: Impossible A1 allele assignment for variant rs4677689.\nWarning: Impossible A1 allele assignment for variant rs4677695.\nWarning: Impossible A1 allele assignment for variant rs9820715.\nWarning: Impossible A1 allele assignment for variant rs35840880.\nWarning: Impossible A1 allele assignment for variant rs6847677.\nWarning: Impossible A1 allele assignment for variant rs16854250.\nWarning: Impossible A1 allele assignment for variant rs12646999.\nWarning: Impossible A1 allele assignment for variant rs13128530.\nWarning: Impossible A1 allele assignment for variant rs2949614.\nWarning: Impossible A1 allele assignment for variant rs17007758.\nWarning: Impossible A1 allele assignment for variant rs10006274.\nWarning: Impossible A1 allele assignment for variant rs4691482.\nWarning: Impossible A1 allele assignment for variant rs1215429.\nWarning: Impossible A1 allele assignment for variant rs1395093.\nWarning: Impossible A1 allele assignment for variant rs2972819.\nWarning: Impossible A1 allele assignment for variant rs199361.\nWarning: Impossible A1 allele assignment for variant rs4403186.\nWarning: Impossible A1 allele assignment for variant rs1574436.\nWarning: Impossible A1 allele assignment for variant rs1048944.\nWarning: Impossible A1 allele assignment for variant rs4704197.\nWarning: Impossible A1 allele assignment for variant rs173545.\nWarning: Impossible A1 allele assignment for variant rs2060424.\nWarning: Impossible A1 allele assignment for variant rs449359.\nWarning: Impossible A1 allele assignment for variant rs11746705.\nWarning: Impossible A1 allele assignment for variant rs7448017.\nWarning: Impossible A1 allele assignment for variant rs1465686.\nWarning: Impossible A1 allele assignment for variant rs13180237.\nWarning: Impossible A1 allele assignment for variant rs17776554.\nWarning: Impossible A1 allele assignment for variant rs266000.\nWarning: Impossible A1 allele assignment for variant rs4868581.\nWarning: Impossible A1 allele assignment for variant rs4710897.\nWarning: Impossible A1 allele assignment for variant rs9461653.\nWarning: Impossible A1 allele assignment for variant rs1129765.\nWarning: Impossible A1 allele assignment for variant rs1694112.\nWarning: Impossible A1 allele assignment for variant rs12207915.\nWarning: Impossible A1 allele assignment for variant rs1383266.\nWarning: Impossible A1 allele assignment for variant rs4565302.\nWarning: Impossible A1 allele assignment for variant rs970392.\nWarning: Impossible A1 allele assignment for variant rs17183312.\nWarning: Impossible A1 allele assignment for variant rs2075967.\nWarning: Impossible A1 allele assignment for variant rs3757212.\nWarning: Impossible A1 allele assignment for variant rs573684.\nWarning: Impossible A1 allele assignment for variant rs9373596.\nWarning: Impossible A1 allele assignment for variant rs3924019.\nWarning: Impossible A1 allele assignment for variant rs9719226.\nWarning: Impossible A1 allele assignment for variant rs2961253.\nWarning: Impossible A1 allele assignment for variant rs2428430.\nWarning: Impossible A1 allele assignment for variant rs4870666.\nWarning: Impossible A1 allele assignment for variant rs1043987.\nWarning: Impossible A1 allele assignment for variant rs2068338.\nWarning: Impossible A1 allele assignment for variant rs2283017.\nWarning: Impossible A1 allele assignment for variant rs2854541.\nWarning: Impossible A1 allele assignment for variant rs361489.\nWarning: Impossible A1 allele assignment for variant rs2855882.\nWarning: Impossible A1 allele assignment for variant rs2734060.\nWarning: Impossible A1 allele assignment for variant rs2244520.\nWarning: Impossible A1 allele assignment for variant rs1573618.\nWarning: Impossible A1 allele assignment for variant rs2855914.\nWarning: Impossible A1 allele assignment for variant rs2734112.\nWarning: Impossible A1 allele assignment for variant rs2367191.\nWarning: Impossible A1 allele assignment for variant rs2855920.\nWarning: Impossible A1 allele assignment for variant rs2855929.\nWarning: Impossible A1 allele assignment for variant rs6961143.\nWarning: Impossible A1 allele assignment for variant rs17231.\nWarning: Impossible A1 allele assignment for variant rs6979421.\nWarning: Impossible A1 allele assignment for variant rs17163237.\nWarning: Impossible A1 allele assignment for variant rs1008660.\nWarning: Impossible A1 allele assignment for variant rs17250.\nWarning: Impossible A1 allele assignment for variant rs2156940.\nWarning: Impossible A1 allele assignment for variant rs11768792.\nWarning: Impossible A1 allele assignment for variant rs17277.\nWarning: Impossible A1 allele assignment for variant rs17279.\nWarning: Impossible A1 allele assignment for variant rs2734171.\nWarning: Impossible A1 allele assignment for variant rs6979469.\nWarning: Impossible A1 allele assignment for variant rs2156956.\nWarning: Impossible A1 allele assignment for variant rs6943682.\nWarning: Impossible A1 allele assignment for variant rs926044.\nWarning: Impossible A1 allele assignment for variant rs6971657.\nWarning: Impossible A1 allele assignment for variant rs6942393.\nWarning: Impossible A1 allele assignment for variant rs1134309.\nWarning: Impossible A1 allele assignment for variant rs17835147.\nWarning: Impossible A1 allele assignment for variant rs1114856.\nWarning: Impossible A1 allele assignment for variant rs10088098.\nWarning: Impossible A1 allele assignment for variant rs11780139.\nWarning: Impossible A1 allele assignment for variant rs39767.\nWarning: Impossible A1 allele assignment for variant rs1027623.\nWarning: Impossible A1 allele assignment for variant rs1545909.\nWarning: Impossible A1 allele assignment for variant rs3800829.\nWarning: Impossible A1 allele assignment for variant rs7856222.\nWarning: Impossible A1 allele assignment for variant rs3808902.\nWarning: Impossible A1 allele assignment for variant rs17269854.\nWarning: Impossible A1 allele assignment for variant rs534721.\nWarning: Impossible A1 allele assignment for variant rs11139569.\nWarning: Impossible A1 allele assignment for variant rs16908089.\nWarning: Impossible A1 allele assignment for variant rs2245389.\nWarning: Impossible A1 allele assignment for variant rs34312136.\nWarning: Impossible A1 allele assignment for variant rs4078122.\nWarning: Impossible A1 allele assignment for variant rs3207775.\nWarning: Impossible A1 allele assignment for variant rs561415.\nWarning: Impossible A1 allele assignment for variant rs11813861.\nWarning: Impossible A1 allele assignment for variant rs1650166.\nWarning: Impossible A1 allele assignment for variant rs11196005.\nWarning: Impossible A1 allele assignment for variant rs12243523.\nWarning: Impossible A1 allele assignment for variant rs7100377.\nWarning: Impossible A1 allele assignment for variant rs12415539.\nWarning: Impossible A1 allele assignment for variant rs2273748.\nWarning: Impossible A1 allele assignment for variant rs5030779.\nWarning: Impossible A1 allele assignment for variant rs516761.\nWarning: Impossible A1 allele assignment for variant rs234872.\nWarning: Impossible A1 allele assignment for variant rs7107290.\nWarning: Impossible A1 allele assignment for variant rs4287314.\nWarning: Impossible A1 allele assignment for variant rs10501259.\nWarning: Impossible A1 allele assignment for variant rs4756057.\nWarning: Impossible A1 allele assignment for variant rs1044796.\nWarning: Impossible A1 allele assignment for variant rs17507049.\nWarning: Impossible A1 allele assignment for variant rs661124.\nWarning: Impossible A1 allele assignment for variant rs1894080.\nWarning: Impossible A1 allele assignment for variant rs2324509.\nWarning: Impossible A1 allele assignment for variant rs4936260.\nWarning: Impossible A1 allele assignment for variant rs11524965.\nWarning: Impossible A1 allele assignment for variant rs2159347.\nWarning: Impossible A1 allele assignment for variant rs3782598.\nWarning: Impossible A1 allele assignment for variant rs1451772.\nWarning: Impossible A1 allele assignment for variant rs10505915.\nWarning: Impossible A1 allele assignment for variant rs3782514.\nWarning: Impossible A1 allele assignment for variant rs10772153.\nWarning: Impossible A1 allele assignment for variant rs2372379.\nWarning: Impossible A1 allele assignment for variant rs803569.\nWarning: Impossible A1 allele assignment for variant rs2279405.\nWarning: Impossible A1 allele assignment for variant rs6633.\nWarning: Impossible A1 allele assignment for variant rs7957839.\nWarning: Impossible A1 allele assignment for variant rs1413155.\nWarning: Impossible A1 allele assignment for variant rs9300901.\nWarning: Impossible A1 allele assignment for variant rs9604511.\nWarning: Impossible A1 allele assignment for variant rs7996853.\nWarning: Impossible A1 allele assignment for variant rs7399982.\nWarning: Impossible A1 allele assignment for variant rs9604529.\nWarning: Impossible A1 allele assignment for variant rs11259844.\nWarning: Impossible A1 allele assignment for variant rs11618091.\nWarning: Impossible A1 allele assignment for variant rs6602901.\nWarning: Impossible A1 allele assignment for variant rs9577914.\nWarning: Impossible A1 allele assignment for variant rs9604566.\nWarning: Impossible A1 allele assignment for variant rs7323426.\nWarning: Impossible A1 allele assignment for variant rs6602905.\nWarning: Impossible A1 allele assignment for variant rs7323932.\nWarning: Impossible A1 allele assignment for variant rs7996145.\nWarning: Impossible A1 allele assignment for variant rs7332546.\nWarning: Impossible A1 allele assignment for variant rs9550238.\nWarning: Impossible A1 allele assignment for variant rs7400267.\nWarning: Impossible A1 allele assignment for variant rs6602894.\nWarning: Impossible A1 allele assignment for variant rs7399469.\nWarning: Impossible A1 allele assignment for variant rs6602895.\nWarning: Impossible A1 allele assignment for variant rs6422414.\nWarning: Impossible A1 allele assignment for variant rs7335819.\nWarning: Impossible A1 allele assignment for variant rs13379029.\nWarning: Impossible A1 allele assignment for variant rs4147557.\nWarning: Impossible A1 allele assignment for variant rs10483432.\nWarning: Impossible A1 allele assignment for variant rs11627089.\nWarning: Impossible A1 allele assignment for variant rs17597295.\nWarning: Impossible A1 allele assignment for variant rs12793.\nWarning: Impossible A1 allele assignment for variant rs1744296.\nWarning: Impossible A1 allele assignment for variant rs4983517.\nWarning: Impossible A1 allele assignment for variant rs8034978.\nWarning: Impossible A1 allele assignment for variant rs3809581.\nWarning: Impossible A1 allele assignment for variant rs10519208.\nWarning: Impossible A1 allele assignment for variant rs3087567.\nWarning: Impossible A1 allele assignment for variant rs2107234.\nWarning: Impossible A1 allele assignment for variant rs252304.\nWarning: Impossible A1 allele assignment for variant rs8061401.\nWarning: Impossible A1 allele assignment for variant rs13337562.\nWarning: Impossible A1 allele assignment for variant rs28437095.\nWarning: Impossible A1 allele assignment for variant rs9928892.\nWarning: Impossible A1 allele assignment for variant rs1048149.\nWarning: Impossible A1 allele assignment for variant rs2306270.\nWarning: Impossible A1 allele assignment for variant rs764688.\nWarning: Impossible A1 allele assignment for variant rs3764420.\nWarning: Impossible A1 allele assignment for variant rs7210126.\nWarning: Impossible A1 allele assignment for variant rs17673149.\nWarning: Impossible A1 allele assignment for variant rs11868321.\nWarning: Impossible A1 allele assignment for variant rs1042678.\nWarning: Impossible A1 allele assignment for variant rs3744155.\nWarning: Impossible A1 allele assignment for variant rs16942082.\nWarning: Impossible A1 allele assignment for variant rs9973085.\nWarning: Impossible A1 allele assignment for variant rs11080748.\nWarning: Impossible A1 allele assignment for variant rs355311.\nWarning: Impossible A1 allele assignment for variant rs3826608.\nWarning: Impossible A1 allele assignment for variant rs10502668.\nWarning: Impossible A1 allele assignment for variant rs4919838.\nWarning: Impossible A1 allele assignment for variant rs4523.\nWarning: Impossible A1 allele assignment for variant rs11085099.\nWarning: Impossible A1 allele assignment for variant rs3093088.\nWarning: Impossible A1 allele assignment for variant rs14129.\nWarning: Impossible A1 allele assignment for variant rs8100232.\nWarning: Impossible A1 allele assignment for variant rs8109833.\nWarning: Impossible A1 allele assignment for variant rs430989.\nWarning: Impossible A1 allele assignment for variant rs3760667.\nWarning: Impossible A1 allele assignment for variant rs3187346.\nWarning: Impossible A1 allele assignment for variant rs2286750.\nWarning: Impossible A1 allele assignment for variant rs6110212.\nWarning: Impossible A1 allele assignment for variant rs3746600.\nWarning: Impossible A1 allele assignment for variant rs3761210.\nWarning: Impossible A1 allele assignment for variant rs17001274.\nWarning: Impossible A1 allele assignment for variant rs17114359.\nWarning: Impossible A1 allele assignment for variant rs3788014.\nWarning: Impossible A1 allele assignment for variant rs35829851.\nWarning: Impossible A1 allele assignment for variant rs2268780.\nWarning: Impossible A1 allele assignment for variant rs4820280.\nWarning: Impossible A1 allele assignment for variant rs9611591.\nWarning: Impossible A1 allele assignment for variant rs34420568.\nWarning: Impossible A1 allele assignment for variant rs9614750.\nWarning: Impossible A1 allele assignment for variant rs34315830.\nWarning: Impossible A1 allele assignment for variant rs5767487.\nWarning: Impossible A1 allele assignment for variant rs35812349.\n--a1-allele: 376560 assignments made.\n376560 variants and 109 people pass filters and QC.\nAmong remaining phenotypes, 54 are cases and 55 are controls.\n--make-bed to Results/GWAS4/HapMap-adj.bed + Results/GWAS4/HapMap-adj.bim +\nResults/GWAS4/HapMap-adj.fam ... done.\n\n\n2. To resolve strand issues, we flip SNPs found in both datasets with complementary alleles (i.e. they were reported in opposite strands). We generate SNP lists (ID and alleles) for both datasets, identify unique SNPs, and visualize differences in allele reporting. If a SNP is unique but reports alleles differently, it will appear twice. Below are examples of SNPs with strand issues from the 1000GP and HapMap data:\n\n#print SNP and A1 A2 alleles on files for the two datasets\nawk '{print$2,$5,$6}' Results/GWAS4/1kG_MDS5.bim &gt; Results/GWAS4/1kGMDS5_tmp\nawk '{print$2,$5,$6}' Results/GWAS4/HapMap-adj.bim &gt; Results/GWAS4/HapMap-adj_tmp\n\n#sort by SNP name to see SNPs with complementary alleles\nsort Results/GWAS4/1kGMDS5_tmp Results/GWAS4/HapMap-adj_tmp | uniq -u &gt; Results/GWAS4/all_differences.txt\n\n\nhead -6 Results/GWAS4/all_differences.txt\n\nrs10006274 C T\nrs10006274 G A\nrs1008660 A G\nrs1008660 T C\nrs10088098 C T\nrs10088098 G A\n\n\nHow many of these differences are there? We can count 604 lines, so 302 SNPs\n\nwc -l Results/GWAS4/all_differences.txt\n\n604 Results/GWAS4/all_differences.txt\n\n\nSome of these differences might be might be due to strand issues.\nLet’s look at this variant rs10006274. Will it be flipped in the HapMap dataset?\nThe answer is yes! If we look at the reference allele in 1kg_ref-list.txt, it shows C. This means the SNP is on the forward strand in 1000GP (C/T) and on the reverse strand in HapMap (G/A).\n\ngrep rs10006274 Results/GWAS4/1kg_ref-list.txt\n\nrs10006274 C\n\n\n\ngrep rs10006274 Results/GWAS4/all_differences.txt\n\nrs10006274 C T\nrs10006274 G A\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nLook at these other SNPs: rs9614750 and rs10088098.\n\nWhich ones will have to be flipped?\nIs it always the same dataset that must be flipped?\n\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe will first print out the SNPs from the reference file to know which line corresponds to each dataset (since we know we used the 1000 Genomes Project as the reference). If there are strand issues, the SNP will need to be flipped in the dataset that wasn’t used as the reference.\n\ngrep rs9614750 Results/GWAS4/1kg_ref-list.txt \n\nrs9614750 A\n\n\n\ngrep rs9614750 Results/GWAS4/all_differences.txt\n\nrs9614750 A G\nrs9614750 C G\n\n\nFor rs9614750, the genotype is reported as A/G in the 1000GP data, while in HapMap, it is C/G. This discrepancy between the two datasets means that the SNP will need to be removed later.\n\ngrep rs10088098 Results/GWAS4/1kg_ref-list.txt \n\nrs10088098 C\n\n\n\ngrep rs10088098 Results/GWAS4/all_differences.txt\n\nrs10088098 C T\nrs10088098 G A\n\n\nFor rs10088098, the genotype is reported as C/T in the 1000GP data, while in HapMap, it is G/A. This means that PLINK will flip the allele, as they are complementary.\n\n\n\n\nNow we take only the SNP names and give them to PLINK (option --flip), together with the reference genome (option --reference-allele):\n\n## Flip SNPs for resolving strand issues.\n# Print SNP-identifier and remove duplicates.\nawk '{print$1}' Results/GWAS4/all_differences.txt | sort -u &gt; Results/GWAS4/flip_list.txt\n\n\nwc -l Results/GWAS4/flip_list.txt\n\n302 Results/GWAS4/flip_list.txt\n\n\nThese are the SNP ID of non-corresponding SNPs (N=302) between the two files.\n\nhead -5 Results/GWAS4/flip_list.txt\n\nrs10006274\nrs1008660\nrs10088098\nrs1011297\nrs1023098\n\n\nApply the flipping option:\n\nplink --bfile Results/GWAS4/HapMap-adj \\\n    --flip Results/GWAS4/flip_list.txt \\\n    --reference-allele Results/GWAS4/1kg_ref-list.txt \\\n    --make-bed \\\n    --out Results/GWAS4/corrected_hapmap \\\n    --silent\n\nWarning: Impossible A1 allele assignment for variant rs2581195.\nWarning: Impossible A1 allele assignment for variant rs9614750.\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThere might still be problematic SNPs after flipping.\n\nCheck if the expected allele flip occurred.\n\nHint: use grep to find the rs10006274 and rs9614750 variants; then compare the alleles assignments in the HapMap file before and after flipping.\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nPLINK attempts to flip all SNPs in the list, but an error occurs when A1 does not match the one in the reference.\nNotice how this SNP has changed as we predicted:\n\ngrep rs10006274 Results/GWAS4/corrected_hapmap.bim\n\n4   rs10006274  0   124165369   C   T\n\n\n\ngrep rs10006274 Results/GWAS4/HapMap-adj.bim\n\n4   rs10006274  0   124165369   G   A\n\n\nrs10006274 was flipped and has the same strand orientation in both datasets (same alleles in A1 and A2).\nWhat happened to this one? PLINK attempts to resolve the mismatch by flipping the alleles but throws an error because the complementary alleles do not match the reference!\n\ngrep rs9614750 Results/GWAS4/corrected_hapmap.bim\n\n22  rs9614750   0   44436371    G   C\n\n\n\ngrep rs9614750 Results/GWAS4/HapMap-adj.bim\n\n22  rs9614750   0   44436371    C   G\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t need to flip the 1000GP data because the reference allele (A1) in the 1000GP data already matches the strand orientation used in the HapMap data.\n\n\n3. After flipping SNPs, some differ in their alleles when comparing datasets to each other (e.g. SNP rs9614750) and such SNPs must be removed.\nWe extract the SNPs from the corrected HapMap data and search for unique SNP (ID, A1, and A2), comparing them with those from the 1000GP data.\n\nawk '{print$2,$5,$6}' Results/GWAS4/corrected_hapmap.bim &gt; Results/GWAS4/corrected_hapmap_tmp\n\nsort Results/GWAS4/1kGMDS5_tmp Results/GWAS4/corrected_hapmap_tmp | uniq -u  &gt; Results/GWAS4/uncorresponding_SNPs.txt\n\nHow many SNP mismatches are there?\n\nwc -l Results/GWAS4/uncorresponding_SNPs.txt\n\n24 Results/GWAS4/uncorresponding_SNPs.txt\n\n\nThis corresponds to 12 unique SNP IDs with mismatched information.\n\nhead Results/GWAS4/uncorresponding_SNPs.txt \n\nrs11524965 T C\nrs11524965 T G\nrs12646999 G A\nrs12646999 G T\nrs17114359 C A\nrs17114359 C T\nrs17269854 C A\nrs17269854 C T\nrs2060424 G A\nrs2060424 G C\n\n\nWe extract again the SNP IDs from the file above, and exclude them using the PLINK option --exclude in both datasets\n\nawk '{print$1}' Results/GWAS4/uncorresponding_SNPs.txt | sort -u &gt; Results/GWAS4/SNPs_for_exclusion.txt\n\nplink --bfile Results/GWAS4/corrected_hapmap \\\n    --exclude Results/GWAS4/SNPs_for_exclusion.txt \\\n    --make-bed \\\n    --out Results/GWAS4/HapMap_MDS3 \\\n    --silent\nplink --bfile Results/GWAS4/1kG_MDS5 \\\n    --exclude Results/GWAS4/SNPs_for_exclusion.txt \\\n    --make-bed \\\n    --out Results/GWAS4/1kG_MDS6 \\\n    --silent\n\n5. We can finally merge the data! We provide our dataset (-bfile) and the one to add (--bmerge option):\n\nplink --bfile Results/GWAS4/corrected_hapmap \\\n    --bmerge Results/GWAS4/1kG_MDS6.bed Results/GWAS4/1kG_MDS6.bim Results/GWAS4/1kG_MDS6.fam \\\n    --allow-no-sex \\\n    --make-bed \\\n    --out Results/GWAS4/MDS_merge \\\n    --silent\n\n\n\n\nPerform MDS on HapMap-CEU data anchored by 1000 Genomes data.\nMDS is typically performed on independent SNPs (pruned SNPs). We have previously identified such SNPs in this course, so we will extract only these SNPs for the analysis.\n\nplink --bfile Results/GWAS4/MDS_merge \\\n    --extract Results/GWAS3/indepSNP.prune.in \\\n    --genome \\\n    --out Results/GWAS4/MDS_merge \\\n    --silent\n\nNow, we can use PLINK to run MDS with the option ---mds-plot specifying the number of components to calculate.\n\n# mds-plot\nplink --bfile Results/GWAS4/MDS_merge \\\n    --read-genome Results/GWAS4/MDS_merge.genome \\\n    --cluster \\\n    --mds-plot 10 \\\n    --out Results/GWAS4/MDS_merge \\\n    --silent\n\nFor visualization purposes, we downloaded the 1000 Genomes Project (1000GP) panel, which includes individual names and their corresponding population information.\n\nwget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/20100804.ALL.panel -P Results/GWAS4 -q\n\nTo determine the population origins of HapMap individuals, we created a new file that combines the 1000GP panel information with the HapMap data, labeling the population HapMap entries as ‘OWN’.\n\nawk '{print$1,$2,\"OWN\"}' Results/GWAS4/HapMap_MDS.fam &gt; Results/GWAS4/popfile_own.txt\nawk '{print$1,$1,$2}' Results/GWAS4/20100804.ALL.panel &gt; Results/GWAS4/20100804.ALL.panel.txt\n\ncat &lt;(echo \"FID IID POP\") Results/GWAS4/20100804.ALL.panel.txt Results/GWAS4/popfile_own.txt &gt; Results/GWAS4/popfile.txt\n\n\n\n\n\n\n\nNote\n\n\n\nThe 1000 Genomes Project (1000GP) categorizes individuals into major continental groups—such as Europeans (EUR), Africans (AFR), Americans (AMR), East Asians (EAS), and South Asians (SAS)—each comprising various subpopulations. We will use this population structure information to visualize and determine the clusters our samples belong to.\n\n\n\n Switch to the R kernel.\nLet’s visualize population stratification using the multidimensional scaling (MDS) results.\n\noptions(repr.plot.width = 12, repr.plot.height = 6)\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\n# Read data into R \ndata &lt;- read.table(file=\"Results/GWAS4/MDS_merge.mds\",header=TRUE)\npop &lt;- read.table(file=\"Results/GWAS4/popfile.txt\",header=TRUE)\ndatafile &lt;- merge(data,pop,by=c(\"FID\",\"IID\"))\n\n# Metapopulation information for the population in the 1000GP dataset\nsuperpop &lt;- c(\n  \"JPT\" = \"ASN\",\n  \"ASW\" = \"AFR\",\n  \"CEU\" = \"EUR\",\n  \"CHB\" = \"ASN\",\n  \"CHD\" = \"ASN\",\n  \"YRI\" = \"AFR\",\n  \"LWK\" = \"AFR\",\n  \"TSI\" = \"EUR\",\n  \"MXL\" = \"AMR\",\n  \"GBR\" = \"EUR\",\n  \"FIN\" = \"EUR\",\n  \"CHS\" = \"ASN\",\n  \"PUR\" = \"AMR\",\n  \"OWN\" = \"UN\"\n)\n\n# add metapopulation info to the table \ndatafile$SUPERPOP &lt;- superpop[datafile$POP]\n\n# Plotting                \nscatter.mds &lt;- ggplot(datafile, aes(x=C1, y=C2, color=SUPERPOP)) +\n  geom_point(size=5, alpha=.4) +\n  scale_color_manual(values=c(\"AFR\" = \"red\", \"AMR\" = \"springgreen4\", \"ASN\" = \"gold\", \"EUR\" = \"blue\", \"UN\" = \"grey\" )) +\n  xlab(\"MD Component 1\") + \n  ylab(\"MD Component 2\") +\n  labs(color=\"Superpop\") +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), legend.text = element_text(size = 15), \n        axis.text = element_text(size = 14), legend.title=element_text(size=15))\n  \nshow(scatter.mds)\n\n\n\n\n\n\n\n\nThe HapMap data clusters closely with European populations such as CEU, TSI, IBS, GBR, and FIN, confirming its European composition. Additionally, the absence of distant points indicates no outliers in the HapMap dataset (grey datapoints cluster together).\n\nExclude ethnic outliers\nLet’s run the scripts to filter population stratification outliers for educational purposes (e.g. imagine a HapMap individual clusters in the lower-right corner with African populations).\n Switch to the Bash kernel.\nTo identify and exclude ethnic outliers in the HapMap dataset, select individuals falling within specific cut-off thresholds. These thresholds should be determined based on the visualization of the first two dimensions from the multidimensional scaling (MDS) analysis.\nWhat values would you select or apply in this context, and why? Hint: look at the plot above.\nPreview of the MDS results:\n\nhead -3 Results/GWAS4/MDS_merge.mds | cut -f1-6 -d$'\\t'\n\n    FID       IID    SOL           C1           C2           C3           C4           C5           C6           C7           C8           C9          C10 \n   1328   NA06984      0   -0.0218368  -0.00620683  -0.00464884   0.00121512 -0.000413235   0.00221093    0.0104188  -0.00199382    0.0173257   -0.0131241 \n   1328   NA06989      0   -0.0208157  -0.00581126  -0.00638572   0.00503345  -0.00116741  -0.00369152    0.0120005   -0.0229035  -0.00238946    0.0381386 \n\n\nBased on the position of the target population’s cluster in the MDS plot, we will exclude individuals with MDS component 1 values less than 0 and MDS component 2 values less than -0.05.\nThe selection has to be done for the individuals we want to keep, so the area to be chosen has to be mirrored into &gt;0 and &gt;-0.05. We provide the MDS component values in columns 4 and 5 of the file (corresponding to the first 2 components), and extract the individuals using --keep\n\nawk '{ if ($4 &gt;0 || $5 &gt;-0.05) print $1,$2 }' Results/GWAS4/MDS_merge.mds &gt; Results/GWAS4/EUR_MDS_merge\n\nplink --bfile Results/GWAS4/HapMap_3_r3_9 \\\n    --keep Results/GWAS4/EUR_MDS_merge \\\n    --make-bed  \\\n    --out Results/GWAS4/HapMap_3_r3_10 \\\n    --silent\n\n\n\nCreating covariates for GWAS analysis\nThe 10 MDS dimensions will be used as covariates in the association analysis in the next tutorial to correct for population stratification. The covariate file is created by removing column 3 (SOL, optional metadata) from the MDS output file.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nWhy are we computing the covariates again?\n\n\n\nplink --bfile Results/GWAS4/HapMap_3_r3_10 \\\n    --extract Results/GWAS3/indepSNP.prune.in \\\n    --genome  \\\n    --out Results/GWAS4/HapMap_3_r3_10 \\\n    --silent\nplink --bfile Results/GWAS4/HapMap_3_r3_10 \\\n    --read-genome Results/GWAS4/HapMap_3_r3_10.genome \\\n    --cluster \\\n    --mds-plot 10 \\\n    --out Results/GWAS4/HapMap_3_r3_10_mds \\\n    --silent\n\n# Change the format of the .mds file into a plink covariate file.\nawk '{print $1, $2, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13}' Results/GWAS4/HapMap_3_r3_10_mds.mds &gt; Results/GWAS4/covar_mds.txt\n\nThe covar_mds.txt file contains the covariates to adjust for residual population stratification.\n\nhead -5 Results/GWAS4/covar_mds.txt\n\nFID IID C1 C2 C3 C4 C5 C6 C7 C8 C9 C10\n1328 NA06989 0.0193503 -0.0481539 0.053743 -8.56966e-05 0.0124037 -0.00872553 0.0146577 -0.0266013 0.0064429 -0.0149862\n1377 NA11891 0.0105154 -0.0241653 -0.00713715 -0.0276522 0.0272997 0.0044621 -0.00373271 -0.00561896 -0.0317101 0.0188078\n1349 NA11843 -0.00217144 0.0120046 -0.00508388 0.0193558 -0.00738542 0.0285001 -0.00512723 0.00271516 0.0029428 0.000145191\n1330 NA12341 -0.0124555 -0.0114929 0.0019162 -0.0252928 -0.0300722 -0.00411769 -0.0207568 -0.0122574 -0.017065 0.0353729\n\n\n\n\n\n\n\n\nWrapping up\n\n\n\nYou have now successfully checked your data for relatedness population stratification. You filtered out the individuals with high relatedness and produced a summary of the population structure using the MDS projection. You will use the MDS coordinates as a proxy for the population structure you want your association testing to be corrected for.\nIn the next notebook on Association Testing, you will need the following files from the folder Results/GWAS4/: - HapMap_3_r3_10 (the bfile, i.e., HapMap_3_r3_10.bed, HapMap_3_r3_10.bim, and HapMap_3_r3_10.fam) - covar_mds.txt which are the HapMap data and the MDS covariates highlighting the population stratification. Those are already available once you have been running this notebook.\nBelow is a cheat sheet of our new methods of QC. Again, it is important to remember that each method of QC should be justified, which will depend on the nature of the feature you are trying to analyze.\n\n\n\n\n\n\n\n\n\nStep\nCommand\nFunction\nThresholds and explanation\n\n\n\n\n6: Relatedness\n–make-king-table (PLINK2)\nCalculates KING kinship of all sample pairs. The KING kinship is more reliable in presence of population structure.\nUse independent SNPs (pruning) for this analysis and limit it to autosomal chromosomes only.\n\n\n-\nawk + –remove\nSets threshold and creates a list of individuals with relatedness above the chosen threshold (awk command). This means that subjects who are related at, for example, KINSHIP &gt; 0.1 (i.e., half siblings, or siblings, or parent-child) can be detected.\nCryptic relatedness can interfere with the association analysis. If you have a family‐based sample (e.g., parent‐offspring), you do not need to remove related pairs but the statistical analysis should take family relatedness into account. However, for a population-based sample, we suggest using a KINSHIP threshold of 0.06, which is in line with the literature using IBD kinship thresholds (Anderson et al., 2010; Guo et al., 2014).\n\n\n7: Population Stratification\n–cluster –mds-plot k\nProduces a k‐dimensional representation of any substructure in the data, based on IBS.\nK is the number of dimensions, which needs to be defined (typically 10). This is an important step of the QC that consists of multiple proceedings but for reasons of completeness, we briefly refer to this step in the table. This step will be described in more detail in the section “Controlling for population stratification.”",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: Relatedness & Population Stratification"
    ]
  },
  {
    "objectID": "access/otherHPC.html",
    "href": "access/otherHPC.html",
    "title": "Independent users",
    "section": "",
    "text": "The app is a Docker image that you can use on a different machine or your own computer. To use it, you should be familiar with Docker/Singularity. Simply pull the image and run the container using the command start-app -c \"Intro-to-GWAS\" (example below).\nLink: https://hub.docker.com/r/hdssandbox/genomicsapp.\n\nPull docker image\n# docker\ndocker pull hdssandbox/genomicsapp\n# singularity\nsingularity pull genomicsapp.sif docker://hdssandbox/genomicsapp \n\n\nRun the container\nYou can customize the port by using the -p option to select a different port for running the application. Additionally, if you already have data and notebooks locally, you can bind them to the container, avoiding the need for any new downloads. The command to run the container with these options looks like this:\n\n--rm: This option removes the container after running, preventing your disk from filling up with cached images.\nAdd -v /path/to/data to bind your local data/notebooks to the container\n\ndocker run -rm -p $PORT:$PORT genomicsapp.sif start-app -c \"Intro_to_GWAS\" -p $PORT\n\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "access/setup.html",
    "href": "access/setup.html",
    "title": "Setup guidelines",
    "section": "",
    "text": "Here, you’ll find the guidelines for using the “Introduction to GWAS” module from our genomics app, developed by the Health Data Science sandbox. We build our training modules as Docker images for easy deployment and use. This Docker container includes course tutorials, datasets, and tools for research or self-learning. The genomics app consists of several modules, with each course item built on JupyterLab. JupyterLab is a web-based integrated development environment for Jupyter notebooks, code, and data.",
    "crumbs": [
      "Access",
      "General"
    ]
  },
  {
    "objectID": "access/setup.html#ucloud",
    "href": "access/setup.html#ucloud",
    "title": "Setup guidelines",
    "section": "UCloud",
    "text": "UCloud\nUCloud is an HPC platform available to researchers and students at Danish universities (via a WAYF university login). It features a user-friendly graphical interface that simplifies project, user, and resource management. UCloud offers access to numerous tools via selectable apps and a variety of flexible compute resources. Check out UCloud’s extensive user docs here. For a more detailed information on navigating UCloud and using our apps, check out the Sandbox guidelines.\nIf you’ve chosen UCloud as your HPC platform to use the Genomics app, follow the steps below.\n\nStep 1\nLog onto UCloud at the address http://cloud.sdu.dk using university credentials.\n\n\nStep 2\nWhen logged in, choose the project from the dashboard (top-right side) from which you would like to utilize compute resources. Every user has their personal workspace (My workspace). You can also provision your own project (check with your local DeiC office if you’re new to UCloud) or you can be invited to someone else’s project. If you’ve previously selected a project, it will be launched by default. If it’s your first time, you’ll be in your workspace.\n\n\nStep 3\nOnce approved as a UCloud user, you will be greeted by a dashboard interface. Here, you can view a summary of your workspace, including computing hours, available storage, and other key details. Your current workspace is displayed in the top-right corner (e.g. Sandbox_workshop). On the left side, a toolbar menu provides navigation options. Our Genomic App offers a pre-configured environment with all necessary installations. However, unless you are participating in one of our workshops, you will need to use your own resources to run the training materials.\n\n\n\nDashboard\n\n\n\n\nStep 4\nThe left-side menu can be used to access the stored data, applications, running programs and settings. Use the Applications symbol (in gray). Search for the Genomics Sandbox application to open its settings.\n\n\n\nStep 5\nChoose any Job Name (#1 in the figure below), how many hours you want to use for the job (#2, choose at least 2 hours, you can increase this later), and how many CPUs (#3, choose at least 4 CPUs for the first three exercises, but use at least 8 CPUs to run the GWAS analysis). Select the Introduction to GWAS as course (#4). Then click on Submit (#5). The App needs to download data and packages which can take some time. See below how to reuse the data and avoid long waiting time (you need however to download data the first time you run the app).\n\n\n\n\n\n\n\nOptional: select a folder from your own drive\n\n\n\nWe suggest creating a folder to store your results and any modifications you make to the notebooks. Click on Add folder. For example, work_gwas.\n\n\nYou will be waiting in a queue looking like this:\n\n\n\nStep 6\nAs soon as there are resources, you will have them available, and in a short time the course will be ready to run. The screen you get is in the image below. Here you can increase the number of hours you want the session to run (Time allocation), close the session (Stop application) and open the interface for coding (Open interface)\n\n\n\n\n\n\n\nTip\n\n\n\nOnce you open the coding interface, it does not matter if you close the browser tab with the countdown timer. You can always access it again from the toolbar menu of UCloud. Simply click on Jobs and choose your session from the list of running softwares.\n\n\nNow you’re ready to use JupyterLab for coding!\n\n\n\n\n\n\nNote\n\n\n\nIf you have mounted your own folder, copy both the notebook and the data folder into it before running any cell.\n\n\nUse the file browser on the left side to locate the Notebooks. Select one of the notebooks—it will open in the right-side panel. Carefully read the instructions and execute each code cell, starting from the first.\nMake sure you have selected the correct kernel before running the cells. You’ll see the results appear directly in the notebook!\n\n\n\nRecovering the material from your previous session\nIt would be annoying to start from scratch at each session, with all the analysis to be executed again. You can use data and notebooks running in a previous session of the App. Otherwise, the app will download the data and the notebooks every time. How can we avoid this?\n\nA. If you copied the folder into your mounted directory, include both folders (“Add folders”) when submitting the job in future runs to maintain your own version of the notebook.\n\n\n\nB. If you didn’t copy the folder, you can still access your version of the notebook. To select data from previous sessions, click “Add folders” and navigate to your latest sandbox session (inside the folder Jobs/Genomics Sandbox under your personal user folder as shown below) and select the folders you need. In this example, accepted folders are Data and Notebooks.",
    "crumbs": [
      "Access",
      "General"
    ]
  },
  {
    "objectID": "access/setup.html#download-the-data-you-generated",
    "href": "access/setup.html#download-the-data-you-generated",
    "title": "Setup guidelines",
    "section": "Download the data you generated",
    "text": "Download the data you generated\nYou can easily download files you generated by right-clicking on selected files in the browser of Jupyterlab, and by choosing download (see figure below).",
    "crumbs": [
      "Access",
      "General"
    ]
  },
  {
    "objectID": "access/setup.html#genomedk",
    "href": "access/setup.html#genomedk",
    "title": "Setup guidelines",
    "section": "GenomeDK",
    "text": "GenomeDK\nYou can run the Genomics sandbox on GenomeDK. Use virtual desktop on your browser at the address desktop.genome.au.dk. First, log into the virtual desktop by filling in name and password for GenomeDK at the webpage desktop.genome.au.dk.\n\n\n\n\n\nTo run the tutorial, you need to be able to use a project folder on GenomeDK. You can go into that folder using the file browser (toolbar at the bottom of the virtual desktop), and create a subfolder to run the material into. You can use the right-click button and choose Create folder (green circle below).\n\n\n\n\n\nNow, right-click inside the create folder and choose Open Terminal Here. You should see a terminal window like below\n\n\n\n\n\nYou need to copy-paste some commands. To copy text from your pc to the virtual desktop, you need to first paste it into the clipboard, which you can open clicking Show clipboard on the top-right corner of the desktop.\n\n\n\n\n\nFirst of all, we need to download the container using singularity. Run this command:\nSINGULARITYENV_OMP_NUM_THREADS=1 singularity pull genomicsapp_latest.sif docker://hdssandbox/genomicsapp\nIt takes time, so be patient.\nNow download the script to run the genomics sandbox\nwget https://raw.githubusercontent.com/hds-sandbox/Genomics_app/refs/heads/main/scripts/chooseCourse.sh?token=GHSAT0AAAAAAC4XE7DM35ZLCCG5SLYNORYYZ7AQ72A\n\nchmod + chooseCourse.sh\nExecute the script and follow the interactive instructions: you need to choose a course, folder with the container, and amount of computing resources.\nbash chooseCourse.sh\nOnce finished, you will start a job on the cluster. When you get through the queue and download all the data (data downloaded only the first time), you will need to open the provided address in the command line (green circle below).",
    "crumbs": [
      "Access",
      "General"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the GWAS tutorial",
    "section": "",
    "text": "Welcome to the GWAS tutorial\n\n\nThis course is an introduction to the method of Genome-Wide Association Studies (GWAS), which quantifies the statistical association between a genetic variant and a phenotype (often on disease traits). This course will not focus on using any particular software, instead explaining why the given analyses are done from a statistical and biological perspective.\n\n\n\n\n\n\nCourse Overview\n\n\n\n\n📖 Syllabus:\n\n\nUnderstand what is a GWAS is and why we use it\n\nStatistics of GWAS (regression coefficients, P-values, statistical power, Bayes factors)\n\nGenetic relatedness and population structure\n\nConfounding and covariates in GWAS\n\nHaplotypes, linkage disequilibrum, imputation, fine-mapping\n\nLinear mixed models and heritability\n\nSummary statistics and meta-analysis\n\nAdvanced tools\n\n\n⏰ Total Time Estimation: 8 hours\n📁 Supporting Materials:\n\nExercises inspired from A tutorial on conducting genome‐wide association studies: Quality control and statistical analysis\nOriginal course from the University of Helsinki\nPLINK documentation\nAn Introduction to Statistical Learning (for further statistics explanations)\n\n👨‍💻 Target Audience: Ph.D., MSc, etc.\n👩‍🎓 Level: Beginner.\nLicense: Tutorial Content is licensed under Creative Commons Attribution 4.0 International License\n\n\n\n\n\n\n\n\n\nCourse Requirements\n\n\n\n\nKnowledge of R. It is recommended that you have at least followed our workshop From Excel to R\nBasic knowledge of bash.\nBasic statistics and mathematics skills\n\n\n\nThis workshop material includes a tutorial on how to run genome-wide association studies and the necessary preprocessing steps. Why are GWAS important?\nThey identify statistical associations between specific regions of the genome and a given phenotype which can:\n\nhelp point to biological mechanisms affecting the phenotype,\n\nallow prediction of the phenotype from genomic information.\n\nThese results may further benefit:\n\nmedicine by leading to molecular or environmental interventions against harmful phenotypes,\n\nbiotechnology by improving the ways we utilize microbes, plants or animals,\n\nforensics by more accurate identification of an individual from a DNA sample,\n\nbiogeographic ancestry inference of individuals, populations and species,\n\nour understanding of the role of natural selection and other evolutionary forces in the living world.\n\nThe genome of an individual remain (nearly) constant throughout the individual’s lifetime. This is a truly remarkable property compared to, e.g., other molecular sources of information (such as metabolomics, metagenomics, transcriptomics, proteomics or epigenomics) or environmental factors that may vary widely across time. Therefore, the genome seems an ideal starting point for scientific research: it needs to be measured only once for an individual and there is no reverse causation from the phenotype to genome (with cancer as an important exception).\n\n\n\n\n\n\nCourse Goals\n\n\n\nBy the end of this workshop, you should be able to:\n\nLearn and explain fundamental population genetics concepts, applying them during data analysis.\nUnderstand the principles of GWAS, including linkage disequilibrium and linear regression, and apply them in practice.\nDevelop skills to preprocess data and perform genotype imputation for missing values.\nExplore, discuss, and replicate basic GWAS applications from the scientific literature.\nInterpret GWAS results critically, recognizing their limitations.\n\n\n\n\nAcknowledgements\n\nCenter for Health Data Science, University of Copenhagen\nMatti Pirinen, PhD, University of Helsinki\nAndries T. Marees, Vrije Universiteit Amsterdam\n\n\n\nCourse instructors\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlba Refoyo Martinez\n\n\nData Scientist, KU\n\n\n\n\n\n\n\n\n\n\n\nSamuele Soraggi\n\n\nData Scientist, AU\n\n\n\n\n\n\n\nNo matching items\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "access/genomedk.html",
    "href": "access/genomedk.html",
    "title": "GenomeDK",
    "section": "",
    "text": "If you are using GenomeDK as the HPC of your choice, you can use the pre-packaged Docker container, which contains JupyterLab and the necessary packages to run all the notebooks for our genomics app. GenomeDK comes with ‘Singularity’, which can import and execute Docker containers, ensuring full reproducibility of the analysis. Instructions for using the container through the terminal or desktop are available.\nFollow the instructions below to get started."
  },
  {
    "objectID": "access/genomedk.html#using-genomedk-desktop",
    "href": "access/genomedk.html#using-genomedk-desktop",
    "title": "GenomeDK",
    "section": "Using GenomeDK Desktop",
    "text": "Using GenomeDK Desktop\nWe recommend using GenomeDK Desktop - a browser-based virtual desktop solution. Follow these steps to get the app running:\n\nLog in to GenomeDK Desktop.\nOpen a terminal and navigate to or create a new folder, then pull the Docker image of the app.\n\n# docker\ndocker pull hdssandbox/genomicsapp\n# singularity\nsingularity pull genomicsapp.sif docker://hdssandbox/genomicsapp \n\nCopy the command below and modify it accordingly.\nsrun --mem=32g --cores=2 --time=0:10:0 --account=&lt;YOURPROJECT&gt; --pty singularity exec --writable-tmpfs --fakeroot --bind /tmp:/tmp --bind $(pwd):$(pwd) --pwd $(pwd) --bind /etc/ssl/certs:/etc/ssl/certs --bind /etc/pki/ca-trust:/etc/pki/ca-trust /path/to/genomicsapp.sif start-app -c \"Intro_to_GWAS -p $UID\"\nThe command above is used to run the image as an interactive session on the HPC, specifying the time, cores, and memory allocation.\n\nAdjust the settings to your needs. Check GenomeDK guidelines if in doubt.\nChoose the directories that should be bound for inclusion inside the container.\n\nClick on “Show clipboard” at the top-right of the Desktop, and paste the modified command there.\nIn the terminal, paste the command and ensure you are in the desired working directory (e.g., intro_to_GWAS in one of your projects as we are binding the pwd).\nOpen the link displayed in the terminal, which includes the node name and port number (e.g., cn-1040:8787 or s21n31:8787)."
  },
  {
    "objectID": "access/genomedk.html#using-the-terminal",
    "href": "access/genomedk.html#using-the-terminal",
    "title": "GenomeDK",
    "section": "Using the terminal",
    "text": "Using the terminal\n1. Log into the cluster using the command line, and substituting USERNAME with your actual user name:\nssh USERNAME@login.genome.au.dk\nand be sure to run those two commands to remove space-filling cache data, which can make everything slower after a few times you run tutorials\nrm -rf ~/.apptainer/cache/*\nrm -rf ~/.singularity/cache/*\n2. Get into a folder inside your project, for example\ncd MYPROJECT/ngsSummerSchool\n3. Use singularity to download the container of the course. This will take some time and show a lot of text, and at the end a file called course.sif is created into the folder.\nsingularity pull course.sif docker://hdssandbox/ngssummerschool:2024.07\n\n\n\n\n\n\nWarning\n\n\n\nYou need to do this step only once!\n\n\n4. Activate tmux: this will make things run in background. If you lose your internet connection, the course material will still be up and running when the connection is back on your pc! Use the command\ntmux\nThe command line will change a bit its aspect. Now it’s time to get a few resources to run all the material. We suggest one CPU and 32GB of RAM for this module. For the first configuration suggested, for example, you get resources using\nsrun --mem=32g --cores=1 --time=4:0:0  --account=MYPROJECT --pty /bin/bash\n\n\n\n\n\n\nNote\n\n\n\nYou’ll need your project name and can choose how long you want resources available. * Requesting resources may involve a wait in the queue**. In the example above time is 4 hours, after which your session will be closed, so save your progress.\n\n\n5. execute the container with\nsingularity exec course.sif /bin/bash\nNote that the command line shows now Apptainer&gt; on its left. We are inside the container and the tools we need are now available into it.\n6. Now we need to run a configuration script, which will setup the last details and execute jupyterlab. If a folder called Data exists, it will not be downloaded again (also meaning that you can use our container with your own data folder for your own analysis in future)\ngit config --global http.sslVerify false\nwget -qO-  https://raw.githubusercontent.com/hds-sandbox/NGS_summer_course_Aarhus/docker/scripts/courseMaterial.sh | bash\n7. You will see a lot of messages, which is normal. At the end of the messages, you are provided two links looking as in the image below. Write down the node name and the user id highlighted in the circles.\n\nWrote down node and ID? Last step is to create a tunnel between your computer and genomeDK to be able to see jupyterlab in your browser. Now you need to use the node name and the user id you wrote down before! Open a new terminal window on your laptop and write\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nwhere you substitute USERID and NODENAME as you wrote down before, and then USERNAME is your account name on GenomeDK. For example ssh -L 6835:s21n81:6835 samuele@login.genome.au.dk according to the figure above for a user with name samuele.\n8. Open your browser and go to the address http://127.0.0.1:USERID/lab, where you need your user id again instead of USERID. For example http://127.0.0.1:6835/lab from the figure above. Jupyterlab opens in your browser.\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\n\n\n\n\n\nTip\n\n\n\nRight click on a notebook or a saved results file, and use the download option to save it locally on your computer.\n\n\n\nWhat if my internet connection drops?\nNow worries, tmux kept your material up and running. You only need a new terminal window to run the tunneling\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nas you did before, so you can continue working!\n\n\nRecovering the material from your previous session\nDo you want to work again on the course material, or recover some analysis? Everything is saved in the folder you were working in. Next time, follow the whole procedure again (without step number 3.) and you can be up and running the course in no time."
  },
  {
    "objectID": "access/UCloud.html",
    "href": "access/UCloud.html",
    "title": "UCloud",
    "section": "",
    "text": "UCloud is an HPC platform available to researchers and students at Danish universities (via a WAYF university login). It features a user-friendly graphical interface that simplifies project, user, and resource management. UCloud offers access to numerous tools via selectable apps and a variety of flexible compute resources. Check out UCloud’s extensive user docs here. For a more detailed information on navigating UCloud and using our apps, check out the Sandbox guidelines.\nIf you’ve chosen UCloud as your HPC platform to use the Genomics app, follow the steps below.\n\n\nLog onto UCloud at the address http://cloud.sdu.dk using university credentials.\n\n\n\nWhen logged in, choose the project from the dashboard (top-right side) from which you would like to utilize compute resources. Every user has their personal workspace (My workspace). You can also provision your own project (check with your local DeiC office if you’re new to UCloud) or you can be invited to someone else’s project. If you’ve previously selected a project, it will be launched by default. If it’s your first time, you’ll be in your workspace.\n\n\n\nOnce approved as a UCloud user, you will be greeted by a dashboard interface. Here, you can view a summary of your workspace, including computing hours, available storage, and other key details. Your current workspace is displayed in the top-right corner (e.g. Sandbox_workshop). On the left side, a toolbar menu provides navigation options. Our Genomic App offers a pre-configured environment with all necessary installations. However, unless you are participating in one of our workshops, you will need to use your own resources to run the training materials.\n\n\n\nDashboard\n\n\n\n\n\nThe left-side menu can be used to access the stored data, applications, running programs and settings. Use the Applications symbol (in gray). Search for the Genomics Sandbox application to open its settings.\n\n\n\n\nChoose any Job Name (#1 in the figure below), how many hours you want to use for the job (#2, choose at least 2 hours, you can increase this later), and how many CPUs (#3, choose at least 4 CPUs for the first three exercises, but use at least 8 CPUs to run the GWAS analysis). Select the Introduction to GWAS as course (#4). Then click on Submit (#5). The App needs to download data and packages which can take some time. See below how to reuse the data and avoid long waiting time (you need however to download data the first time you run the app).\n\n\n\n\n\n\n\nOptional: select a folder from your own drive\n\n\n\nWe suggest creating a folder to store your results and any modifications you make to the notebooks. Click on Add folder. For example, work_gwas.\n\n\nYou will be waiting in a queue looking like this:\n\n\n\n\nAs soon as there are resources, you will have them available, and in a short time the course will be ready to run. The screen you get is in the image below. Here you can increase the number of hours you want the session to run (Time allocation), close the session (Stop application) and open the interface for coding (Open interface)\n\n\n\n\n\n\n\nTip\n\n\n\nOnce you open the coding interface, it does not matter if you close the browser tab with the countdown timer. You can always access it again from the toolbar menu of UCloud. Simply click on Jobs and choose your session from the list of running softwares.\n\n\nNow you’re ready to use JupyterLab for coding!\n\n\n\n\n\n\nNote\n\n\n\nIf you have mounted your own folder, copy both the notebook and the data folder into it before running any cell.\n\n\nUse the file browser on the left side to locate the Notebooks. Select one of the notebooks—it will open in the right-side panel. Carefully read the instructions and execute each code cell, starting from the first.\nMake sure you have selected the correct kernel before running the cells. You’ll see the results appear directly in the notebook!\n\n\n\nIt would be annoying to start from scratch at each session, with all the analysis to be executed again. You can use data and notebooks running in a previous session of the App. Otherwise, the app will download the data and the notebooks every time. How can we avoid this?\n\nA. If you copied the folder into your mounted directory, include both folders (“Add folders”) when submitting the job in future runs to maintain your own version of the notebook.\n\n\n\nB. If you didn’t copy the folder, you can still access your version of the notebook. To select data from previous sessions, click “Add folders” and navigate to your latest sandbox session (inside the folder Jobs/Genomics Sandbox under your personal user folder as shown below) and select the folders you need. In this example, accepted folders are Data and Notebooks.\n\n\n\n\n\n\nYou can easily download files you generated by right-clicking on selected files in the browser of Jupyterlab, and by choosing download (see figure below)."
  },
  {
    "objectID": "access/UCloud.html#download-the-data-you-generated",
    "href": "access/UCloud.html#download-the-data-you-generated",
    "title": "UCloud",
    "section": "",
    "text": "You can easily download files you generated by right-clicking on selected files in the browser of Jupyterlab, and by choosing download (see figure below)."
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html",
    "href": "develop/GWAS6-PRSAnalysis.html",
    "title": "Polygenic scores I",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nPolygenic scores (PRS) estimate an individual’s genetic predisposition to complex traits or diseases by combining information from multiple genetic variants previously identified in the GWAS study. This notebook provides a step-by-step guide to performing a basic PRS analysis using PRSice and explains how to interpret the results.\n\n\n\nDiscuss and choose the PRS equation\nDiscuss PRS scores and biases\n\n\n\n\n\nIn this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel\nWhile most individual associations found in GWAS studies are of small effect, information about them can be combined across the genome, to create a polygenic score (PGS). These scores can be used to make genome-based predictions about the overall risk of having a particular trait or disease or about the genetic value for continuous traits. If the prediction is on a discrete phenotype such as a disease, these scores are known as polygenic risk scores (PRS).",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#learning-outcomes",
    "href": "develop/GWAS6-PRSAnalysis.html#learning-outcomes",
    "title": "Polygenic scores I",
    "section": "",
    "text": "Discuss and choose the PRS equation\nDiscuss PRS scores and biases",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS6-PRSAnalysis.html#how-to-make-this-notebook-work",
    "title": "Polygenic scores I",
    "section": "",
    "text": "In this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-prediction-analyses",
    "href": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-prediction-analyses",
    "title": "Polygenic scores I",
    "section": "Polygenic risk prediction analyses",
    "text": "Polygenic risk prediction analyses\nSingle-variant association analysis has been the foundation of GWAS. However, detecting more than a handful of significant SNPs for many complex traits requires extremely large sample sizes. In contrast, PGS aggregate genetic risk across multiple variants into a single polygenic score for a given trait.\nA PGS is typically calculated by summing the allele frequencies of statistically significant trait-associated variants, weighted by their effect sizes, while ensuring independence among them (e.g., via LD pruning). These effect sizes—betas for continuous traits and log odds ratios for binary traits—are obtained from a discovery GWAS. Large discovery samples (also known as base or training samples) are needed for accurate estimates, but if the target sample shares ancestry, effect sizes from larger studies can be leveraged. A target sample of ~2,000 individuals may be sufficient to detect meaningful genetic contributions to trait variance (Dudbridge 2013). For many complex traits, SNP effect sizes are publicly available (e.g., see https://www.nealelab.is/uk-biobank, https://www.med.unc.edu/pgc/downloads or https://www.ebi.ac.uk/gwas/).\nA common practice to calculate PRS involves clumping GWAS results using p-value thresholds (e.g., p &lt; 0.05) to exclude poorly associated SNPs. Usually, multiple PRS analyses will be performed, with varying thresholds for the p-values of the association test.\nOnce PRS are calculated, they are used in (logistic) regression models to assess the contribution to the trait variance. Prediction accuracy is measured by the increase in \\(R^2\\), comparing a baseline model with only covariates (e.g., MDS components) to a model that also includes PRS. This increase reflects the proportion of variance explained by genetic risk factors. Accuracy depends on trait heritability, SNP count, and discovery sample size, with a few thousand individuals typically sufficient for reliable estimates.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-score-analysis-with-prsice-2",
    "href": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-score-analysis-with-prsice-2",
    "title": "Polygenic scores I",
    "section": "Polygenic risk score analysis with PRSice-2",
    "text": "Polygenic risk score analysis with PRSice-2\nPRSice is a widely used tool for polygenic risk score analysis. This tutorial offers a step-by-step guide on its use and result interpretation.\nThe installed package will include an R script that is straightforward to run. It requires the following information:\n\n--prsice: the binary executable file\n--base: the .assoc file that contains statistical information\n--target: the PLINK-formatted dataset\n\n\n\n\n\n\n\nNote\n\n\n\nWe would apply this method to our HapMap dataset, but PRS analysis typically requires a sample size of around 2,000 to produce meaningful results, while our dataset includes only about 150 individuals. To facilitate learning, we will instead use a toy dataset. In this notebook, we will focus on analyzing a binary trait.\nIdeally, the summary statistics should come from the most powerful GWAS available for the phenotype of interest. Commonly, the target dataset is typically generated within your lab or obtained through collaborations.\n\n\n\nPRSice analysis for binary traits\n Let’s create a folder for the output files. Then, perform the PRS analysis on the toy dataset in the following way:\n\nmkdir -p Results/GWAS6\n\n# Create two links to data\nln -sf ../Data\n\nWe will run the PRSice.R script using the association test results (TOY_BASE_GWAS.assoc) and specify the column names for SNPs, chromosomes, and other relevant data. This is necessary because different association tools generate varying header formats. Finally, we will specify the location of our data (TOY_TARGET_DATA) and define the phenotype format as binary (0s and 1s).\n\n\n\n\n\n\nWarning\n\n\n\nIf you get an error in the following command, try to restart the kernel in the Kernel menu. Sometimes links to folders are not recognized immediately.\n\n\n\n# Recommendation: check the usage instructions and mandatory input files by uncommenting the command below:  \n#PRSice -h\n\n\nPRSice --base ./Data/TOY_BASE_GWAS.assoc \\\n    --snp SNP --chr CHR --bp BP --A1 A1 --A2 A2 --stat OR --pvalue P \\\n    --target ./Data/TOY_TARGET_DATA \\\n    --out Results/GWAS6/PRSice \\\n    --binary-target T\n\nPRSice 2.3.5 (2021-09-20) \nhttps://github.com/choishingwan/PRSice\n(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\nGNU General Public License v3\nIf you use PRSice in any published work, please cite:\nChoi SW, O'Reilly PF.\nPRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\nGigaScience 8, no. 7 (July 1, 2019)\n2025-03-20 14:03:50\nPRSice \\\n    --a1 A1 \\\n    --a2 A2 \\\n    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n    --base ./Data/TOY_BASE_GWAS.assoc \\\n    --binary-target T \\\n    --bp BP \\\n    --chr CHR \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --interval 5e-05 \\\n    --lower 5e-08 \\\n    --num-auto 22 \\\n    --or  \\\n    --out Results/GWAS6/PRSice \\\n    --pvalue P \\\n    --seed 2840029482 \\\n    --snp SNP \\\n    --stat OR \\\n    --target ./Data/TOY_TARGET_DATA \\\n    --thread 1 \\\n    --upper 0.5\n\nInitializing Genotype file: ./Data/TOY_TARGET_DATA (bed) \n\nStart processing TOY_BASE_GWAS \n================================================== \n\nBase file: ./Data/TOY_BASE_GWAS.assoc \nHeader of file is: \nSNP CHR BP A1 A2 P OR \n\nReading 32.60%\n\n\nIOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n\n\nReading 74.31%\n\n\nIOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n\n\nReading 100.00%\n91062 variant(s) observed in base file, with: \n2226 variant(s) located on haploid chromosome \n88836 total variant(s) included from base file \n\nLoading Genotype info from target \n================================================== \n\n2000 people (1024 male(s), 976 female(s)) observed \n2000 founder(s) included \n\nWarning: Currently not support haploid chromosome and sex \n         chromosomes \n\n88836 variant(s) included \n\nThere are a total of 1 phenotype to process \n\nStart performing clumping \n\nClumping Progress: 100.00%\nNumber of variant(s) after clumping : 88836 \n\nProcessing the 1 th phenotype \n\nPhenotype is a binary phenotype \n1000 control(s) \n1000 case(s) \n\n\nStart Processing\nProcessing 40.15%\n\n\nIOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n\n\nProcessing 100.00%\nThere are 1 region(s) with p-value less than 1e-5. Please \nnote that these results are inflated due to the overfitting \ninherent in finding the best-fit PRS (but it's still best \nto find the best-fit PRS!). \nYou can use the --perm option (see manual) to calculate an \nempirical P-value. \n\n\n\n\nThe --base parameter refers to the file with summary statistics from the base sample. Each line represents a single SNP and includes details such as effect size and p-value.\nThe --target parameter specifies the prefix of genotype data files in binary PLINK format (.bed, .bim, .fam). The base and target samples must be independent to avoid inflated polygenic risk score associations.\n\nIf the type effect (--stat) or data type (--binary-target) were not specified, PRSice will try to determine this information based on the header of the base file.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nCan all genomic variants be used for calculating PRS? Why or why not?\nHow can you determine which variants should be included in the PRS calculation?\nAre linkage disequilibrium (LD) blocks shared across populations with different ancestry? Explain your reasoning.\n\nHint: read the [PRSice user manual](https://choishingwan.github.io/PRSice/step_by_step and Berisa and Pickrell (2016).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNo, not all variants should be used. Variants in high LD (highly correlated) should be handled carefully to avoid inflated significance and false positives.\nVariants should be selected based on their association with the trait and their independence from other variants. Two common approaches for handling correlated SNPs are: - LD clumping (e.g., PRSice): correlated SNPs within each LD block are filtered by selecting the one with the lowest p-value from the discovery set. Other SNPs in the same block are excluded. Clumping parameters can be customized. - Bayesian adjustments (e.g., LD Pred2) use a Bayesian framework to adjust the effect sizes of SNPs by accounting for LD patterns across the genome. This helps refine PRS calculations and corrects for correlated SNPs.\nNo, LD blocks can differ between populations of different ancestry due to genetic history and environment. It is essential to account for these differences when calculating PRS, especially when using cross-population data.\n\n\n\n\nFor simplicity’s sake, we did not include principal components or covariates in this analysis, however, when conducting your analyses we strongly recommend including these.\n\n\nInterpreting the results\nBy default, PRSice saves two plots and several text files. The first plot is PRSice_BARPLOT_&lt;date&gt;.png(which you find in Result/GWAS6 using the file browser, the filename depends on the current date). This plot illustrates the predictive value (Nagelkerke’s R²) in the target sample based on SNPs with p-values below specific thresholds in the base sample. A p-value is also provided for each model.\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nWhich P-value threshold generated the “best-fit” PRS?\nHow much phenotypic variation does the “best-fit” PRS explain?\n\nHint: Check the PRSice.summary file.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs shown in the plot, a model using SNPs with a p-value &lt; 0.4463 achieves the highest predictive value in the target sample (p-value= 4.7e-18). However, as is often the case in polygenic risk scores analysis with relatively small samples, the predictive value is relatively low (Nagelkerke’s around 5%). The text files include the exact values for each p-value threshold (check them!).\nThe phenotypic variation (PRS.R2) explained by these variants is 0.05.\n\nPRS.R2: quantifies how much of the trait variation is attributable to the genetic variants used in the analysis\nFull.R2: represents the total variance explained by the full model (genetic variants and any other covariates used)\nNull.R3: indicates the variance explained by the model without the PRS component (i.e., just the covariates)\n\n\n\n\nThe second plot PRSice_HIGH-RES_PLOT_&lt;date&gt;.png (which you again can manually open) shows many different p-value thresholds. The p-value of the predictive effect is in black together with an aggregated trend line in green.\n\nBoth figures show that trait-associated SNPs in the base sample can predict the trait in the target sample. If the same trait is used, predictive power depends on the trait’s heritability and base sample size. When using related but different traits, the predictive power also depends on their genetic correlation. Studies suggest that models with more lenient p-value thresholds capture smaller effects important for complex traits, while stricter thresholds reduce noise, aiding interpretation and the understanding of the underlying genetic architecture. Balancing informative SNPs and minimizing noise is key to maximizing predictive power.\n\n\nConclusion\nIn this tutorial, we have discussed how to perform a simple polygenic risk score analysis using the PRSice script and interpret its results. As mentioned before, PRSice offers many additional options to adjust the risk score analysis, including adding covariates (principal components) and adjusting clumping parameters. It is recommended to read the user manual of PRSice to perform a polygenic risk score analysis optimal to the research question at hand.\nNow, you will need to do the same for a quantitative trait and explore the results.\n\n\n\n\n\n\nOther take-home messages\n\n\n\n\nReplication in (several) other cohorts provides convincing evidence\nApplying stringent statistics (P&lt;5e-8) helps to reduce the likelihood of false-positive results\nAn external reference panel can be used to improve LD estimation for clumping, providing more accurate definitions of LD blocks and refining the selection of variants for PRS analysis, especially when sample size is limited (e.g. ~500 samples).",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#further-reading",
    "href": "develop/GWAS6-PRSAnalysis.html#further-reading",
    "title": "Polygenic scores I",
    "section": "Further Reading",
    "text": "Further Reading\nThere is only so much one can discuss in a beginner’s practical guide to GWAS. As such, for those who want to expand their knowledge of GWAS, we have provided a comprehensive list of resources for you to read/try out below.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores I"
    ]
  },
  {
    "objectID": "develop/GWAS8-OtherToolsAndTesting.html",
    "href": "develop/GWAS8-OtherToolsAndTesting.html",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\n\n\n\n\nExplore LDAK software and some of its functionalities\nDiscuss other tools and conclusions from this tutorial\n\n\n\n\n\nIn this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Other tools & conclusions"
    ]
  },
  {
    "objectID": "develop/GWAS8-OtherToolsAndTesting.html#learning-outcomes",
    "href": "develop/GWAS8-OtherToolsAndTesting.html#learning-outcomes",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "Explore LDAK software and some of its functionalities\nDiscuss other tools and conclusions from this tutorial",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Other tools & conclusions"
    ]
  },
  {
    "objectID": "develop/GWAS8-OtherToolsAndTesting.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS8-OtherToolsAndTesting.html#how-to-make-this-notebook-work",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "In this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Other tools & conclusions"
    ]
  },
  {
    "objectID": "develop/GWAS8-OtherToolsAndTesting.html#ldak",
    "href": "develop/GWAS8-OtherToolsAndTesting.html#ldak",
    "title": "Other tools & conclusions",
    "section": "LDAK",
    "text": "LDAK\nThroughout this tutorial, we have used PLINK as the main method of our GWAS analysis. This is, in large part, due to its popularity in modern literature and its ease of use. But it is by no means the only method of GWAS.\nOne tool that has been developed in recent years is LDAK, by Dough Speed (2012). One of the most significant improvements of this program is the genetic prediction of complex traits from both individual-level data and summary statistics. Most prediction tools assume the GCTA model, whereby each SNP is expected to contribute equally to the phenotype (as is the case with PLINK). If we replace the GCTA Model with the BLD-LDAK Model, the squared correlation between observed and predicted phenotypes (\\(R^2\\)) increases by an average of 14% (s.d. 1%).",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Other tools & conclusions"
    ]
  },
  {
    "objectID": "develop/GWAS8-OtherToolsAndTesting.html#overview-of-functionality",
    "href": "develop/GWAS8-OtherToolsAndTesting.html#overview-of-functionality",
    "title": "Other tools & conclusions",
    "section": "Overview of functionality",
    "text": "Overview of functionality\nUsing LDAK is very similar to PLINK. As with PLINK, you will require the .bed, .bim, and .fam files of your cohort. Beyond this, you will need additional files:\n\n.info - information scores for SNPs\n.pheno - a phenotype\n.covar - covariates\n.ind.hers - estimates of per-SNP heritabilities\n.genefile - (real) RefSeq human gene annotations\n\n If we call our prefix human, then very simply, we can compute summary statistics in the following way:\n\n# link the data and create output directory \nln -sf ../Data\nmkdir Results/GWAS8\n\n# Run ldak software\n../Software/ldak --calc-stats Results/GWAS8/human --bfile Data/ldak_data/human\n\nmkdir: cannot create directory ‘Results/GWAS7’: File exists\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nLDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\nVersion 5.2 - Help pages at http://www.ldak.org\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nThere are 2 pairs of arguments:\n--calc-stats Results/GWAS7/human\n--bfile Data/ldak_data/human\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nCalculating predictor and individual statistics\n\nTo run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nReading IDs for 424 samples from Data/ldak_data/human.fam\n\nReading details for 3289 predictors from Data/ldak_data/human.bim\n\nData contain 424 samples and 3289 predictors\n\nCalculating statistics for Chunk 1 of 1\n\nStatistics saved in Results/GWAS7/human.stats and Results/GWAS7/human.missing\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nMission completed. All your basepair are belong to us :)\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\n\nThis command asks LDAK to read the data stored in Binary PLINK format with the prefix human, then save the results to files with the prefix “human”. Remember that software command line arguments, can be provided in any order (generally, there is no strict order requirement), so that the command above would be equivalent to ../Software/ldak --bfile Data/ldak_data/human --calc-stats Data/ldak_data/human\nThe output files are called human.stats and human.missing and found in the folder Results/GWAS8. By accessing the columns of human.stats, we can create plots similar to those in the notebook GWAS3 with the tutorial on QC:\n\n######### FOR EXERCISE\n\nsnpmiss &lt;- read.table(file=\"Results/GWAS8/human.stats\", header=TRUE)\n\nhead(snpmiss)\n\nhist(snpmiss$MAF, breaks = 50) \n\n#  geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n#  labs(title = \"Frequency of missingness rates in individuals\") + \n#  xlab(\"Frequency\") + \n# ylab(\"Missingness in Individuals\") + \n# theme_bw()\n\n\n###########################\n\n\nA data.frame: 6 × 7\n\n\n\nPredictor\nA1\nA2\nA1_Mean\nMAF\nCall_Rate\nInfo\n\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n21:14642464\nA\nG\n0.884434\n0.442217\n1\n-1\n\n\n2\n21:14649798\nA\nC\n0.974057\n0.487028\n1\n-1\n\n\n3\n21:14669931\nG\nA\n0.969340\n0.484670\n1\n-1\n\n\n4\n21:14688825\nT\nC\n0.983491\n0.491745\n1\n-1\n\n\n5\n21:14736298\nC\nT\n0.858491\n0.429245\n1\n-1\n\n\n6\n21:14757043\nT\nC\n0.929245\n0.464623\n1\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.1: Genomic properties are easily accessible by parsing through the outputted summary statistics\n\n\nIf you wish to perform single-SNP association analysis using linear regression. We would use the main argument --linear in this case. Each main argument requires different options. Remember to check the Documentation at www.dougspeed.com. Most software have a --help option, but LDAK doesn’t, so an alternative is to run the main argument, which will print out the options required and missing for a successful run:\n\n../Software/ldak --linear linear\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nLDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\nVersion 5.2 - Help pages at http://www.ldak.org\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nThere is one pair of arguments:\n--linear linear\n\nError, you must use \"--pheno\" to provide phenotypes\n\n\n\n: 1\n\n\nThe output can be used to obtain GWAS plots of interest, such as a Manhattan plot:\n\n\n\nFigure 7.2: Manhattan plot outputted by LDAK\n\n\nFurthermore, LDAK offers various additional methods and features, such as the explicit incorporation of covariates and PRS. For those interested, we recommend following the tutorials available here. Additionally, we have included the dataset accompanying this tutorial in the Data folder, conveniently named extra_data.zip. All you need is to run the commands in the tutorial.\nThe takeaway is that while more advanced tools exist, PLINK serves as an excellent starting point for conducting focused and specific analyses, particularly for educational purposes.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Other tools & conclusions"
    ]
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html",
    "href": "develop/GWAS2-DataCollection.html",
    "title": "Data exploration",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nThis course module covers practical considerations regarding the standard file formats used in GWAS.\n\n\n\nExplore the content of classical data files for GWAS through the command line\nApply and extend some command line programs to retrieve and explore data\n\n\n\n\nWe will only use the bash command line in this notebook. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data exploration"
    ]
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#learning-outcomes",
    "href": "develop/GWAS2-DataCollection.html#learning-outcomes",
    "title": "Data exploration",
    "section": "",
    "text": "Explore the content of classical data files for GWAS through the command line\nApply and extend some command line programs to retrieve and explore data",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data exploration"
    ]
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS2-DataCollection.html#how-to-make-this-notebook-work",
    "title": "Data exploration",
    "section": "",
    "text": "We will only use the bash command line in this notebook. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data exploration"
    ]
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#description-of-the-data",
    "href": "develop/GWAS2-DataCollection.html#description-of-the-data",
    "title": "Data exploration",
    "section": "Description of the Data",
    "text": "Description of the Data\nTo demonstrate all analysis steps with realistic genetic data, we will use a simulated dataset (N = 165) with a binary outcome measure, based on the publicly available data from the International HapMap Project (Gibbs et al. 2003). For this tutorial, we only included Utah residents with ancestry from Northern and Western Europe (CEU) to create an ethnically homogenous dataset. Because of the relatively small sample size of the HapMap data, genetic effect sizes in these simulations were set at values larger than usually observed in genetic studies of complex traits. It is important to note that larger sample sizes (e.g., at least in the order of thousands but likely even tens or hundreds of thousands) will be required to detect genetic risk factors of complex traits.\n Choose the Bash kernel.\nFirst, we link the data folder to easily access it by using the ln -sf command.\n\nln -sf ../Data\n\n\nFam file - Info on individuals\nWe begin by looking at HapMap_3_r3_1.fam, which you can do using the command below (head), which prints and selects the first 10 lines of a file:\n\nhead -10 Data/HapMap_3_r3_1.fam\n\n1328 NA06989 0 0 2 2\n1377 NA11891 0 0 1 2\n1349 NA11843 0 0 1 1\n1330 NA12341 0 0 2 2\n1444 NA12739 NA12748 NA12749 1 -9\n1344 NA10850 0 NA12058 2 -9\n1328 NA06984 0 0 1 2\n1463 NA12877 NA12889 NA12890 1 -9\n1418 NA12275 0 0 2 1\n13291 NA06986 0 0 1 1\n\n\nIt is just a plain text file with six columns separated by the others using the so-called tab spacing and no header. What information does each column contain?\n\n1st column (FID) is the family identification abbreviated as FID. The PLINK software was primarily developed for genomic analyses in humans, which is reflected in the naming terminology and default settings. As an example, in the goat Adatapt project (AdaptMap), the use of this column is to specify breed identity. Since this field is required, you can organize your data into any meaningful grouping that suits your needs, or repeat the sample ID if no other category fits better.\n2nd column (IID) is the “within family ID” or “individual ID” and is abbreviated as IID which is unique to each individual.\n3rd and 4th columns: the father and mother IDs are recorded in the third and fourth columns if genotyped. If parents are unknown or not available, their entries are set to 0.\n5th column (sex) contains the sex information of the individual in the IID column. According to the built-in coding, 1 is for males, 2 for females, and 0 is unknown. Similar to parent information, this is also many times missing, usually not a problem, but specific PLINK options need to be included in case any issues come up.\n6th column: denotes the phenotype of individuals in the IID column, with 1 for controls, 2 for cases, and other values or continuous measurements for other phenotypes. Missing values are represented by 0 or -9.\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThe exercises provide solutions below. However, you should try to solve the questions on your own. Feel free to use online search and AI tools to ask questions and find the answers.\n\nQ1. How many individuals are represented in the fam file? Find a command that counts the number of lines in the file.\nQ2. How many unique fathers and mothers are there in the population? Try to extract column 3 and count the unique occurrences of each ID of the fathers. Do the same with column 4 for the mothers. Hint: there is a white-space between columns.\nQ3. How many individuals do not have phenotype information? Search for missing values in column 6.\n\n\n\n\n# Write your code here - Q1\n\n\n# Write your code here - Q2\n\n\n# Write your code here - Q3\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe command wc (which stands for Word Count) can count the words in a file. With the option -l it will instead count the lines of the file.\n\nwc -l Data/HapMap_3_r3_1.fam\n\n165 Data/HapMap_3_r3_1.fam\n\n\nQ1: There are 165 individuals.\nTo see how many unique fathers there are, we need a sequence of commands. Each command has an output, which is sent to the next command using the pipe | symbol. We will: - cut the 3rd column of the text file setting the space as a separator for the columns, - sort the column extracted, so multiple occurrences of the same fathers are grouped together and not counted as separate groups - count how many times each father is shown using the command uniq with the option -c for counting - displays the first 5 rows of the file, allowing you to preview the data and check its format\n\ncut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | head -n5\n\n    115 0\n      1 NA06986\n      1 NA06993\n      1 NA06994\n      1 NA07051\n\n\nYou can see how there are 115 unknown fathers (0s), and all the others occur only once. To count how many fathers there are, we can simply run the same commands and add wc -l at the end. There are 51 lines, meaning 50 known fathers if we remove the unknown ones\n\ncut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l\n\n51\n\n\nYou can observe a similar thing for the mothers, where we have one less which is unknown\n\ncut -f4 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l\n\n52\n\n\nQ2: There are 50 unique fathers and 51 unique mothers in the dataset.\nFinally, we will count the occurrences of 0 and -9 in column 6 using the awk command:\n\nawk '{if ($6 == 0 || $6 == -9) print $0}' Data/HapMap_3_r3_1.fam | wc -l \n\n53\n\n\nQ3: There are 53 individuals with missing phenotypes in the dataset.\n\n\n\n\n\n\nBim file - SNP location info\nThe .bim file contains the genomic locations of all SNPs in the data, and looks like this:\n\nhead -10 Data/HapMap_3_r3_1.bim\n\n1   rs2185539   0   556738  T   C\n1   rs11510103  0   557616  G   A\n1   rs11240767  0   718814  T   C\n1   rs3131972   0   742584  A   G\n1   rs3131969   0   744045  A   G\n1   rs1048488   0   750775  C   T\n1   rs12562034  0   758311  A   G\n1   rs12124819  0   766409  G   A\n1   rs4040617   0   769185  G   A\n1   rs2905036   0   782343  C   T\n\n\nSimilar to the .fam file, the bim file has six columns.\n\n1st column contains the chromosome number where the SNP is located. You can see that the first 10 SNPs are located on Chromosome 1.\n2nd column is the SNP name. This name is predefined during the construction of the SNP chip. If you ever want to compare versions of different SNP chips for the same species, overlapping the SNP name is an excellent way to start.\n3rd column is the position of the SNP in Morgans or centimorgans (cM), with zero value if you do not know or care. For most of the analyses, this could be kept as zero.\n4th column is the base pair coordinate of the SNP. In other words, you start to count from the beginning of the chromosome, and for each SNP write down its exact location. At the beginning of each new chromosome, the counter resets and starts from one again.\n\nIn the remaining two columns 5th and 6th are the alleles for respective SNPs. All SNPs on chips are biallelic, meaning each row shows only two alleles, with missing genotypes represented by zero (not shown in the .bim file). Genotypes in column five usually represent the minor allele, and column six shows the major allele (more about allele frequencies in data quality control).\nSimilar to .fam files, you can extract useful information just by looking at the file. Here, each row contains information about a particular SNP.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nQ4. What is the total number of variants in the HapMap dataset?\n\n\n\n\n# Write your code here - Q4 \n\nDid you also get 1,457,897 SNPs for the HapMap data with the wc -l Data/HapMap_3_r3_1.bim command?\n\n\nBed file - Individual genotypes\nSo far, we know that the files you downloaded contain genotypes for 165 individuals, each of them genotyped for 1,457,897 SNPs. But where are the genotypes for the individual samples?\nThese are located in the binary file called HapMap_3_r3_1.bed file, but unfortunately, opening it as a normal text looks like this:\n\nhead -1 Data/HapMap_3_r3_1.bed\n\nl\u001b\u0001�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003��λ������������/����������������������\u0003��λ������������/�����������������������\u0003��λ������������/����������������������\u0003��������?�������������������������������\u0002������������������������⸿Ͼ��,��\u0002z�\u0003��ο������������/�����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003���������ﮪ���������+���������������\u0003����������������������������������������\u0003�����誮����\u000fΫ������������:���*�?����\u0003��������������﫿����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003���?�������￿�����;�����������������\u0003//���������﮿������;����ή����������\u0002���?�������ʯϿ�\u000f����;����Ϯ�����������\u0002�����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003����������ʯ￾�����;����Ϯ���&lt;�������\u0002����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003��뿌�������\u000fϿ������:���Ϫ���&lt;�.�?����\u0002�����������������������������������������\u0003����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002������������������������������β�����.�\u0003�����������������������������������������\u0003����������?������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0002�����������������(������/����������\n\n\nThis is because the genotypes are stored in a binary format, which saves disk space and allows faster processing by the computer, as it’s already in a machine-readable format. It is often useful to check out the individual genotypes, for that, you will need a new command called xxd to open the file which can then be pipeped into the head command.\n\nxxd -b Data/HapMap_3_r3_1.bed | head -10\n\n00000000: 01101100 00011011 00000001 11111111 11111111 11111111  l.....\n00000006: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000000c: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000012: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000018: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000001e: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000024: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000002a: 11111111 11111111 00000011 11111111 11111111 11111111  ......\n00000030: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000036: 11110011 11111111 11111111 11111111 11111111 11111111  ......\n\n\nThe non-binary file format for the genotype is stored in the so-called .ped and .map files. These are also some well-known formats and widely used in various programs.\n\n\n\n\n\n\nChallenge yourself with the command line programs\n\n\n\nWe have real mice data from the heterogeneous stock data with an example phenotype. The datasets are with extensions .bed, .bim, .fam, .pheno and name prefix Data/mice. The mice.pheno file contains an example phenotype per individual.\n\nFind out how many individuals and how many SNPs there are in the mice data. Which chromosomes are considered in the data? Is it possible to check it for sex discrepancy?\nAre there any parents in the fam file? Hint: the fam file has just a backspace as a separator and is not tab-separated. This needs the specific option -d' ' for the cut command.\nIs there any data for sex and phenotype in the .fam file? Is this data from a case-control study or a sample-based study?\nHow can you find the minimum and maximum value of the phenotype (last column) using only the command line?\n\nAnswer the questions by creating all the code cells you need for the code to check your answers.\n\n\n\n\n\n\n\n\nClick to view answers\n\n\n\n mice-solutions.ipynb\n\n\n\n\n\n\n\n\nWrapping up\n\n\n\nWe have learned about the principles of study design for GWAS and the genotyping process. Now you are also able to use some basic commands to show the content of typical GWAS file formats.",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data exploration"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html",
    "href": "develop/GWAS3-QualityControlA.html",
    "title": "Quality Control: initial steps",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAfter gathering your data and genotyping, there are many checks to do to determine the quality of the data. It is crucial to perform quality control before carrying out any GWAS, otherwise, there is the risk that some of the associations are spurious.\n\n\n\nDistinguish the various QC steps\nDiscuss and choose thresholds on plink\nImplement basic QC in plink and statistical plots in R\nHypothesize the effects of various plink commands and verify your hypothesis using the analysis in R\n\n\n\n\n\nIn this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel\nThe next critical step in any GWAS involves scrutinizing the data for potential issues. It’s crucial to ensure that the results are not merely artifacts of poor data quality discovered after the analysis.\nAfter gathering your data and genotyping, there are many checks one can do to determine the quality of the data. PLINK provides several summary statistics for quality control (e.g. missing genotype rate, minor allele frequency, and Hardy-Weinberg equilibrium failures) which will serve as thresholds for subsequent analyses.\nFor this tutorial, we will look at the following quality-related topics:",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#learning-outcomes",
    "href": "develop/GWAS3-QualityControlA.html#learning-outcomes",
    "title": "Quality Control: initial steps",
    "section": "",
    "text": "Distinguish the various QC steps\nDiscuss and choose thresholds on plink\nImplement basic QC in plink and statistical plots in R\nHypothesize the effects of various plink commands and verify your hypothesis using the analysis in R",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS3-QualityControlA.html#how-to-make-this-notebook-work",
    "title": "Quality Control: initial steps",
    "section": "",
    "text": "In this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#missingness-per-snp",
    "href": "develop/GWAS3-QualityControlA.html#missingness-per-snp",
    "title": "Quality Control: initial steps",
    "section": "Missingness per SNP",
    "text": "Missingness per SNP\nOverall, the SNP genotyping platform is very reliable and delivers stable results when it comes to determining genotypes. Of course, it is not flawless. One of the most frequent problems is that some of the SNPs are just not well-genotyped in the entire population. These should be removed to improve the overall data quality.\nCertainly, we can’t remove every SNP with any missing values, as that would result in losing a significant portion of our data. Instead, we adopt some thresholds. However, determining these thresholds isn’t governed by strict rules. You have the flexibility to set them within “reasonable” limits. To find out what constitutes “reasonable,” consulting relevant literature for your species of interest is advisable. For humans, a common starting point is a threshold of 0.2, meaning we exclude SNPs where 20% or more of the genotypes are missing in our population.",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#missingness-per-individual",
    "href": "develop/GWAS3-QualityControlA.html#missingness-per-individual",
    "title": "Quality Control: initial steps",
    "section": "Missingness per individual",
    "text": "Missingness per individual\nThe reliability of SNP chips is also high when it comes to individual genotypes. In some cases, however, some of the individuals contain a large number of missing SNPs. The reason could be low DNA sample quality, the wrong chip type used (e.g. cattle chip for deer samples), or other technical issues. Regardless of the reason, you should remove the worst offenders from your data set, to not compromise the overall quality of your results.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nHave a look at the following toy example:\n\n\n\n/\nSNP1\nSNP2\nSNP3\nSNP4\nSNP5\n\n\n\n\nIND1\n22\n00\n11\n12\n22\n\n\nIND2\n22\n00\n11\n12\n22\n\n\nIND3\n11\n12\n11\n22\n21\n\n\nIND4\n00\n00\n11\n11\n00\n\n\nIND5\n22\n00\n11\n22\n22\n\n\n\nHere, we have a data set of five individuals, each of them genotyped for five SNPs. The genotypes themselves are in numerical coding, 11 and 22 being the two homozygous, 12 the heterozygous, and 00 coded as missing. We want to apply two filters: one for the variants, and one for the individuals.\n\nFirst remove variants with &gt;= 40% missingness\nThen remove individuals with &gt;= 40% missingness\n\nWhich variants and individuals are we removing?\n\n\nIn practice, you want to remove the SNPs based on missingness before the individuals. This is simply because we generally have a lot more SNPs than individuals, and would thus lose less information by removing SNPs than individuals. This will remove “bad” SNPs first, leaving a lower rate of missingness for all the individuals.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nVariant-level threshold: In this example, we would only remove SNP2 since it exceeds this threshold, with 80% missingness (4 out of 5 missing values).\nIndividual-level threshold: IND4 is removed from the data set, as there is missing genotype information for 2/4 = 50% SNPs (after filtering out SNP2).",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#first-run-of-the-plink-tool",
    "href": "develop/GWAS3-QualityControlA.html#first-run-of-the-plink-tool",
    "title": "Quality Control: initial steps",
    "section": "First run of the PLINK tool",
    "text": "First run of the PLINK tool\n\n\n\n\n\n\nThe plink syntax\n\n\n\nBefore using plink, let’s see how its syntax is. Usual PLINK commands are written in this basic form:\nplink --bfile INPUT --out OUTPUT\nwith the additional option --make-bed if you need to generate a modified version of the input data, such as in\nplink --bfile INPUT --make-bed --out OUTPUT\nwhich will create an OUTPUT equal to the input, because you have no other options added.\nNote that INPUT and OUTPUT have no extension, as this will be added by plink. For example, INPUT means you have the files INPUT.bim, INPUT.bed, INPUT.fam, and eventually other extensions needed by extra options. The same holds for the OUTPUT. The software always tells you which file extension has created and which it needs, in case it misses some files.\nYou will see how we add different options along the tutorials. Often we use the option --silent to avoid printing messages all the time. Feel free to remove it to know which files are created.\n\n\nUsing PLINK, we can address missing data using two functions; one operates at the variant level and the other at the individual level:\n\n--geno: This will remove SNPs with a specified proportion of missingness (e.g. --geno 0.01 will remove SNPs above 1% missingness).\n--mind: This will remove individuals with a specified proportion of missingness (e.g. --mind 0.01 will remove individuals above 1% missingness).\n\nA common threshold for –mind and –geno ranges from 1% to 5% to ensure quality and robustness. Higher thresholds may be acceptable if the study has a large sample size and missingness is not widespread.\nLet’s implement our first QC method in PLINK.\n We use ln -sf to link the data folder and create a folder for output files (Results/GWAS3)\n\nln -sf ../Data\nmkdir -p Results/GWAS3\n\nPLINK program uses options implemented using the -- symbol to perform different functions or access files. We will use the option --bfile for data (filename without extension), --missing for missing data summary, and --out for output prefixes. This helps us analyze data missingness.\n\nplink --bfile Data/HapMap_3_r3_1 --missing --out Results/GWAS3/data\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS3/data.log.\nOptions in effect:\n  --bfile Data/HapMap_3_r3_1\n  --missing\n  --out Results/GWAS3/data\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1457897 variants loaded from .bim file.\n165 people (80 males, 85 females) loaded from .fam.\n112 phenotype values loaded from .fam.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 112 founders and 53 nonfounders present.\nCalculating allele frequencies... done.\nWarning: 225 het. haploid genotypes present (see Results/GWAS3/data.hh ); many\ncommands treat these as missing.\nTotal genotyping rate is 0.997378.\n--missing: Sample missing data report written to Results/GWAS3/data.imiss, and\nvariant-based missing data report written to Results/GWAS3/data.lmiss.\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nPLINK prints a lot of information. Make sure you read it.\n\nWhich file formats are read by PLINK to understand the data?\nWhat is the percentage of valid genotype data?\nWhat is the count of females and males? Is sex information available for all individuals?\nWhat files are generated as output from the command?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nPLINK reads two files in the format .fam and .bim for this task. As explained in the notebook GWAS2, these files contain data for individuals and variants, respectively.\nImmediately we can see that the total genotyping rate for our sample is 0.997378.\nIt counts 80 males and 85 females.\nIt prints the name of the two output files from this command: data.imiss and data.lmiss, in the directory Results/GWAS3/. These files show the proportion of missing SNPs per individual and the proportion of missing individuals per SNP, respectively.\n\n\n\n\nThese files include a header and one line per sample or per variant, containing the following fields:\n\nFID: Family ID\nIID: Within-family ID\nCHR and SNP: chromosome and SNP ID.\nMISS_PHENO: Indicates if the phenotype is missing (Y/N)\nN_MISS: Number of missing genotype calls (excluding obligatory missings or heterozygous haploids)\nN_GENO: Number of potentially valid calls\nF_MISS: Missing call rate\n\nLet’s check the first 5 lines of the files to understand their structure.\n\nAre there missing phenotypes or genotypes in the .imiss file?\n\n\nhead -5 Results/GWAS3/data.imiss\n\n    FID       IID MISS_PHENO   N_MISS   N_GENO   F_MISS\n   1328   NA06989          N     4203  1457897 0.002883\n   1377   NA11891          N    20787  1457897  0.01426\n   1349   NA11843          N     1564  1457897 0.001073\n   1330   NA12341          N     6218  1457897 0.004265\n\n\nNo, the first individuals of the imiss file do not seem to miss phenotypes (column MISS_PHENO) and have small proportion of missing genotypes (column F_MISS).\n\nWhat about at the variant-level (.lmiss)?\n\n\nhead -5 Results/GWAS3/data.lmiss\n\n CHR         SNP   N_MISS   N_GENO   F_MISS\n   1   rs2185539        0      165        0\n   1  rs11510103        4      165  0.02424\n   1  rs11240767        0      165        0\n   1   rs3131972        0      165        0\n\n\nIn the lmiss file, we can see that the second variant has missing data (4 missing genotype calls).\n Switch to the R kernel.\nWe can visualize the distribution of missing data in individuals and SNPs using histograms in R (change kernel).\nThe ggplot2 package is used here for visualization and various plot elements are combined with the + symbol. Histograms are saved in your results directory as histimiss.png and histlmiss.png. Look below at the R code and the output.\n\nsuppressWarnings(library(ggplot2))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nindmiss &lt;- read.table(file=\"Results/GWAS3/data.imiss\", header=TRUE)\nsnpmiss &lt;- read.table(file=\"Results/GWAS3/data.lmiss\", header=TRUE)\n\n#lmiss histogram\nhist.lmiss &lt;- ggplot(snpmiss, aes(x=snpmiss[,5])) +\n    geom_histogram(binwidth = 0.005, col = \"black\", fill=\"tomato\") + \n    labs(title = \"Frequency of missingness rates in SNPs\") + \n    xlab(\"Frequency\") + \n    ylab(\"Missingness in SNPs\") + \n    theme_bw() +\n    theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n\n#imiss histogram\nhist.imiss &lt;- ggplot(indmiss, aes(x=indmiss[,6])) +\n    geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n    labs(title = \"Frequency of missingness rates in individuals\") + \n    xlab(\"Frequency\") + \n    ylab(\"Missingness in Individuals\") + \n    theme_bw() +\n    theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n#show histograms\nshow(hist.lmiss)\nshow(hist.imiss)\n\n# Save plots silently\nsuppressMessages({\nggsave(plot=hist.lmiss, filename=\"Results/GWAS3/histlmiss.png\");\nggsave(plot=hist.imiss, filename=\"Results/GWAS3/histimiss.png\");\n})\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nWhat is the highest percentage of missingness for a SNP?\nAre there individuals with no missing data?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere are a few observations we can make. Firstly, it’s clear that very few individuals have no missing data at all. One interpretation could be that one or a few SNPs are poorly genotyped across all samples. Fortunately, this isn’t the case here, otherwise the first plot would show many more SNPs with high missing frequency. As shown in the SNP-based histogram, the highest percentage of missing data for a SNP is around 0.05 (5%). Overall, the histogram provides insight into how applying a missingness filter will affect the size of your remaining data.\n\n\n\n Switch to the Bash kernel.\nNext, we will use PLINK to filter the data using missingness thresholds to ensure data quality.\nWe choose a 2% missingness threshold for both individuals and SNP, as only a few outliers exceed this rate (this threshold does not need to be the same for SNPs and individuals). Below, we provide the command to remove samples (--mind) and SNPs (--geno) above this threshold. The --out option defines the output prefix, and --make-bed denotes the output format (consisting of the three files .bed, .bim, .fam).\nPLINK provides detailed output during execution, so check the printed text to monitor progress.\n\n# Delete samples with missing call freq &gt; 2% and SNPs with missingness &gt; 2%\nplink --bfile Data/HapMap_3_r3_1 \\\n    --geno .02 \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_geno\n\nplink --bfile Results/GWAS3/HapMap_geno \\\n    --mind .02 \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_3_r3_2\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS3/HapMap_geno.log.\nOptions in effect:\n  --bfile Data/HapMap_3_r3_1\n  --geno .02\n  --make-bed\n  --out Results/GWAS3/HapMap_geno\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1457897 variants loaded from .bim file.\n165 people (80 males, 85 females) loaded from .fam.\n112 phenotype values loaded from .fam.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 112 founders and 53 nonfounders present.\nCalculating allele frequencies... done.\nWarning: 225 het. haploid genotypes present (see Results/GWAS3/HapMap_geno.hh\n); many commands treat these as missing.\nTotal genotyping rate is 0.997378.\n27454 variants removed due to missing genotype data (--geno).\n1430443 variants and 165 people pass filters and QC.\nAmong remaining phenotypes, 56 are cases and 56 are controls.  (53 phenotypes\nare missing.)\n--make-bed to Results/GWAS3/HapMap_geno.bed + Results/GWAS3/HapMap_geno.bim +\nResults/GWAS3/HapMap_geno.fam ... done.\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS3/HapMap_3_r3_2.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_geno\n  --make-bed\n  --mind .02\n  --out Results/GWAS3/HapMap_3_r3_2\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1430443 variants loaded from .bim file.\n165 people (80 males, 85 females) loaded from .fam.\n112 phenotype values loaded from .fam.\n0 people removed due to missing genotype data (--mind).\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 112 founders and 53 nonfounders present.\nCalculating allele frequencies... done.\nWarning: 179 het. haploid genotypes present (see Results/GWAS3/HapMap_3_r3_2.hh\n); many commands treat these as missing.\nTotal genotyping rate is 0.997899.\n1430443 variants and 165 people pass filters and QC.\nAmong remaining phenotypes, 56 are cases and 56 are controls.  (53 phenotypes\nare missing.)\n--make-bed to Results/GWAS3/HapMap_3_r3_2.bed + Results/GWAS3/HapMap_3_r3_2.bim\n+ Results/GWAS3/HapMap_3_r3_2.fam ... done.\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nWhat happened during filtering?\n\nHow many individuals and variants were removed?\nCan you preview the output files? Which command do you need for each file? Use it to print the first 5 lines of each file.\nWhy are you warned all the time that you have haploid genotypes present? Hint: one of the SNPs listed in the file with extension .hh can be seen here on the UCSC genome browser\n\n\n\n\n# Write code here - fam file\n\n\n# Write code here - bim file\n\n\n# Write code here - bed file\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we read the message from plink, only 1 individual has been removed, while 26686 variants where above the filtering threshold.\nWe can see a preview of the output files: those are again a set of fam, bim and bed file including only the data passing the filters. For the first two formats we can use head, while for the bed file we need also xxd because of the binary nature of the file.\n\nhead -5 Results/GWAS3/HapMap_3_r3_2.fam\n\n1328 NA06989 0 0 2 2\n1377 NA11891 0 0 1 2\n1349 NA11843 0 0 1 1\n1330 NA12341 0 0 2 2\n1344 NA10850 0 NA12058 2 -9\n\n\n\nhead -5 Results/GWAS3/HapMap_3_r3_2.bim\n\n1   rs2185539   0   556738  T   C\n1   rs11240767  0   718814  T   C\n1   rs3131972   0   742584  A   G\n1   rs3131969   0   744045  A   G\n1   rs1048488   0   750775  C   T\n\n\n\nxxd -b Results/GWAS3/HapMap_3_r3_2.bed | head -5\n\n00000000: 01101100 00011011 00000001 11111111 11111111 11111111  l.....\n00000006: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000000c: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000012: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000018: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n\n\nNow, if you looked into the file HapMap_3_r3_2.hh, you could look at the first SNP on the UCSC genome browser and find out it is on chromosome X\n\nhead -5 Results/GWAS3/HapMap_3_r3_2.hh\n\n1355    NA12413 rs2034740\n1355    NA12413 rs6641142\n1355    NA12413 rs7059273\n1355    NA12413 rs1482812\n1420    NA12003 rs12387774\n\n\nWhat happens is your data contains heterozygous genotypes on haploid chromosomes (such as the X chromosome in males or the Y/MT chromosomes), which is biologically not feasible. These genotypes are usually counted as missing in most tools. You are welcome to look at other SNPs on the UCSC browser, you will find out they are on those chromosomes.",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#plink-commands",
    "href": "develop/GWAS3-QualityControlA.html#plink-commands",
    "title": "Quality Control: initial steps",
    "section": "PLINK Commands",
    "text": "PLINK Commands\nThis sex check can be performed in PLINK using the --check-sex option. The results are outputted in the file with extension .sexcheck (in the Results/GWAS4 folder) in which the sex is in column PEDSEX (1 means male and 2 means female) and the inbreeding coefficient is in column F).\nGenerally, males should have an X chromosome homozygosity estimate &gt;0.8 and females should have a value &lt;0.2. So we could simply remove any individuals where the homozygosity estimate (F) does not match their specified sex. Subjects who do not fulfill these requirements are flagged PROBLEM by PLINK in the output file.\nNote the option --silent to avoid long texts printed out on the screen.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_2 --check-sex --out Results/GWAS3/HapMap_3_r3_2 --silent\n\nWarning: 179 het. haploid genotypes present (see Results/GWAS3/HapMap_3_r3_2.hh\n); many commands treat these as missing.\n\n\n Switch to the R kernel.\nWe can visualize the results of the sex check by plotting three histograms for the F values in males, females, and all samples. Let’s look at all sexes and males first.\n\n# Inbreeding coefficients for all sexes and for males/females separately\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R and subset for sexes\nsex &lt;- read.table(\"Results/GWAS3/HapMap_3_r3_2.sexcheck\", header=T,as.is=T)\nmale &lt;- subset(sex, sex$PEDSEX==1)\n\n# sex inbreeding coeff histogram\nhist.sex &lt;- ggplot(sex, aes(x=sex[,6])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"Values of F for all sexes\") + \n  xlab(\"F\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n\n# Inbreeding coeff in males histogram\nhist.male &lt;- ggplot(male, aes(x=male[,6])) +\n  geom_histogram(col = \"black\", fill=\"blue\", bins=50) + \n  labs(title = \"Values of F for males\") + \n  xlab(\"F\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n\nshow(hist.sex)\nshow(hist.male)\n\n# Save plots \nggsave(plot=hist.sex, filename=\"Results/GWAS3/histsex.png\")\nggsave(plot=hist.male, filename=\"Results/GWAS3/histmale.png\")\n\n\n\n\n\n\n\n\nSaving 6.67 x 6.67 in image\nSaving 6.67 x 6.67 in image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\n\nDo the plots look as you would expect?\n\n\nModify the code above to plot the F values for females and save the plot as Results/GWAS3/histfemale.png\n\n\nWhat can you conclude about the distribution of inbreeding coefficients between males and females? (pay attention to the axis ranges)\n\n\n\n\n\n# Write your code here - female F values histogram \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nYes.\nYou need to change the value sex$PEDSEX==2 instead of ==1 in the code for the histogram, and change the file name at the end\n\n\n# B) \n\n# subset females \nfemale &lt;- subset(sex, sex$PEDSEX==2)\n\n# Inbreeding coeff in females histogram\nhist.female &lt;- ggplot(female, aes(x=female[,6])) +\n  geom_histogram(col = \"black\", fill=\"blue\", bins=50) + \n  labs(title = \"Values of F for females\") + \n  xlab(\"F\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n# Show hist\nshow(hist.female)\n\n# Save plot \nggsave(plot=hist.female, filename=\"Results/GWAS3/histfemale.png\")\n\nSaving 6.67 x 6.67 in image\n\n\n\n\n\n\n\n\n\n\nThe inbreeding coefficient plot indicates that there is one woman with a sex discrepancy (F value of 0.99). When using other datasets often a few discrepancies might be found.\n\n\n\n\n\n\nHow can we proceed?\nWe have two options when dealing with sex discrepancy. One is to simply remove any individual with sex discrepancy. In our case, this would involve removing the female with the F value of 0.99.\n Switch to the Bash kernel.\nRemoval can be done with the command below. Use grep to find lines in the sexcheck file that contain PROBLEM. Then, pipe (send) the output to the command awk (using the so-called pipe symbol |). awk will extract the first two columns from each line identified by the grep command and redirect them to the file sex_discrepancy.txt using the symbol &gt; (redirecting the output away from the screen/terminal).\n\ngrep \"PROBLEM\" Results/GWAS3/HapMap_3_r3_2.sexcheck | awk '{print$1,$2}' &gt; Results/GWAS3/sex_discrepancy.txt\n\nShow the content of the file using cat:\n\ncat Results/GWAS3/sex_discrepancy.txt\n\n1349 NA10854\n\n\nFor long files, you can simply count the number of lines in the file with wc (word count command)\n\nwc -l Results/GWAS3/sex_discrepancy.txt\n\n1 Results/GWAS3/sex_discrepancy.txt\n\n\nThe file can be provided to PLINK for removal of sex-discrepant individuals using the option --remove:\n\nplink --bfile Results/GWAS3/HapMap_3_r3_2 \\\n    --remove Results/GWAS3/sex_discrepancy.txt \\\n    --make-bed --out Results/GWAS3/HapMap_3_r3_3 \\\n    --silent\n\nWarning: 179 het. haploid genotypes present (see Results/GWAS3/HapMap_3_r3_3.hh\n); many commands treat these as missing.\n\n\n\n\n\n\n\n\nAlternative approach\n\n\n\nThe other approach supported by PLINK is to impute the sex codes based on the SNP data, which is done with the command --impute-sex as shown below.\nplink --bfile Results/GWAS3/HapMap_3_r3_2 --impute-sex --make-bed --out Results/GWAS3/HapMap_3_r3_3_alt\n\nPLINK automatically detects and imputes incorrect sex information, requiring just an additional option to be specified. However, we will not be executing this command. Instead, we will retain only the dataset where incorrect sexes have already been filtered out: Results/GWAS3/HapMap_3_r3_3.",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#plink-commands-1",
    "href": "develop/GWAS3-QualityControlA.html#plink-commands-1",
    "title": "Quality Control: initial steps",
    "section": "PLINK commands",
    "text": "PLINK commands\nFiltering data based on the minor allele frequencies is done in a similar way to previous commands. If you want to get rid only of the fixed SNPs, you specify a MAF threshold of 0, which can be done by the command --maf 0.\n\n\n\n\n\n\nWarning\n\n\n\nOne should limit MAF analysis to only autosomal chromosomes, meaning you need to generate a subset of the data containing only autosomal chromosomes as done below.\n\n\nFirst, we extract the SNP identifiers from chromosomes 1 to 22 with awk, and redirect the output to the file snp_1_22.txt. Then, PLINK can extract those SNPs using the option --extract:\n\n# Get a file with autosomal variants\nawk '{ if ($1 &gt;= 1 && $1 &lt;= 22) print $2 }' Results/GWAS3/HapMap_3_r3_3.bim &gt; Results/GWAS3/snp_1_22.txt\n# Filter data based on the list of SNPs\nplink --bfile Results/GWAS3/HapMap_3_r3_3 \\\n    --extract Results/GWAS3/snp_1_22.txt \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_3_r3_4 \\\n    --silent\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nHow can you verify if only the autosomal regions are present in the output? Retrieve a list of chromosomes present in one of the files with the prefix Results/GWAS3/HapMap_3_r3_4.\n\n\n\n# write your code\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSNPs are saved in the output bim file and the first column contains the chromosome names. So, we just need to extract the first column, and check the unique names (as extra, we count how many times each chromosome occurs):\n\ncut -f 1 Results/GWAS3/HapMap_3_r3_4.bim | uniq -c\n\n 117459 1\n 117501 2\n  97341 3\n  86388 4\n  88819 5\n  92037 6\n  75919 7\n  75777 8\n  64180 9\n  74379 10\n  71812 11\n  68941 12\n  52335 13\n  45626 14\n  42284 15\n  45090 16\n  38729 17\n  41141 18\n  26437 19\n  36624 20\n  19415 21\n  20310 22\n\n\nYou can do exactly the same with awk\n\nawk '{print$1}' Results/GWAS3/HapMap_3_r3_4.bim | uniq -c\n\n 117459 1\n 117501 2\n  97341 3\n  86388 4\n  88819 5\n  92037 6\n  75919 7\n  75777 8\n  64180 9\n  74379 10\n  71812 11\n  68941 12\n  52335 13\n  45626 14\n  42284 15\n  45090 16\n  38729 17\n  41141 18\n  26437 19\n  36624 20\n  19415 21\n  20310 22\n\n\n\n\n\n\nNow that we have a set of files containing only autosomal chromosomes, let’s obtain summary statistics for the minor allele frequency and plot the values on a histogram. This can be done using the --freq option in PLINK.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nTry to write the PLINK command below before reviewing the command provided.\nHint: Remember most PLINK commands are written in this basic form:\nplink --bfile INPUT --out OUTPUT\nwith the additional option --make-bed if you need to generate a modified version of the data. Now you want to calculate the MAF of the data, so --make-bed is not needed, but you need the option --freq to calculate frequencies from the INPUT. You will need to give a name for the output containing the frequencies. Use the INPUT Results/GWAS3/HapMap_3_r3_4 (the last data in use) and the OUTPUT Results/GWAS3/MAF_check.\n\n\n\n# Your PLINK command\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere the correct command. Check if it matches yours (the --silent option is to avoid long outputs on the screen, but has no effect on data)\n\n# Generate a plot of the MAF distribution.\nplink --bfile Results/GWAS3/HapMap_3_r3_4 --freq --out Results/GWAS3/MAF_check --silent\n\n\n\n\n\n Switch to the R kernel.\nLet’s plot the MAF histogram using R. We will have a second plot, which is a zoom-in version with MAF up to 0.1 to better observe the low MAF values. Note: The zoom-in version will throw some warnings as data points are removed, but don’t worry about it.\n\n# MAF plot only for autosomal SNPs. Note the zoomed interval (0,0.1)\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nmaf_freq &lt;- read.table(\"Results/GWAS3/MAF_check.frq\", header =TRUE, as.is=T)\n\nsummary(maf_freq$MAF)\n\n# maf_freq histogram\nhist.maf &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"MAF distribution\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  theme_bw()\n\n# zoom-in into X-axis\nhist.maf.zoom &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins = 10) + \n  labs(title = \"Zoom into MAF distribution up to value 0.1\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  xlim(0, 0.1) +\n  theme_bw()\n\n\nshow(hist.maf)\nshow(hist.maf.zoom)\n\n# Save plot\nsuppressMessages(ggsave(plot=hist.maf, filename=\"Results/GWAS3/histmaf.png\"))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.05856 0.18750 0.20315 0.33480 0.50000 \n\n\nWarning message:\n“Removed 929441 rows containing non-finite outside the scale range\n(`stat_bin()`).”\nWarning message:\n“Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Switch to the Bash kernel.\nAs stated above, your MAF threshold depends on sample size, though a conventional MAF threshold for a regular GWAS is between 0.01 and 0.05. Here, to ensure the inclusion of only SNPs we will apply a MAF threshold of 0.05 (that is, remove SNPs where the MAF is 5% or less). The threshold is given with the option --maf:\n\n# Remove SNPs with a low MAF frequency.\nplink --bfile Results/GWAS3/HapMap_3_r3_4 \\\n    --maf 0.05 \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_3_r3_5 \\\n    --silent\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nDetermine the number of SNPs remaining after applying quality control measures. Hint: Check the .bim file from the output with the prefix Results/GWAS3/HapMap_3_r3_5.\nRepeat the process for a MAF threshold of 0.01. How many additional SNPs would be retrieved? Do not overwrite the output from the command above! Please, rename the output prefix (e.g. Results/GWAS3/HapMap_3_r3_5_alt)\n\n\n\n\n# Write your code here - maf &gt; 0.05\n\n\n# Write your code here - maf &gt; 0.01\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCheck the number of lines of the .bim file using wc -l and modify the plink command from above:\n\nwc -l Results/GWAS3/HapMap_3_r3_5.bim\n\n1073226 Results/GWAS3/HapMap_3_r3_5.bim\n\n\n\n# plink filtering step\nplink --bfile Results/GWAS3/HapMap_3_r3_4 \\\n    --maf 0.01 \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_3_r3_5_alt \\\n    --silent\n    \n# get number of variants\nwc -l Results/GWAS3/HapMap_3_r3_5_alt.bim\n\n1181555 Results/GWAS3/HapMap_3_r3_5_alt.bim\n\n\nThe difference between the two threshold is ~100,000 SNPS\n\n\n\n\nIt is worth noting that no matter what the sample size is, monomorphic SNPs (i.e., SNPs that show no genetic variation whatsoever in the sample) are usually problematic and should always be removed. Some code crashes when monomorphic SNPs are included; even if this wasn’t the case, these SNPs cannot possibly be informative in a genome-wide association study.",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#plink-commands-2",
    "href": "develop/GWAS3-QualityControlA.html#plink-commands-2",
    "title": "Quality Control: initial steps",
    "section": "PLINK commands",
    "text": "PLINK commands\nWe can use the option --hardy in PLINK to generate H-W p-values (as well as observed and expected heterozygosity). Then, use awk to select SNPs (column 9 of the file) with HWE p-value &lt; 0.0001, indicating a strong deviation from HWE.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_5 --hardy --out Results/GWAS3/HapMap_3_r3_5 --silent\n\nawk '{ if ($9 &lt;0.00001) print $0 }' Results/GWAS3/HapMap_3_r3_5.hwe &gt; Results/GWAS3/HapMap_3_r3_5.deviating.hwe\n\nWhat can we conclude about the data from the generated files?\n Switch to the R kernel.\nLet’s plot a histogram of the HWE p-values and zoom in for the deviating p-values. To do this, we need to read the PLINK output and examine the table with the low HWE p-values. The header of the PLINK output includes the following fields:\n\nCHR: Chromosome number.\nSNP: SNP identifier (rsID).\nTEST: Type of HWE test performed. This will usually be “UNAFF” for the test on controls if your data has case/control status.\nA1: First allele (reference allele).\nA2: Second allele (alternate allele).\nGENO: Genotype counts in the format “HOM1/HET/HOM2”, where HOM1 is the count of homozygous for the first allele, HET is the count of heterozygous, and HOM2 is the - count of homozygous for the second allele.\nO(HET): Observed heterozygote frequency.\nE(HET): Expected heterozygote frequency.\nP: Hardy-Weinberg equilibrium exact test p-value.\n\nWe will modify the values in the TEST column to have more readable names for the plots and save the updated values in the Phenotype column.\n\n# HWE tables\nsuppressMessages(suppressWarnings(library(dplyr)))\n\n# Read data into R using dplyr library \nhwe &lt;- read.table(file=\"Results/GWAS3/HapMap_3_r3_5.hwe\", header=TRUE)\nhwe_zoom &lt;- read.table(file=\"Results/GWAS3/HapMap_3_r3_5.deviating.hwe\", header=FALSE)\n# Add column names \ncolnames(hwe_zoom) &lt;- colnames(hwe)\n# Modify colnames \nhwe$Phenotype &lt;- recode(hwe$TEST, \"ALL\"=\"All\", \"UNAFF\"=\"Control\", \"AFF\"=\"Non-Control\")\nhwe_zoom$Phenotype &lt;- recode(hwe_zoom$TEST, \"ALL\"=\"All\", \"UNAFF\"=\"Control\", \"AFF\"=\"Non-Control\")\n\nHere, we print the first rows of the two generated tables\n\nhead(hwe)\nhead(hwe_zoom)\n\n\nA data.frame: 6 × 10\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\nPhenotype\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n\n\n\n\n1\n1\nrs3131972\nALL\nA\nG\n2/33/77\n0.2946\n0.2758\n0.7324\nAll\n\n\n2\n1\nrs3131972\nAFF\nA\nG\n1/19/36\n0.3393\n0.3047\n0.6670\nNon-Control\n\n\n3\n1\nrs3131972\nUNAFF\nA\nG\n1/14/41\n0.2500\n0.2449\n1.0000\nControl\n\n\n4\n1\nrs3131969\nALL\nA\nG\n2/26/84\n0.2321\n0.2320\n1.0000\nAll\n\n\n5\n1\nrs3131969\nAFF\nA\nG\n1/17/38\n0.3036\n0.2817\n1.0000\nNon-Control\n\n\n6\n1\nrs3131969\nUNAFF\nA\nG\n1/9/46\n0.1607\n0.1771\n0.4189\nControl\n\n\n\n\n\n\nA data.frame: 6 × 10\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\nPhenotype\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;chr&gt;\n\n\n\n\n1\n3\nrs7623291\nALL\nT\nC\n22/28/62\n0.2500\n0.4362\n8.938e-06\nAll\n\n\n2\n7\nrs34238522\nALL\nC\nT\n0/64/48\n0.5714\n0.4082\n3.515e-06\nAll\n\n\n3\n8\nrs3102841\nALL\nC\nA\n8/78/23\n0.7156\n0.4905\n1.899e-06\nAll\n\n\n4\n9\nrs354831\nALL\nC\nT\n12/18/82\n0.1607\n0.3047\n6.339e-06\nAll\n\n\n5\n9\nrs10990625\nALL\nC\nT\n23/28/61\n0.2500\n0.4424\n9.391e-06\nAll\n\n\n6\n9\nrs10990625\nAFF\nC\nT\n15/8/33\n0.1429\n0.4483\n3.574e-07\nNon-Control\n\n\n\n\n\nNow, we can plot the histograms. We isolate each “phenotype” to see if there are any significant differences in p-value distribution between them.\n\n# HWE p-values calculated with PLINK and zoom for the SNPs deviating from HWE. We can spot some deviations from HWE in the zoomed plot. Note that the p+values for the phenotype `All` is not the merging of the barplots from the other two phenotypes!\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# maf_freq histogram\nhist.hwe &lt;- ggplot(hwe, aes(x=hwe[,9])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"HWE distribution\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  facet_wrap(~Phenotype) +\n  theme_bw() + \n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15),strip.text = element_text(size = 14))\n\n# maf_freq histogram\nhist.hwe_below_threshold &lt;- ggplot(hwe_zoom, aes(x=hwe_zoom[,9])) +\n  geom_histogram(binwidth = 0.0000015, col = \"black\", fill=\"tomato\") + \n  labs(title = \"HWE distribution for strongly deviating SNPs only\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  facet_wrap(~Phenotype) +\n  theme_bw() +\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=10.5), plot.title=element_text(size=15),strip.text = element_text(size = 14))\n\nshow(hist.hwe)\nshow(hist.hwe_below_threshold)\n\n# Save plots \nsuppressMessages({\nggsave(plot=hist.hwe, filename=\"Results/GWAS3/histhwe.png\");\nggsave(plot=hist.hwe_below_threshold, filename=\"Results/GWAS3/histhwe_below_threshold.png\");})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Switch to the Bash kernel.\nAlmost all of our SNPs are in HWE, as determined by testing whether the alleles follow a binomial distribution. However, in our zoomed-in plot, we can spot a few extreme deviations. We can remove these outliers using the option --hwe in PLINK with the specified threshold. Note that --hwe filters only on controls, so if you want to apply the threshold to non-controls as well, add the include-nonctrl in the command. In the first step below, we filter controls using a threshold of 1e-6, followed by filtering all phenotypes with a threshold 1e-10:\n\n# filter applied to controls \nplink --bfile Results/GWAS3/HapMap_3_r3_5 --hwe 1e-6 --make-bed --out Results/GWAS3/HapMap_3_r3_5_onlycontrols\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS3/HapMap_3_r3_5_onlycontrols.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_5\n  --hwe 1e-6\n  --make-bed\n  --out Results/GWAS3/HapMap_3_r3_5_onlycontrols\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073226 variants loaded from .bim file.\n164 people (80 males, 84 females) loaded from .fam.\n112 phenotype values loaded from .fam.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 112 founders and 52 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998039.\n--hwe: 0 variants removed due to Hardy-Weinberg exact test.\n1073226 variants and 164 people pass filters and QC.\nAmong remaining phenotypes, 56 are cases and 56 are controls.  (52 phenotypes\nare missing.)\n--make-bed to Results/GWAS3/HapMap_3_r3_5_onlycontrols.bed +\nResults/GWAS3/HapMap_3_r3_5_onlycontrols.bim +\nResults/GWAS3/HapMap_3_r3_5_onlycontrols.fam ... done.\n\n\n\n# threshold apply to all ind\nplink --bfile Results/GWAS3/HapMap_3_r3_5_onlycontrols --hwe 1e-10 include-nonctrl --make-bed --out Results/GWAS3/HapMap_3_r3_6\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS3/HapMap_3_r3_6.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_5_onlycontrols\n  --hwe 1e-10 include-nonctrl\n  --make-bed\n  --out Results/GWAS3/HapMap_3_r3_6\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073226 variants loaded from .bim file.\n164 people (80 males, 84 females) loaded from .fam.\n112 phenotype values loaded from .fam.\nUsing 1 thread (no multithreaded calculations invoked).\nBefore main variant filters, 112 founders and 52 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998039.\n--hwe: 0 variants removed due to Hardy-Weinberg exact test.\n1073226 variants and 164 people pass filters and QC.\nAmong remaining phenotypes, 56 are cases and 56 are controls.  (52 phenotypes\nare missing.)\n--make-bed to Results/GWAS3/HapMap_3_r3_6.bed + Results/GWAS3/HapMap_3_r3_6.bim\n+ Results/GWAS3/HapMap_3_r3_6.fam ... done.\n\n\nThis was just an example to show the commands, but you can notice how the filter removed 0 variants.\n\n\n\n\n\n\nNote\n\n\n\nWhy using a softer filtering threshold for HWE? HWE test assumes that the population is randomly mating without strong selection, migration, or genotyping errors. Since cases may be under selective pressure due to the disease, they may deviate from HWE due to association with the phenotype rather than genotyping errors or population structure.\nThus it is better to choose a lower threshold for cases, or avoiding filtering them at all according to HWE.",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/GWAS3-QualityControlA.html#plink-commands-3",
    "href": "develop/GWAS3-QualityControlA.html#plink-commands-3",
    "title": "Quality Control: initial steps",
    "section": "PLINK commands",
    "text": "PLINK commands\nPLINK does not provide a summary of individual heterozygosity. To assess this, we first prune the dataset by excluding highly correlated SNPs, as they reduce analysis power. We use --indep-pairwise &lt;window size&gt;['kb'] &lt;step size (variant ct)&gt; &lt;r^2 threshold&gt; to prune SNPs in high Linkage Disequilibrium, excluding high inversion regions (--exclude with Data/inversion.txt). For more information, click here.\nIn our case, the parameters for the --indep-pairwise are 50 5 0.2 representing the window size, shift-window step count, and correlation threshold for pruning. Once we have the pruned list, we will check heterozygosity on the set of SNPs that are not highly correlated.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_6 \\\n    --exclude Data/inversion.txt \\\n    --range \\\n    --indep-pairwise 50 5 0.2 \\\n    --out Results/GWAS3/indepSNP \\\n    --silent\n\nWith this pruned list, we measure the heterozygosity rates of the individuals in the remaining independent SNPs.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_6 \\\n    --extract Results/GWAS3/indepSNP.prune.in \\\n    --het \\\n    --out Results/GWAS3/R_check \\\n    --silent\n\n Switch to the R kernel.\nNow, let’s plot the distribution of heterozygosity rates. Again, we will first examine the heterozygosity table. The --het option in PLINK generates an output table with the following columns:\n\nFID: Individual’s Family ID.\nIID: Individual ID within the family.\nO(HOM): Observed number of homozygous genotypes.\nE(HOM): Expected number of homozygous genotypes under Hardy-Weinberg equilibrium.\nN(NM): Number of non-missing autosomal genotypes.\nF: Inbreeding coefficient, which is calculated as \\(\\tfrac{(E(HOM)−O(HOM))}{N(NM)}\\).\n\n\nhet &lt;- read.table(\"Results/GWAS3/R_check.het\", head=TRUE)\nhead(het)\n\n\nA data.frame: 6 × 6\n\n\n\nFID\nIID\nO.HOM.\nE.HOM.\nN.NM.\nF\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1328\nNA06989\n67039\n67470\n103911\n-0.0117200\n\n\n2\n1377\nNA11891\n66847\n66840\n102970\n0.0001494\n\n\n3\n1349\nNA11843\n67262\n67560\n104071\n-0.0082900\n\n\n4\n1330\nNA12341\n66654\n67400\n103826\n-0.0205100\n\n\n5\n1444\nNA12739\n66687\n66560\n102519\n0.0036020\n\n\n6\n1344\nNA10850\n67421\n67520\n104001\n-0.0027780\n\n\n\n\n\nWe will calculate the heterozygosity rates manually for plotting, as they are not included by default in the table. The formula is \\(N(NM)-O(HOM)/N(NM)\\)\n\n# Barplot for heterozigosity rates\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\n# plink.imiss histogram\nhist.het &lt;- ggplot(het, aes(x=HET_RATE)) +\n  geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Heterozygosity Rates\") + \n  xlab(\"Heterozygosity Rate\") + \n  ylab(\"Frequency\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=10.5), plot.title=element_text(size=15))\n\n\nshow(hist.het)\n\n# Save plots \nsuppressMessages(ggsave(plot=hist.het, filename=\"Results/GWAS3/heterozygosity.png\"))\n\n\n\n\n\n\n\n\nAs a rule of thumb, we remove individuals whose heterozygosity deviates (sd) more than 3 standard deviations from the mean. We will create a file that subsets the heterozygosity table based on this threshold for use in PLINK removal. Additionally, we’ll add a HET_DST column to the table containing the standardized heterozygosity values.\n\nsuppressMessages(suppressWarnings(library(dplyr)))\n\n# read file \nhet &lt;- read.table(\"Results/GWAS3/R_check.het\", head=TRUE)\n# add column with heterozygocity rates\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\n# Substract inds that deviate more than sd=3 from the mean \nhet_fail &lt;- subset(het, (het$HET_RATE &lt; mean(het$HET_RATE)-3*sd(het$HET_RATE)) | \n                    (het$HET_RATE &gt; mean(het$HET_RATE)+3*sd(het$HET_RATE)))\n\n# Add column with standardized heterozygosity rates\nhet_fail$HET_DST &lt;- (het_fail$HET_RATE-mean(het$HET_RATE))/sd(het$HET_RATE)\n\n# write file \nwrite.table(het_fail, \"Results/GWAS3/fail-het-qc.txt\", row.names=FALSE, quote=FALSE)\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThe output of the R code is saved as fail-het-qc.txt. Let’s check how many individuals are picked up as having a heterozygosity rate deviating more than 3 SDs from the mean.\nHint: wc -l counts only the lines in the file (incl. header).\n Switch to the Bash kernel.\n\n\n\n#Write your code here\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can count 3 lines (one is the header), meaning there are two individuals to be filtered out. To use the file in PLINK, we need only the first two columns (Family ID and Individual ID) as shown below\n\nwc -l Results/GWAS3/fail-het-qc.txt\n\n3 Results/GWAS3/fail-het-qc.txt\n\n\nWe need the first two columns to create the list of individuals to remove.\n\ncat Results/GWAS3/fail-het-qc.txt\n\nFID IID O.HOM. E.HOM. N.NM. F HET_RATE HET_DST\n1330 NA12342 68049 67240 103571 0.02229 0.342972453679119 -3.66711854374478\n1459 NA12874 68802 67560 104068 0.0339 0.338874582004074 -5.04839854982741\n\n\nWe use awk to print out the first two columns in the file het-fail-ind.txt and the option --remove to filter out the individuals using PLINK.\n\nawk '{print$1, $2}' Results/GWAS3/fail-het-qc.txt &gt; Results/GWAS3/het-fail-ind.txt\n\nplink --bfile Results/GWAS3/HapMap_3_r3_6 \\\n    --remove Results/GWAS3/het-fail-ind.txt \\\n    --make-bed \\\n    --out Results/GWAS3/HapMap_3_r3_7 \\\n    --silent\n\nAfter all filtering is done, we can count the number of individuals and variants\n\nwc -l Results/GWAS3/HapMap_3_r3_7.fam\nwc -l Results/GWAS3/HapMap_3_r3_7.bim\n\n162 Results/GWAS3/HapMap_3_r3_7.fam\n1073226 Results/GWAS3/HapMap_3_r3_7.bim\n\n\nLook back at the very first run of PLINK. We had 1457897 SNPs and 165 individuals. We filtered out around 1/3 of all SNPs!\n\n\n\n\n\n\n\n\n\n\nChallenge yourself: first quality control on mice data\n\n\n\nWe continue working with the mice data. Now we want to do a quality control workflow as we did before. Try to repeat all the steps, excluding the sex discrepancies, which cannot be done due to the missing sex chromosomes in the data:\n1 - Missingness analysis and filtering, both per SNP and per individual.\n2 - Minor Allele Frequency. Note: The number of chromosomes is different in this dataset.\n3 - Hardy-Weinberg Equilibrium. Note: This data contains case-control, so you don’t need to rename the columns hwe$Phenotype and hwe_zoom$Phenotype. Similarly, avoid using include-nonctrl in PLINK. In the R code, you will also want to avoid the line with facet_wrap separating the group Phenotype for plotting.\n4 - Heterozigosity rate. Note: You do not have a list of regions with inversions, so do not use --exclude Data/inversion.txt --range in PLINK.\nGeneral notes for the exercise:\n\nCopy-paste all the commands you need from the tutorial, but remember to carefully check that the file names and options are correct to be used in your data.\nUse proper file names for the output of PLINK when filtering and creating new bed/bim/fam files. For example, when you apply the various filterings, create a new output name prefix instead of keeping use mice. Start from mice, then create mice_miss, mice_miss_maf, mice_miss_maf_hwe, mice_miss_maf_hwe_het, so that you can trace back all your work to each analysis step.\nFeel free to play with the code for creating plots (e.g. changing colors and cutoff values).\nMake use of Generative AI to get help for the code if you think it is not enough to use what is provided in the tutorial, or if you want to explore something beyond the exercise.\n\n\n\n\n\n\n\n\n\nClick to view answers\n\n\n\n mice-solutions.ipynb\n\n\n\n\n\n\n\n\nWrapping up\n\n\n\nIn this tutorial, we have tried several quality control approaches in PLINK and calculated various statistics, which we visualized using R. In the next notebook, you will find even more examples of how you verify the quality of your data.\nA table with a small recap of the options used in filtering with PLINK\n\n\n\n\n\n\n\n\n\nStep\nCommand\nFunction\nThresholds and explanation\n\n\n\n\n1: Missingness of SNPs\n--geno\nExcludes SNPs that are missing in a large proportion of the subjects. In this step, SNPs with low genotype calls are removed\nWe recommend first filtering SNPs and individuals based on a relaxed threshold (0.2; &gt;20%), as this will filter out SNPs and individuals with very high levels of missingness. Then a filter with a more stringent threshold can be applied (0.02)\n\n\n2: Missingness of individuals\n--mind\nExcludes individuals who have high rates of genotype missingness. In this step, individuals with low genotype calls are removed\nNote, SNP filtering should be performed before individual filtering\n\n\n3: Sex discrepancy\n--check-sex\nChecks for discrepancies between the sex of the individuals recorded in the dataset and their sex based on X chromosome heterozygosity/homozygosity rates\nCan indicate sample mix‐ups. If many subjects have this discrepancy, the data should be checked carefully. Males should have an X chromosome homozygosity estimate &gt;0.8 and females should have a value &lt;0.2\n\n\n4: Minor allele frequency (MAF)\n--maf\nIncludes only SNPs above the set MAF threshold\nSNPs with a low MAF are rare, therefore power is lacking for detecting SNP‐phenotype associations. These SNPs are also more prone to genotyping errors. The MAF threshold should depend on your sample size, larger samples can use lower MAF thresholds. Respectively, for large (N = 100.000) vs. moderate samples (N = 10000), 0.01 and 0.05 are commonly used as MAF thresholds\n\n\n5: Hardy-Weinberg equilibrium (HWE)\n--hwe\nExcludes markers which deviate from Hardy–Weinberg equilibrium\nCommon indicator of genotyping error, may also indicate evolutionary selection. For binary traits, we suggest excluding: HWE p-value &lt;1e−10 in cases and &lt;1e−6 in controls. A less strict case threshold avoids discarding disease‐associated SNPs under selection. For quantitative traits, we recommend HWE p-value &lt;1e‐6.\n\n\n6: Heterozygosity\nR code + --remove option in PLINK\nExcludes individuals with high or low heterozygosity rates\nDeviations can indicate sample contamination and inbreeding. We suggest removing individuals who deviate ±3 SD from the samples’ heterozygosity rate mean",
    "crumbs": [
      "Tutorials",
      "Quality Control",
      "Quality Control: initial steps"
    ]
  },
  {
    "objectID": "develop/exercises/gwas3-mice.html",
    "href": "develop/exercises/gwas3-mice.html",
    "title": "Mice data exercise",
    "section": "",
    "text": "Perform the following filtering analysis:\n\n1. Missingness and filtering, both at the variant- and individual-level.\n2. Minor Allele Frequency filtering.\n3. Hardy-Weinberg Equilibrium.\n4. Heterozygosity rate.\n\n Switch to the Bash kernel.\n\nln -sf ../../Data\nln -sf ../Results\n\n\n1. Filtering excessive missing values.\nFirst of all, we begin by producing the sample-wise and variant-wise missing reports in the format .imiss and .lmiss. Note that sex will not be considered at all by PLINK as mentioned in the warning.\n\nplink --bfile Data/mice --missing --out Results/GWAS3/mice --silent\n\nWarning: Ignoring phenotypes of missing-sex samples.  If you don't want those\nphenotypes to be ignored, use the --allow-no-sex flag.\n\n\n Switch to the R-GWAS kernel.\nNow we look at the histograms. The only thing needed to change in the code, compared to the tutorial, is the name of the two missingness reports.\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nindmiss &lt;- read.table(file=\"Results/GWAS3/mice.imiss\", header=TRUE)\nsnpmiss &lt;- read.table(file=\"Results/GWAS3/mice.lmiss\", header=TRUE)\n\n#imiss histogram\nhist.imiss &lt;- ggplot(indmiss, aes(x=indmiss[,6])) +\n  geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Frequency of missingness rates in individuals\") + \n  xlab(\"Frequency\") + \n  ylab(\"Missingness in Individuals\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n#lmiss histogram\nhist.lmiss &lt;- ggplot(snpmiss, aes(x=snpmiss[,5])) +\n  geom_histogram(binwidth = 0.005, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Frequency of missingness rates in SNPs\") + \n  xlab(\"Frequency\") + \n  ylab(\"Missingness in SNPs\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n#show histograms\nshow(hist.imiss)\nshow(hist.lmiss)\n\nWarning message:\n“package ‘ggplot2’ was built under R version 4.2.3”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histograms do not show any high missingness for the variants (second plot), while there are a few individuals that we should filter out. Below, we filter only individuals with missingness above 2%, without choosing any variant filter. The new bed, bim, fam files have the prefix mice_miss\n\nplink --bfile Data/mice --mind .02 --make-bed --out Results/GWAS3/mice_miss --silent\n\nWarning: Ignoring phenotypes of missing-sex samples.  If you don't want those\nphenotypes to be ignored, use the --allow-no-sex flag.\n\n\n\n\n2. Minimum Allele Frequency.\nLet’s calculate the MAF values using --freq:\n\n# Generate a plot of the MAF distribution.\nplink --bfile Results/GWAS3/mice_miss --freq --out Results/GWAS3/mice_miss --silent\n\n Switch to the R-GWAS kernel.\nLet’s plot the MAF histogram using R. The second plot, is a zoom-in version with MAF up to 0.1 to observe the low MAF values.\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nmaf_freq &lt;- read.table(\"Results/GWAS3/mice_miss.frq\", header =TRUE, as.is=T)\n\n# maf_freq histogram\nhist.maf &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"MAF distribution\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n# zoom-in into X-axis\nhist.maf.zoom &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins = 10) + \n  labs(title = \"Zoom into MAF distribution up to value 0.1\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  xlim(-.01, 0.1) +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n\nshow(hist.maf)\nshow(hist.maf.zoom)\n\nWarning message:\n“package ‘ggplot2’ was built under R version 4.2.3”\nWarning message:\n“Removed 2611 rows containing non-finite outside the scale range (`stat_bin()`).”\nWarning message:\n“Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).”\n\n\n\n\n\n\n\n\n\n\n\n(a) MAF plot for the autosomal SNPs only. Note the zoomed interval (0, 0.1)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 1\n\n\n\n\nThere are two minor peaks in the histograms above, one at 0.05 and 0.1. Choosing 0.1 would remove over a hundred extra SNPs, while 0.05 should remove around less than 200. We can for example choose 0.05, but 0.1 is acceptable as well as it is another threshold often applied in literature.\n\n# Remove SNPs with a low MAF frequency.\nplink --bfile Results/GWAS3/mice_miss --maf 0.05 --make-bed --out Results/GWAS3/mice_miss_maf --silent\n\n\n\n3. Hardy Weinberg Equilibrium.\nHere we need again to apply the option hardy to calculate observed and expected heterozigous frequencies and p-values for the binomial test. Note how column TEST considers all individuals ( ALL(NP) stands for ALL Not Pruned).\n\nplink --bfile Results/GWAS3/mice_miss_maf --hardy --out Results/GWAS3/mice_miss_maf --silent\n\nawk '{ if ($9 &lt;0.00001) print $0 }' Results/GWAS3/mice_miss_maf.hwe &gt; Results/GWAS3/mice_miss_maf.deviating.hwe\n\n\nhead Results/GWAS3/mice_miss_maf.hwe \n\n CHR                  SNP     TEST   A1   A2                 GENO   O(HET)   E(HET)            P \n   1            rs3683945  ALL(NP)    A    G         358/1002/572   0.5186   0.4939      0.03035\n   1            rs3707673  ALL(NP)    G    A         359/1003/572   0.5186   0.4939      0.03048\n   1            rs6269442  ALL(NP)    A    G          252/887/791   0.4596    0.461       0.8824\n   1            rs6336442  ALL(NP)    A    G         358/1003/572   0.5189   0.4939      0.02714\n   1           rs13475700  ALL(NP)    A    C          33/442/1458   0.2287   0.2283            1\n   1            rs3658242  ALL(NP)    A    T         359/1003/572   0.5186   0.4939      0.03048\n   1           rs13475701  ALL(NP)    C    G          33/481/1417   0.2491   0.2432       0.3045\n   1            rs6198069  ALL(NP)    A    G          186/802/945   0.4149   0.4229       0.4197\n   1            rs3659303  ALL(NP)    A    G         360/1001/571   0.5181    0.494      0.03419\n\n\n\nwc -l Results/GWAS3/mice_miss_maf.deviating.hwe\n\n356 Results/GWAS3/mice_miss_maf.deviating.hwe\n\n\nThere are 355 variants to remove with a p-value below 0.00001\n Switch to the R-GWAS kernel.\nNow we create histograms to look at the p-values from the tables above. We do not need to use the case-control renaming and plotting categories.\n\nsuppressMessages(suppressWarnings(library(dplyr)))\n\n# Read data into R using dplyr library \nhwe &lt;- read.table(file=\"Results/GWAS3/mice_miss_maf.hwe\", header=TRUE)\nhwe_zoom &lt;- read.table(file=\"Results/GWAS3/mice_miss_maf.deviating.hwe\", header=FALSE)\ncolnames(hwe_zoom) &lt;- colnames(hwe)\n\nHere, we print the first rows of the two generated tables\n\nhead(hwe)\nhead(hwe_zoom)\n\n\n\n\n\n\n\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\nrs3683945\nALL(NP)\nA\nG\n358/1002/572\n0.5186\n0.4939\n0.03035\n\n\n2\n1\nrs3707673\nALL(NP)\nG\nA\n359/1003/572\n0.5186\n0.4939\n0.03048\n\n\n3\n1\nrs6269442\nALL(NP)\nA\nG\n252/887/791\n0.4596\n0.4610\n0.88240\n\n\n4\n1\nrs6336442\nALL(NP)\nA\nG\n358/1003/572\n0.5189\n0.4939\n0.02714\n\n\n5\n1\nrs13475700\nALL(NP)\nA\nC\n33/442/1458\n0.2287\n0.2283\n1.00000\n\n\n6\n1\nrs3658242\nALL(NP)\nA\nT\n359/1003/572\n0.5186\n0.4939\n0.03048\n\n\n\n\n\n(a) HWE tables from PLINK\n\n\n\n\n\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\nrs13475729\nALL(NP)\nG\nA\n46/339/1549\n0.1753\n0.1980\n3.014e-06\n\n\n2\n1\nrs13475730\nALL(NP)\nG\nA\n46/339/1547\n0.1755\n0.1982\n3.079e-06\n\n\n3\n1\nrs3654377\nALL(NP)\nG\nA\n46/339/1549\n0.1753\n0.1980\n3.014e-06\n\n\n4\n1\nrs3655978\nALL(NP)\nA\nG\n46/339/1545\n0.1756\n0.1984\n3.146e-06\n\n\n5\n1\nrs13475731\nALL(NP)\nA\nG\n46/339/1548\n0.1754\n0.1981\n3.046e-06\n\n\n6\n1\nrs3670630\nALL(NP)\nA\nC\n46/339/1545\n0.1756\n0.1984\n3.146e-06\n\n\n\n\n\n\nFigure 2: A data.frame: 6 × 9\n\n\n\n\nNow, we can plot the histograms\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# maf_freq histogram\nhist.hwe &lt;- ggplot(hwe, aes(x=hwe[,9])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"HWE distribution\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n# maf_freq histogram\nhist.hwe_below_threshold &lt;- ggplot(hwe_zoom, aes(x=hwe_zoom[,9])) +\n  geom_histogram(binwidth = 0.0000015, col = \"black\", fill=\"tomato\") + \n  labs(title = \"HWE distribution for strongly deviating SNPs only\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\nshow(hist.hwe)\nshow(hist.hwe_below_threshold)\n\n\n\n\n\n\n\n\n\n\n(a) HWE p-values calculated with PLINK and zoom for the SNPs deviating from HWE.\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 3\n\n\n\n\nWe choose the threshold 1e-5 and create the new filtered data files:\n\nplink --bfile Results/GWAS3/mice_miss_maf --hwe 1e-5 --make-bed --out Results/GWAS3/mice_miss_maf_hwe --silent\n\n\n\n4. Heterozigosity rate.\nNow we look at genotype calls at each individual’s level. First, we create a list of SNPs for which there is lower correlation, so to avoid linkage disequilibrium.\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe --indep-pairwise 50 5 0.2 --out Results/GWAS3/mice_indepSNP --silent\n\nWith this pruned list, we measure the heterozygosity rates of the individuals in the remaining independent SNPs.\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe \\\n    --extract Results/GWAS3/mice_indepSNP.prune.in \\\n    --het \\\n    --out Results/GWAS3/mice_R_check \\\n    --silent\n\nHow does the table with the SNPs look like?\n\nhead -5 Results/GWAS3/mice_R_check.het\n\n         FID          IID       O(HOM)       E(HOM)        N(NM)            F\n  A048005080   A048005080          112        109.5          184      0.03357\n  A048006063   A048006063          111        109.5          184      0.02015\n  A048006555   A048006555          105        109.5          184     -0.06039\n  A048007096   A048007096           94        109.5          184       -0.208\n\n\n Switch to the R-GWAS kernel.\nWe are going to calculate by hand the heterozygosity rates so we can plot them (not by default in the table). The formula for the rates is \\(N(NM)-O(HOM)/N(NM)\\)\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\nhet &lt;- read.table(\"Results/GWAS3/mice_R_check.het\", head=TRUE)\n\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\n# plink.imiss histogram\nhist.het &lt;- ggplot(het, aes(x=HET_RATE)) +\n  geom_histogram(binwidth = 0.01, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Heterozygosity Rates\") + \n  xlab(\"Heterozygosity Rate\") + \n  ylab(\"Frequency\") + \n  theme_bw()\n\n\nshow(hist.het)\n\nWarning message:\n“package ‘ggplot2’ was built under R version 4.2.3”\n\n\n\n\n\n\n\n\nFigure 4: Barplot of heterozigosity rates.\n\n\n\n\n\nWe use the same filter for all individuals as applied to the other dataset (heterozigosity rate 3 standard deviations away from the mean)\n\nsuppressMessages(suppressWarnings(library(dplyr)))\n\nhet &lt;- read.table(\"Results/GWAS3/mice_R_check.het\", head=TRUE)\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\nhet_fail &lt;- subset(het, (het$HET_RATE &lt; mean(het$HET_RATE)-3*sd(het$HET_RATE)) | \n                    (het$HET_RATE &gt; mean(het$HET_RATE)+3*sd(het$HET_RATE)))\n\nhet_fail$HET_DST &lt;- (het_fail$HET_RATE-mean(het$HET_RATE))/sd(het$HET_RATE);\n\nwrite.table(het_fail, \"Results/GWAS3/mice-fail-het-qc.txt\", row.names=FALSE, quote=FALSE)\n\nThe resulting table contains a few outlying individuals:\n\nwc -l Results/GWAS3/mice-fail-het-qc.txt\n\n9 Results/GWAS3/mice-fail-het-qc.txt\n\n\nWe use awk to print out the first two columns in the file het-fail-ind.txt and use the option --remove to filter out the individuals with PLINK.\n\nawk '{print$1, $2}' Results/GWAS3/mice-fail-het-qc.txt &gt; Results/GWAS3/mice-het-fail-ind.txt\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe \\\n    --remove Results/GWAS3/mice-het-fail-ind.txt \\\n    --make-bed \\\n    --out Results/GWAS3/mice_QCA \\\n    --silent\n\nWe can count again samples and variants\n\nwc -l Results/GWAS3/mice_QCA.fam\nwc -l Results/GWAS3/mice_QCA.bim\n\n1926 Results/GWAS3/mice_QCA.fam\n2439 Results/GWAS3/mice_QCA.bim\n\n\n\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "develop/workshop.html#access-sandbox-resources",
    "href": "develop/workshop.html#access-sandbox-resources",
    "title": "Welcome to GWAS with the Genomics Sandbox",
    "section": "Access Sandbox resources",
    "text": "Access Sandbox resources\nOur first choice is to provide all the training materials, tutorials, and tools as interactive apps on UCloud, the supercomputer located at the University of Southern Denmark. Anyone using these resources needs the following:\n\na Danish university ID so you can sign on to UCloud via WAYF1.\n\n \n\n for UCloud Access click here \n\n \n\nbasic ability to navigate in Linux/R/Jupyter. You don’t need to be an expert, but it is beyond our ambitions (and course material) to teach you how to code from zero and how to run analyses simultaneously. We recommend a basic R or Python course before diving in.\nFor workshop participants: Use our invite link to the correct UCloud workspace that will be shared on the day of the workshop. This way, we can provide you with compute resources for the active sessions of the workshop2. Click the link below to accept the invitation (after accessing UCloud for the first time).\n\n \n\n Invite link to UCloud workspace \n\n \n\nDownload the slides\n\n\n Download slides \n\n\nEXTRA EXERCISE - GWAS4\n\nYou can download an extra notebook and data with population structure and effect of LD on that. Upload the files through jupyterlab, and copy the data in the data folder and the notebook in the notebooks folder:\n\n Download data \n\n\n Download notebook \n\n\nEXTRA EXERCISE - LDAK\n\nA notebook with an analysis using LDAK for preprocessing and some of the implemented association testings and heritability estimates\n\n Download notebook \n\n\nCourse evaluation survey - The Novo Nordisk Foundation funds the Sandbox project and is interested in the outcomes of our training activities, so we really appreciate your responses!\n\n \n\n Evaluation survey link"
  },
  {
    "objectID": "develop/workshop.html#discussion-and-feedback",
    "href": "develop/workshop.html#discussion-and-feedback",
    "title": "Welcome to GWAS with the Genomics Sandbox",
    "section": "Discussion and feedback",
    "text": "Discussion and feedback\nWe hope you enjoyed the workshop. If you have broader questions, suggestions, or concerns, now is the time to raise them! Remember that you can check out longer versions of our tutorials as well as other topics and tools in each of the Sandbox modules. All of our open-source materials are available on our Github page and can be used on any computing cluster! We regularly run workshops on a variety of health data science topics that you can also check out (follow our news here).\n \n\n\n\n\n\n\n\nNice meeting you and we hope to see you again!"
  },
  {
    "objectID": "develop/workshop.html#footnotes",
    "href": "develop/workshop.html#footnotes",
    "title": "Welcome to GWAS with the Genomics Sandbox",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOther institutions (e.g. hospitals, libraries, …) can log on through WAYF. See all institutions here.↩︎\nTo use Sandbox materials outside of the workshop: remember that each new user has hundreds of hours of free computing credit and around 50GB of free storage, which can be used to run any UCloud software. If you run out of credit (which takes a long time) you’ll need to check with the local DeiC office at your university about how to request compute hours on UCloud. Contact us at the Sandbox if you need help or want more information.↩︎"
  },
  {
    "objectID": "develop/GWAS2-DataCollectionA.html",
    "href": "develop/GWAS2-DataCollectionA.html",
    "title": "Data collection",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nThis course module introduces fundamental concepts regarding designing and executing GWAS. We touch on data collection (which involves gathering genomic data and phenotypic information from diverse populations), potential biases, and practical considerations on the standard file formats in GWAS.\n\n\n\nUnderstand and identify types of GWAS studies in the scientific literature",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data collection"
    ]
  },
  {
    "objectID": "develop/GWAS2-DataCollectionA.html#learning-outcomes",
    "href": "develop/GWAS2-DataCollectionA.html#learning-outcomes",
    "title": "Data collection",
    "section": "",
    "text": "Understand and identify types of GWAS studies in the scientific literature",
    "crumbs": [
      "Tutorials",
      "Introduction",
      "Data collection"
    ]
  },
  {
    "objectID": "develop/GWAS5b-PopulationStratification.html",
    "href": "develop/GWAS5b-PopulationStratification.html",
    "title": "Population stratification",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAs we’ve discussed, removing population structure is crucial, as residual population stratification—highlighted by (Sohail et al. 2019)—can even be detected in published GWAS. This can lead to biased effect size estimates, impacting polygenic risk scores and other downstream analyses. In this notebook, we will further explore one way of detecting population stratification in GWAS. Since we were uncertain whether we were being too strict when correcting for population structure, or if the GWAS lacked sufficient power, this analysis will help us clarify if we can trust our results.\n\n\n\nIdentify potential population stratification in our GWAS output.\n\n\n\n\n\nIn this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Population stratification"
    ]
  },
  {
    "objectID": "develop/GWAS5b-PopulationStratification.html#learning-outcomes",
    "href": "develop/GWAS5b-PopulationStratification.html#learning-outcomes",
    "title": "Population stratification",
    "section": "",
    "text": "Identify potential population stratification in our GWAS output.",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Population stratification"
    ]
  },
  {
    "objectID": "develop/GWAS5b-PopulationStratification.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS5b-PopulationStratification.html#how-to-make-this-notebook-work",
    "title": "Population stratification",
    "section": "",
    "text": "In this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Population stratification"
    ]
  },
  {
    "objectID": "develop/cards/AlbaMartinez.html",
    "href": "develop/cards/AlbaMartinez.html",
    "title": "Alba Refoyo Martinez",
    "section": "",
    "text": "Alba is a Sandbox data scientist based at the University of Copenhagen. During her academic background as a PhD and Postdoc she has developed a solid expertise in large-scale genomics and pipelines development on computing clusters.\n\n\n\nCopyrightCC-BY-SA 4.0 license"
  },
  {
    "objectID": "develop/GWAS7-PRSII.html",
    "href": "develop/GWAS7-PRSII.html",
    "title": "Polygenic scores II",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nIn this notebook, we have data for a toy quantitative trait, so you’ll need to perform a basic polygenic risk score analysis and explore the results in a manner similar to what we did in the previous notebook.\n\n\n\nDiscuss and choose the PRS equation\nDiscuss PRS scores and biases\n\n\n\n\n\nWe will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores II"
    ]
  },
  {
    "objectID": "develop/GWAS7-PRSII.html#learning-outcomes",
    "href": "develop/GWAS7-PRSII.html#learning-outcomes",
    "title": "Polygenic scores II",
    "section": "",
    "text": "Discuss and choose the PRS equation\nDiscuss PRS scores and biases",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores II"
    ]
  },
  {
    "objectID": "develop/GWAS7-PRSII.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS7-PRSII.html#how-to-make-this-notebook-work",
    "title": "Polygenic scores II",
    "section": "",
    "text": "We will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel",
    "crumbs": [
      "Tutorials",
      "Association Testing",
      "Polygenic scores II"
    ]
  }
]