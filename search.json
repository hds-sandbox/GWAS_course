[
  {
    "objectID": "access/UCloud.html",
    "href": "access/UCloud.html",
    "title": "Accessing the GWAS workshop on",
    "section": "",
    "text": "1. User accounts on UCloud are enabled by university login credentials using WAYF (Where Are You From). Access the WAYF login portal with the button below here, and then find your affiliated university or institution using the search bar.\n \n\n UCloud Access - click here \n\n \n\n\n\n\n\n\nGWAS with the sandbox\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, click AFTER logging in on the button below. This will add you to a project on uCloud, where we have data and extra computing credit for the course. You should see a message on your browser where you have to accept the invitation to the project. The link expires 30 days after the course.\n \n#\n\n\n\n\n\nInvite link\n\n\nfor the course\n\n\n\n#\n\n \n\n\n\n2. Once you are an approved user of UCloud, you are met with a dashboard interface as below. Here you can see a summary of the workspace you are using, like the hours of computing, the storage available, and other informations. The workspace you are working on is shown in the top-right corner (red circle). On the left side of the screen you have a toolbar menu.\n\n \n\n\n\n\n\n\nNGS summer school\n\n\n\nIf you are participating in the NGS Summer Course 2024 in Aarhus, choose the workspace NGS summer school.\n\n\n\n3. The left-side menu can be used to access the stored data, applications, running programs and settings. Use the Applications symbol (red circle) and click on the Health Science store (green circle).\n\n5. Your screen will show some apps falling in the Health Science subcategory. Click on the Genomics Sandbox application to open its settings.\n\n6. Choose any Job Name (Nr 1 in the figure below), how many hours you want to use for the job (Nr 2, choose at least 2 hours, you can increase this later), and how many CPUs (Nr 3, choose at least 4 CPUs for the first three exercises, but use at least 8 CPUs to run the single cell analysis). Select the Introduction to NGS Data Analysis as course (Nr 4). Then click on Submit (Nr 5).\n\n7. You will be waiting in a queue looking like this\n\n8. As soon as there are resources, you will have them available, and in a short time the course will be ready to run. The screen you get is in the image below. Here you can increase the number of hours you want the session to run (red circle), close the session (green circle) and open the interface for coding (blue circle)\n\n\n\n\n\n\n\nTip\n\n\n\nOnce you open the coding interface, it does not matter if you close the browser tab with the countdown timer. You can always access it again from the toolbar menu of uCloud. Simply click on jobs and choose your session from the list of running softwares:\n\n\n\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\nRecovering the material from your previous session\nIt would be annoying to start from scratch at each session, with all the analysis to be executed again. You can of course find all the notebooks and results in your personal user folder in the workspace in which you are working.\nTo retrieve your work add the folders Data and Notebooks in the submission page of the Genomics App. Those are inside your user folder (called member Files: NameSurname#Number) under Jobs/Genomics Sandbox/SessionName. For example, look at how the Data folder is added from a previous session:\n\nYou need to do the same thing for the folder Notebooks. In the end you should have two folders added in your setup page just as below:"
  },
  {
    "objectID": "access/genomedk.html",
    "href": "access/genomedk.html",
    "title": "Accessing the GWAS workshop on GenomeDK",
    "section": "",
    "text": "If you are using GenomeDK, you have two options. One is to use a pre-packaged Docker container, which contains jupyterlab and the necessary packages to run all the notebooks. GenomeDK comes with singularity, which can import and execute Docker containers and is able to ensure full reproducibility of the analysis. The second option is to download the github repository of the course and create your own conda environment: this solution works also on any computing cluster where you can have conda installed and is shown in the page dedicate to the access with any computing cluster."
  },
  {
    "objectID": "access/genomedk.html#singularity-container",
    "href": "access/genomedk.html#singularity-container",
    "title": "Accessing the GWAS workshop on GenomeDK",
    "section": "Singularity container",
    "text": "Singularity container\n1. Log into the cluster using the command line, and substituting USERNAME with your actual user name:\nssh USERNAME@login.genome.au.dk\nand be sure to run those two commands to remove space-filling cache data, which can make everything slower after a few times you run tutorials\n\nrm -rf ~/.apptainer/cache/*\nrm -rf ~/.singularity/cache/*\n2. Get into a folder inside your project, for example\n\ncd MYPROJECT/ngsSummerSchool\n\n\n\n\n\n\nWarning\n\n\n\nDo not work directly in your home folder /home/username, as this has a limit of 100GB of space available. Work instead inside a previously established project folder.\n\n\n3. Use singularity to download the container of the course. This will take some time and show a lot of text, and at the end a file called course.sif is created into the folder.\n\nsingularity pull course.sif docker://hdssandbox/ngssummerschool:2024.07\n\n\n\n\n\n\nWarning\n\n\n\nYou need to do this step only once!\n\n\n4. Activate tmux: this will make things run in backround. If you lose your internet connection, the course material will still be up and running when the connection is back on your pc! Use the command\n\ntmux\nThe command line will change a bit its aspect. Now it’s time to get a few resources to run all the material. We suggest one CPU and 32GB of RAM for the first three modules, and 2 CPUs and 64GB of RAM for the single-cell analysis. For the first configuration suggested, for example, you get resources using\n\n\nsrun --mem=32g --cores=1 --time=4:0:0  --account=MYPROJECT --pty /bin/bash\n\n\n\n\n\n\nNote\n\n\n\nNote you always need your project name, and you can also choose for how long you want the resources to be available to you. Asking for resources means waiting for some time in a queue before they are assigned.\nIn the example above time is 4 hours. After this time, whatever you are doing will be closed, so be sure to save your work in progress.\n\n\n5. execute the container with\nsingularity exec course.sif /bin/bash\nNote that the command line shows now Apptainer&gt; on its left. We are inside the container and the tools we need are now available into it.\n6. Now we need to run a configuration script, which will setup the last details and execute jupyterlab. If a folder called Data exists, it will not be downloaded again (also meaning that you can use our container with your own data folder for your own analysis in future)\ngit config --global http.sslVerify false\nwget -qO-  https://raw.githubusercontent.com/hds-sandbox/NGS_summer_course_Aarhus/docker/scripts/courseMaterial.sh | bash\n7. You will see a lot of messages, which is normal. At the end of the messages, you are provided two links looking as in the image below. Write down the node name and the user id highlighted in the circles.\n\nWrote down node and ID? Last step is to create a tunnel between your computer and genomeDK to be able to see jupyterlab in your browser. Now you need to use the node name and the user id you wrote down before! Open a new terminal window on your laptop and write\n\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nwhere you substitute USERID and NODENAME as you wrote down before, and then USERNAME is your account name on GenomeDK. For example ssh -L 6835:s21n81:6835 samuele@login.genome.au.dk according to the figure above for a user with name samuele.\n8. Open your browser and go to the address http://127.0.0.1:USERID/lab, where you need your user id again instead of USERID. For example http://127.0.0.1:6835/lab from the figure above. Jupyterlab opens in your browser.\n9. Now you are ready to use JupyterLab for coding. Use the file browser (on the left-side) to find the folder Notebooks. Select one of the four tutorials of the course. You will see that the notebook opens on the right-side pane. Read the text of the tutorial and execute each code cell starting from the first. You will see results showing up directly on the notebook!\n\n\n\n\n\n\n\nTip\n\n\n\nRight click on a notebook or a saved results file, and use the download option to save it locally on your computer.\n\n\n\nWhat if my internet connection drops?\nNow worries, tmux kept your material up and running. You only need a new terminal window to run the tunneling\n\nssh -L USERID:NODENAME:USERID USERNAME@login.genome.au.dk\nas you did before, so you can continue working!\n\n\nRecovering the material from your previous session\nDo you want to work again on the course material, or recover some analysis? Everything is saved in the folder you were working in. Next time, follow the whole procedure again (without step number 3.) and you can be up and running the course in no time."
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html",
    "href": "develop/GWAS6-PRSAnalysis.html",
    "title": "Polygenic Score analysis",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nThis notebook focuses on polygenic scores, which are used to estimate an individual’s genetic predisposition to complex traits or diseases by combining information from multiple genetic variants previously identified in the GWAS study. It provides a step-by-step guide to performing a basic PRS analysis using PRSice and explains how to interpret the results.\n\n\n\nDiscuss and choose the PRS equation\nDiscuss PRS scores and biases\n\n\n\n\n\nIn this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel\nWhile most individual associations found in GWAS studies are of small effect, information about them can be combined across the genome, to create a polygenic score (PGS). These scores can be used to make genome-based predictions about the overall risk of having a particular trait or disease or about the genetic value for continuous traits. If the prediction is on a discrete phenotype such as a disease, these scores are known as polygenic risk scores (PRS)."
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#learning-outcomes",
    "href": "develop/GWAS6-PRSAnalysis.html#learning-outcomes",
    "title": "Polygenic Score analysis",
    "section": "",
    "text": "Discuss and choose the PRS equation\nDiscuss PRS scores and biases"
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS6-PRSAnalysis.html#how-to-make-this-notebook-work",
    "title": "Polygenic Score analysis",
    "section": "",
    "text": "In this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#computing-a-prs",
    "href": "develop/GWAS6-PRSAnalysis.html#computing-a-prs",
    "title": "Polygenic Score analysis",
    "section": "1. Computing a PRS",
    "text": "1. Computing a PRS\nSingle variant association analysis has been the primary method in GWAS but requires very large sample sizes to detect more than a handful of SNPs for many complex traits. In contrast, PRS analysis does not aim to identify individual SNPs but instead aggregates genetic risk across the genome in a single individual polygenic score for a trait of interest. One straightforward way to obtain a PGS, for a given population, is summing the allele frequencies of statistically significant trait-associated variants, weighted by their effect size after ensuring these variants are approximately independent (e.g. via LD pruning).\nIn this approach, a large discovery sample is required to reliably determine how much each SNP is expected to contribute to the polygenic score (“weights”) of a specific trait. Subsequently, in an independent target sample, which can be more modest in size (Dudbridge 2013), polygenic scores can be calculated based on genetic DNA profiles and these weights (see below for details on the calculations). As a rule of thumb, a target sample of around 2,000 subjects provides sufficient power to detect a significant proportion of variance explained. Furthermore, the discovery and target samples should have the same number of subjects until the target sample includes 2,000 subjects. If more samples are available, additional subjects should be included in the discovery sample to maximize the accuracy of the estimation of the effect sizes (Dudbridge 2013).\nAlthough PRS is not powerful enough to predict disease risk on the individual level (Wray et al. 2013), it has been successfully used to show significant associations both within and across traits. For example, a PRS analysis of schizophrenia showed for the first time that an aggregate measure of the genetic risk of developing schizophrenia, estimated based on the effects of common SNPs (from the discovery sample) that showed nominally significant associations with disease risk, was significantly associated with schizophrenia risk in an independent (target) sample. A significant association was found even though the available sample sizes were too small to detect genome‐wide significant SNPs (Purcell Shaun M. shaun@ pngu. mgh. harvard. edu 1 2 b Wray Naomi R. 5 Stone Jennifer L. 1 2 3 4 Visscher Peter M. 5 O’Donovan Michael C. 6 Sullivan Patrick F. 7 Sklar Pamela 1 2 3 4 et al. 2009). In addition, GWAS for schizophrenia (the discovery sample) has been used to significantly predict the risk in target samples with various phenotypes, such as bipolar disorder, level of creativity, and even risk of immune disorders (Power et al. 2015; Stringer et al. 2014)."
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#conducting-polygenic-risk-prediction-analyses",
    "href": "develop/GWAS6-PRSAnalysis.html#conducting-polygenic-risk-prediction-analyses",
    "title": "Polygenic Score analysis",
    "section": "2. Conducting polygenic risk prediction analyses",
    "text": "2. Conducting polygenic risk prediction analyses\nTo conduct PRS analysis, trait‐specific weights (beta’s for continuous traits and the log of the odds ratios for binary traits) are obtained from a discovery GWAS. In the target sample, a PRS is calculated for each individual based on the weighted sum of the number of risk alleles that they carry multiplied by the trait‐specific weights. For many complex traits, SNP effect sizes are publicly available (e.g., see https://www.med.unc.edu/pgc/downloads or https://www.ebi.ac.uk/gwas/).\nAlthough in principle all common SNPs could be used in a PRS analysis, it is customary to first clump the GWAS results before computing risk scores. P-value thresholds are typically used to remove SNPs that show little or no statistical evidence for association (e.g., only keep SNPs with p-values &lt;0.05 or &lt;0.01). Usually, multiple PRS analyses will be performed, with varying thresholds for the p-values of the association test.\nOnce PRS have been calculated for all subjects in the target sample, the scores can be used in a (logistic) regression analysis to predict any trait that is expected to show genetic overlap with the trait of interest. The prediction accuracy can be expressed with the (pseudo‐) \\(R^2\\) measure of the regression analysis. It is important to include at least a few MDS components as covariates in the regression analysis to control for population stratification. To estimate how much variation is explained by the PRS, the \\(R^2\\) of a model that includes only the covariates (e.g., MDS components) and the \\(R^2\\) of a model that includes covariates + PRS will be compared. The increase in \\(R^2\\) due to the PRS indicates the increase in prediction accuracy explained by genetic risk factors.\nThe prediction accuracy of PRS depends mostly on the (co‐)heritability of the analyzed traits, the number of SNPs, and the size of the discovery sample. The size of the target sample only affects the reliability of \\(R^2\\) and typically a few thousand subjects in the target sample are sufficient to achieve a significant \\(R^2\\) (if the (co‐)heritability of the trait(s) of interest and the sample size of the discovery sample used are sufficiently large).\n\n\n\nFigure 6.1: Prediction of schizophrenia (SCZ) and bipolar disorder (BD) in Iceland using polygenic risk scores derived from independent GWASs of these disorders (Power et al. 2015)"
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-score-analysis-with-prsice-2",
    "href": "develop/GWAS6-PRSAnalysis.html#polygenic-risk-score-analysis-with-prsice-2",
    "title": "Polygenic Score analysis",
    "section": "3. Polygenic risk score analysis with PRSice-2",
    "text": "3. Polygenic risk score analysis with PRSice-2\nTo perform polygenic risk score analysis, one possible tool is PRSice. In this tutorial, we provide a step-by-step guide to perform a simple polygenic risk score analysis using PRSice and explain how to interpret the results.\nWe have supplied PRSice-2 with this course material ready to use.\nThe installed package will include an R script that is straightforward to run. It requires the following information:\n\n--prsice: the binary executable file\n--base: the .assoc file that contains statistical information\n--target: the PLINK-formatted dataset\n\n\n\n\n\n\n\nNote\n\n\n\nIt would be ideal at this point to apply this method to our HapMap dataset. However, as mentioned above, PRS requires a sample size of around 2000 for it to show meaningful results. Our dataset, meanwhile, contains only about 150 individuals. Hence, we will use a toy dataset for didactic purposes.\n\n\n\n3.1 PRSice analysis\n Let’s create a folder for the output files. Then, perform the PRS analysis on the toy dataset in the following way:\n\nmkdir -p Results/GWAS6\ncd Results/GWAS6\n\nCreate two links to data and softwares\n\nln -sf ../Data\nln -sf ../Software\n\nWe will apply PRSice by running the R script PRSice.R, which will create all necessary input files for ./Software/PRSice. We then provide the results of association testing and specify the column names that contain information about SNPs, chromosomes, and other relevant data. This step is necessary because different association tools produce varying header formats. Finally, we will specify the location of our data, which is TOY_TARGET_DATA, and the phenotype format (binary: 0s and 1s).\n\n\n\n\n\n\nWarning\n\n\n\nIf you get an error in the following command, try to restart the kernel in the Kernel menu. Sometimes links to folders are not recognized immediately.\n\n\n\n# Recommendation: check the usage instructions and mandatory input files by uncommenting the command below:  \n# ./Software/PRSice -h\n\n\nRscript ./Data/PRSice.R --out Results/GWAS6/PRSice \\\n--prsice ./Software/PRSice \\\n--base ./Data/TOY_BASE_GWAS.assoc \\\n--snp SNP --chr CHR --bp BP --A1 A1 --A2 A2 --stat OR --pvalue P \\\n--target ./Data/TOY_TARGET_DATA \\\n--binary-target T \n\nPRSice 2.3.5 (2021-09-20) \nhttps://github.com/choishingwan/PRSice\n(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\nGNU General Public License v3\nIf you use PRSice in any published work, please cite:\nChoi SW, O'Reilly PF.\nPRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\nGigaScience 8, no. 7 (July 1, 2019)\n2024-08-07 12:08:59\n./Software/PRSice \\\n    --a1 A1 \\\n    --a2 A2 \\\n    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n    --base ./Data/TOY_BASE_GWAS.assoc \\\n    --binary-target T \\\n    --bp BP \\\n    --chr CHR \\\n    --clump-kb 250kb \\\n    --clump-p 1.000000 \\\n    --clump-r2 0.100000 \\\n    --interval 5e-05 \\\n    --lower 5e-08 \\\n    --num-auto 22 \\\n    --or  \\\n    --out Results/GWAS6/PRSice \\\n    --pvalue P \\\n    --seed 1252005307 \\\n    --snp SNP \\\n    --stat OR \\\n    --target ./Data/TOY_TARGET_DATA \\\n    --thread 1 \\\n    --upper 0.5\n\nInitializing Genotype file: ./Data/TOY_TARGET_DATA (bed) \n\nStart processing TOY_BASE_GWAS \n================================================== \n\nBase file: ./Data/TOY_BASE_GWAS.assoc \nHeader of file is: \nSNP CHR BP A1 A2 P OR \n\nReading 31.61%\n\n\nIOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n\n\nProcessing 100.00%\nThere are 1 region(s) with p-value less than 1e-5. Please \nnote that these results are inflated due to the overfitting \ninherent in finding the best-fit PRS (but it's still best \nto find the best-fit PRS!). \nYou can use the --perm option (see manual) to calculate an \nempirical P-value. \n\nBegin plotting\nCurrent Rscript version = 4.3.2\nPlotting Bar Plot\nPlotting the high resolution plot\n\n\n\n\nThe --base parameter refers to the file with summary statistics from the base sample (also known as discovery or training samples). These summary statistics contain for each genetic variant at least an effect size and p-value.\nThe --target parameter refers to the prefix of the files (without file extension) that contain the genotype data in binary plink format (i.e., .bed,.bim,.fam file extensions). The base and target samples are also known as validation or test samples. This target sample should be completely independent of the base sample that was used to compute the summary statistics. Sample overlap across the discovery and target sample will greatly inflate the association between the polygenic risk score and the disease trait.\n\nIf the type effect (--stat) or data type (--binary-target) were not specified, PRSice will try to determine this information based on the header of the base file.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nCan you use all genomic variants for calculating PRS?\nHow can you determine which variants should be used?\nAre LD blocks shared among populations of different ancestry?\n\nHint: read the [PRSice user manual](https://choishingwan.github.io/PRSice/step_by_step and Berisa and Pickrell (2016)\n\n\n\n\n\n\n\n\nSolution\n\n\n\nHandling correlated SNPs is crucial in polygenic risk score (PRS) analysis, particularly for variants in high linkage disequilibrium (LD). It is not advisable to use all genetic variants without considering LD as it would lead to inflated significance and false positives. A common method to tackle this issue is LD Pred2, which employs a Bayesian approach to adjust SNP effect sizes by accounting for LD patterns.\nPRSice uses a different approach called clumping, where within each block of correlated SNPs, the SNP with the lowest p-value from the discovery set is selected, and the remaining SNPs are excluded from further analysis. This clumping process is automatically performed by PRSice but can be customized using various clumping parameters. For more detailed information about clumping and other available options, refer to the PRSice user manual.\n\n\nFor simplicity’s sake, we did not include principal components or covariates in this analysis, however, when conducting your analyses we strongly recommend including these.\n\n\n3.2 Interpreting the results\nBy default, PRSice saves two plots and several text files. The first plot is PRSice_BARPLOT_&lt;date&gt;.png(which you need to open from the folder Result/GWAS6 using the file browser since the name depends on the current date. Below, you can see a screenshot of the figure). This plot shows the predictive value (Nagelkerke’s) in the target sample of models based on SNPs with p-values below specific thresholds in the base sample. In addition, for each model, a p-value is provided.\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nWhich P-value threshold generated the “best-fit” PRS?\nHow much phenotypic variation does the “best-fit” PRS explain?\n\nHint: Check the PRSice.summary file.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nAs shown in the plot, a model using SNPs with a p-value up to 0.4463 achieves the highest predictive value in the target sample with a p-value of 4.7e-18. However, as is often the case in polygenic risk scores analysis with relatively small samples, the predictive value is relatively low (Nagelkerke’s around 5%). The text files include the exact values for each p-value threshold (check them!).\nThe phenotypic variation (PRS.R2) explained by these variants is 0.05. - PRS.R2: quantifies hoe much of the trait variation is attributable to the genetic variants used in the analysis - Full.R2_ represents the total variance explained by the full model (genetic variants and any other covariates used) - Null.R3: indicated the variance explained by the model without the PRS component (i.e., just the covariates)\n\n\nThe second plot PRSice_HIGH-RES_PLOT_&lt;date&gt;.png (which you again need to manually open, but we show also a screenshot below) shows many different p-value thresholds. The p-value of the predictive effect is in black together with an aggregated trend line in green.\n\nBoth figures demonstrate that many SNPs associated with the trait in the base sample can help predict the trait in the target sample. The traits being compared can be either the same or different. If the same trait is used, the predictive power is related to the trait’s heritability and the base sample size. When different traits are analyzed, the predictive power also depends on the genetic correlation between the two traits. Some studies have suggested that polygenic risk score analyses using models with more lenient p-value thresholds (i.e., including more SNPs) often capture smaller effects that are important for complex traits involving many variants with very small effects. Conversely, more stringent thresholds reduce noise, making it easier to understand the polygenic architecture. Finding the right balance between including informative SNPs and minimizing noise is crucial for maximizing predictive power while maintaining meaningful interpretation.\n\n\nConclusion\nIn this tutorial, we have discussed how to perform a simple polygenic risk score analysis using the PRSice script and how to interpret its results. When PLINK genotype target files are available, PRSice provides a relatively easy way of performing polygenic risk score analysis. As mentioned before, PRSice offers many additional options to adjust the risk score analysis, including adding covariates, and principal components and adjusting clumping parameters. It is therefore recommended to read the user manual of PRSice to perform a polygenic risk score analysis optimal to the research question at hand."
  },
  {
    "objectID": "develop/GWAS6-PRSAnalysis.html#further-reading",
    "href": "develop/GWAS6-PRSAnalysis.html#further-reading",
    "title": "Polygenic Score analysis",
    "section": "Further Reading",
    "text": "Further Reading\n\n\n\n\n\n\nOther take-home messages\n\n\n\n\nPopulation structure can be handled with PCs and mixed models (e.g., BOLT-LMM) (although never perfectly)\nIn large meta-analyses, unlikely that bias would be consistent in most studies\nReplication in (several) other cohorts provides convincing evidence\nApplying stringent statistics (P&lt;5e-8) helps to reduce the likelihood of false-positive results\n\n\n\nThere is only so much one can discuss in a beginner’s practical guide to GWAS. As such, for those who want to expand their knowledge of GWAS, we have provided a comprehensive list of resources for you to read/try out below."
  },
  {
    "objectID": "develop/exercises/gwas3-mice.html",
    "href": "develop/exercises/gwas3-mice.html",
    "title": "Mice data exercise",
    "section": "",
    "text": "Perform the following filtering analysis:\n\n1. Missingness and filtering, both at the variant- and individual-level.\n2. Minor Allele Frequency filtering.\n3. Hardy-Weinberg Equilibrium.\n4. Heterozygosity rate.\n\n\nln -sf ../../Data\nln -sf ../Results\n\n\n1. Filtering excessive missing values.\nFirst of all, we begin by producing the sample-wise and variant-wise missing reports in the format .imiss and .lmiss. Note that sex will not be considered at all by PLINK as mentioned in the warning.\n\nplink --bfile Data/mice --allow-no-sex --missing --out Results/GWAS3/mice --silent\n\n Switch to the R-GWAS kernel.\nNow we look at the histograms. The only thing needed to change in the code, compared to the tutorial, is the name of the two missingness reports.\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nindmiss &lt;- read.table(file=\"Results/GWAS3/mice.imiss\", header=TRUE)\nsnpmiss &lt;- read.table(file=\"Results/GWAS3/mice.lmiss\", header=TRUE)\n\n#imiss histogram\nhist.imiss &lt;- ggplot(indmiss, aes(x=indmiss[,6])) +\n  geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Frequency of missingness rates in individuals\") + \n  xlab(\"Frequency\") + \n  ylab(\"Missingness in Individuals\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n#lmiss histogram\nhist.lmiss &lt;- ggplot(snpmiss, aes(x=snpmiss[,5])) +\n  geom_histogram(binwidth = 0.005, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Frequency of missingness rates in SNPs\") + \n  xlab(\"Frequency\") + \n  ylab(\"Missingness in SNPs\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n#show histograms\nshow(hist.imiss)\nshow(hist.lmiss)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histograms do not show any high missingness for the variants (second plot), while there are a few individuals that we should filter out. Below, we filter only individuals with missingness above 2%, without choosing any variant filter. The new bed, bim, fam files have the prefix mice_miss\n\nplink --bfile Data/mice --mind .02 --allow-no-sex --make-bed --out Results/GWAS3/mice_miss --silent\n\n\n\n2. Minimum Allele Frequency.\nLet’s calculate the MAF values using --freq:\n\n# Generate a plot of the MAF distribution.\nplink --bfile Results/GWAS3/mice_miss --freq --out Results/GWAS3/mice_miss --silent\n\n Switch to the R-GWAS kernel.\nLet’s plot the MAF histogram using R. The second plot, is a zoom-in version with MAF up to 0.1 to observe the low MAF values.\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nmaf_freq &lt;- read.table(\"Results/GWAS3/mice_miss.frq\", header =TRUE, as.is=T)\n\n# maf_freq histogram\nhist.maf &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"MAF distribution\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n# zoom-in into X-axis\nhist.maf.zoom &lt;- ggplot(maf_freq, aes(x=maf_freq[,5])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins = 10) + \n  labs(title = \"Zoom into MAF distribution up to value 0.1\") + \n  xlab(\"MAF\") + \n  ylab(\"Frequency\") +\n  xlim(-.01, 0.1) +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n\nshow(hist.maf)\nshow(hist.maf.zoom)\n\nWarning message:\n“Removed 2611 rows containing non-finite outside the scale range (`stat_bin()`).”\nWarning message:\n“Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).”\n\n\n\n\n\n\n\n\n\n\n\n(a) MAF plot for the autosomal SNPs only. Note the zoomed interval (0, 0.1)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 1\n\n\n\n\nThere are two minor peaks in the histograms above, one at 0.05 and 0.1. Choosing 0.1 would remove over a hundred extra SNPs, while 0.05 should remove around less than 200. We can for example choose 0.05, but 0.1 is acceptable as well as it is another threshold often applied in literature.\n\n# Remove SNPs with a low MAF frequency.\nplink --bfile Results/GWAS3/mice_miss --maf 0.05 --make-bed --out Results/GWAS3/mice_miss_maf --silent\n\n\n\n3. Hardy Weinberg Equilibrium.\nHere we need again to apply the option hardy to calculate observed and expected heterozigous frequencies and p-values for the binomial test. Note how column TEST considers all individuals ( ALL(NP) stands for ALL Not Pruned).\n\nplink --bfile Results/GWAS3/mice_miss_maf --hardy --out Results/GWAS3/mice_miss_maf --silent\n\nawk '{ if ($9 &lt;0.00001) print $0 }' Results/GWAS3/mice_miss_maf.hwe &gt; Results/GWAS3/mice_miss_maf.deviating.hwe\n\n\nhead Results/GWAS3/mice_miss_maf.hwe \n\n CHR                  SNP     TEST   A1   A2                 GENO   O(HET)   E(HET)            P \n   1            rs3683945  ALL(NP)    A    G         358/1002/572   0.5186   0.4939      0.03035\n   1            rs3707673  ALL(NP)    G    A         359/1003/572   0.5186   0.4939      0.03048\n   1            rs6269442  ALL(NP)    A    G          252/887/791   0.4596    0.461       0.8824\n   1            rs6336442  ALL(NP)    A    G         358/1003/572   0.5189   0.4939      0.02714\n   1           rs13475700  ALL(NP)    A    C          33/442/1458   0.2287   0.2283            1\n   1            rs3658242  ALL(NP)    A    T         359/1003/572   0.5186   0.4939      0.03048\n   1           rs13475701  ALL(NP)    C    G          33/481/1417   0.2491   0.2432       0.3045\n   1            rs6198069  ALL(NP)    A    G          186/802/945   0.4149   0.4229       0.4197\n   1            rs3659303  ALL(NP)    A    G         360/1001/571   0.5181    0.494      0.03419\n\n\n\nwc -l Results/GWAS3/mice_miss_maf.deviating.hwe\n\n356 Results/GWAS3/mice_miss_maf.deviating.hwe\n\n\nThere are 355 variants to remove with a p-value below 0.00001\n Switch to the R-GWAS kernel.\nNow we create histograms to look at the p-values from the tables above. We do not need to use the case-control renaming and plotting categories.\n\nsuppressMessages(suppressWarnings(library(dplyr)))\n\n# Read data into R using dplyr library \nhwe &lt;- read.table(file=\"Results/GWAS3/mice_miss_maf.hwe\", header=TRUE)\nhwe_zoom &lt;- read.table(file=\"Results/GWAS3/mice_miss_maf.deviating.hwe\", header=FALSE)\ncolnames(hwe_zoom) &lt;- colnames(hwe)\n\nHere, we print the first rows of the two generated tables\n\nhead(hwe)\nhead(hwe_zoom)\n\n\n\n\n\n\n\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\nrs3683945\nALL(NP)\nA\nG\n358/1002/572\n0.5186\n0.4939\n0.03035\n\n\n2\n1\nrs3707673\nALL(NP)\nG\nA\n359/1003/572\n0.5186\n0.4939\n0.03048\n\n\n3\n1\nrs6269442\nALL(NP)\nA\nG\n252/887/791\n0.4596\n0.4610\n0.88240\n\n\n4\n1\nrs6336442\nALL(NP)\nA\nG\n358/1003/572\n0.5189\n0.4939\n0.02714\n\n\n5\n1\nrs13475700\nALL(NP)\nA\nC\n33/442/1458\n0.2287\n0.2283\n1.00000\n\n\n6\n1\nrs3658242\nALL(NP)\nA\nT\n359/1003/572\n0.5186\n0.4939\n0.03048\n\n\n\n\n\n(a) HWE tables from PLINK\n\n\n\n\n\n\n'ALL(NP)'\n\n\n(b)\n\n\n\n\n\n\n\n\nCHR\nSNP\nTEST\nA1\nA2\nGENO\nO.HET.\nE.HET.\nP\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n1\nrs13475729\nALL(NP)\nG\nA\n46/339/1549\n0.1753\n0.1980\n3.014e-06\n\n\n2\n1\nrs13475730\nALL(NP)\nG\nA\n46/339/1547\n0.1755\n0.1982\n3.079e-06\n\n\n3\n1\nrs3654377\nALL(NP)\nG\nA\n46/339/1549\n0.1753\n0.1980\n3.014e-06\n\n\n4\n1\nrs3655978\nALL(NP)\nA\nG\n46/339/1545\n0.1756\n0.1984\n3.146e-06\n\n\n5\n1\nrs13475731\nALL(NP)\nA\nG\n46/339/1548\n0.1754\n0.1981\n3.046e-06\n\n\n6\n1\nrs3670630\nALL(NP)\nA\nC\n46/339/1545\n0.1756\n0.1984\n3.146e-06\n\n\n\n\n\n\nFigure 2: A data.frame: 6 × 9\n\n\n\n\nNow, we can plot the histograms\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# maf_freq histogram\nhist.hwe &lt;- ggplot(hwe, aes(x=hwe[,9])) +\n  geom_histogram(col = \"black\", fill=\"tomato\", bins=50) + \n  labs(title = \"HWE distribution\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\n# maf_freq histogram\nhist.hwe_below_threshold &lt;- ggplot(hwe_zoom, aes(x=hwe_zoom[,9])) +\n  geom_histogram(binwidth = 0.0000015, col = \"black\", fill=\"tomato\") + \n  labs(title = \"HWE distribution for strongly deviating SNPs only\") + \n  xlab(\"HWE p-value\") + \n  ylab(\"Frequency\") +\n  theme_bw()+\n  theme(axis.title=element_text(size=13), axis.text=element_text(size=13), plot.title=element_text(size=15))\n\nshow(hist.hwe)\nshow(hist.hwe_below_threshold)\n\n\n\n\n\n\n\n\n\n\n(a) HWE p-values calculated with PLINK and zoom for the SNPs deviating from HWE.\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 3\n\n\n\n\nWe choose the threshold 1e-5 and create the new filtered data files:\n\nplink --bfile Results/GWAS3/mice_miss_maf --hwe 1e-5 --make-bed --out Results/GWAS3/mice_miss_maf_hwe --silent\n\n\n\n4. Heterozigosity rate.\nNow we look at genotype calls at each individual’s level. First, we create a list of SNPs for which there is lower correlation, so to avoid linkage disequilibrium.\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe --indep-pairwise 50 5 0.2 --out Results/GWAS3/mice_indepSNP --silent\n\nWith this pruned list, we measure the heterozygosity rates of the individuals in the remaining independent SNPs.\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe --extract Results/GWAS3/mice_indepSNP.prune.in --het --out Results/GWAS3/mice_R_check --silent\n\nHow does the table with the SNPs look like?\n\nhead -5 Results/GWAS3/mice_R_check.het\n\n         FID          IID       O(HOM)       E(HOM)        N(NM)            F\n  A048005080   A048005080          112        109.5          184      0.03357\n  A048006063   A048006063          111        109.5          184      0.02015\n  A048006555   A048006555          105        109.5          184     -0.06039\n  A048007096   A048007096           94        109.5          184       -0.208\n\n\n Switch to the R-GWAS kernel.\nWe are going to calculate by hand the heterozygosity rates so we can plot them (not by default in the table). The formula for the rates is \\(N(NM)-O(HOM)/N(NM)\\)\n\n\n\nlibrary(ggplot2)\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\nhet &lt;- read.table(\"Results/GWAS3/mice_R_check.het\", head=TRUE)\n\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\n# plink.imiss histogram\nhist.het &lt;- ggplot(het, aes(x=HET_RATE)) +\n  geom_histogram(binwidth = 0.01, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Heterozygosity Rates\") + \n  xlab(\"Heterozygosity Rate\") + \n  ylab(\"Frequency\") + \n  theme_bw()\n\n\nshow(hist.het)\n\n\nFigure 4\n\n\n\nWe use the same filter for all individuals as applied to the other dataset (heterozigosity rate 3 standard deviations away from the mean)\n\nsuppressMessages(suppressWarnings(library(dplyr)))\n\nhet &lt;- read.table(\"Results/GWAS3/mice_R_check.het\", head=TRUE)\nhet$HET_RATE = (het$\"N.NM.\" - het$\"O.HOM.\")/het$\"N.NM.\"\n\nhet_fail &lt;- subset(het, (het$HET_RATE &lt; mean(het$HET_RATE)-3*sd(het$HET_RATE)) | \n                    (het$HET_RATE &gt; mean(het$HET_RATE)+3*sd(het$HET_RATE)))\n\nhet_fail$HET_DST &lt;- (het_fail$HET_RATE-mean(het$HET_RATE))/sd(het$HET_RATE);\n\nwrite.table(het_fail, \"Results/GWAS3/mice-fail-het-qc.txt\", row.names=FALSE, quote=FALSE)\n\nThe resulting table contains a few outlying individuals:\n\nwc -l Results/GWAS3/mice-fail-het-qc.txt\n\n9 Results/GWAS3/mice-fail-het-qc.txt\n\n\nWe use awk to print out the first two columns in the file het-fail-ind.txt and use the option --remove to filter out the individuals with PLINK.\n\nawk '{print$1, $2}' Results/GWAS3/mice-fail-het-qc.txt &gt; Results/GWAS3/mice-het-fail-ind.txt\n\nplink --bfile Results/GWAS3/mice_miss_maf_hwe --remove Results/GWAS3/mice-het-fail-ind.txt --make-bed --out Results/GWAS3/mice_QCA --silent\n\nWhat are we left with? 1926 samples with 2439 variants\n\nwc -l Results/GWAS3/mice_QCA.fam\nwc -l Results/GWAS3/mice_QCA.bim\n\n1926 Results/GWAS3/mice_QCA.fam\n2439 Results/GWAS3/mice_QCA.bim"
  },
  {
    "objectID": "develop/GWAS7-OtherToolsAndTesting.html",
    "href": "develop/GWAS7-OtherToolsAndTesting.html",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\n\n\n\n\nExplore LDAK software and some of its functionalities\nDiscuss other tools and conclusions from this tutorial\n\n\n\n\n\nIn this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS7-OtherToolsAndTesting.html#learning-outcomes",
    "href": "develop/GWAS7-OtherToolsAndTesting.html#learning-outcomes",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "Explore LDAK software and some of its functionalities\nDiscuss other tools and conclusions from this tutorial"
  },
  {
    "objectID": "develop/GWAS7-OtherToolsAndTesting.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS7-OtherToolsAndTesting.html#how-to-make-this-notebook-work",
    "title": "Other tools & conclusions",
    "section": "",
    "text": "In this notebook, we will only use the bash command line. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS7-OtherToolsAndTesting.html#ldak",
    "href": "develop/GWAS7-OtherToolsAndTesting.html#ldak",
    "title": "Other tools & conclusions",
    "section": "LDAK",
    "text": "LDAK\nThroughout this tutorial, we have used PLINK as the main method of our GWAS analysis. This is, in large part, due to its popularity in modern literature and its ease of use. But it is by no means the only method of GWAS.\nOne tool that has been developed in recent years is LDAK, by Dough Speed (2012). One of the most significant improvements of this program is the genetic prediction of complex traits from both individual-level data and summary statistics. Most prediction tools assume the GCTA model, whereby each SNP is expected to contribute equally to the phenotype (as is the case with PLINK). If we replace the GCTA Model with the BLD-LDAK Model, the squared correlation between observed and predicted phenotypes (\\(R^2\\)) increases by an average of 14% (s.d. 1%)."
  },
  {
    "objectID": "develop/GWAS7-OtherToolsAndTesting.html#overview-of-functionality",
    "href": "develop/GWAS7-OtherToolsAndTesting.html#overview-of-functionality",
    "title": "Other tools & conclusions",
    "section": "Overview of functionality",
    "text": "Overview of functionality\nUsing LDAK is very similar to PLINK. As with PLINK, you will require the .bed, .bim, and .fam files of your cohort. Beyond this, you will need additional files:\n\n.info - information scores for SNPs\n.pheno - a phenotype\n.covar - covariates\n.ind.hers - estimates of per-SNP heritabilities\n.genefile - (real) RefSeq human gene annotations\n\n If we call our prefix human, then very simply, we can compute summary statistics in the following way:\n\n# link the data and create output directory \nln -sf ../Data\nmkdir Results/GWAS7\n\n# Run ldak software\n../Software/ldak --calc-stats Results/GWAS7/human --bfile Data/ldak_data/human\n\nmkdir: cannot create directory ‘Results/GWAS7’: File exists\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nLDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\nVersion 5.2 - Help pages at http://www.ldak.org\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nThere are 2 pairs of arguments:\n--calc-stats Results/GWAS7/human\n--bfile Data/ldak_data/human\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nCalculating predictor and individual statistics\n\nTo run the parallel version of LDAK, use \"--max-threads\" (this will only reduce runtime for some commands)\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nReading IDs for 424 samples from Data/ldak_data/human.fam\n\nReading details for 3289 predictors from Data/ldak_data/human.bim\n\nData contain 424 samples and 3289 predictors\n\nCalculating statistics for Chunk 1 of 1\n\nStatistics saved in Results/GWAS7/human.stats and Results/GWAS7/human.missing\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nMission completed. All your basepair are belong to us :)\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\n\nThis command asks LDAK to read the data stored in Binary PLINK format with the prefix human, then save the results to files with the prefix “human”. Remember that software command line arguments, can be provided in any order (generally, there is no strict order requirement), so that the command above would be equivalent to ../Software/ldak --bfile Data/ldak_data/human --calc-stats Data/ldak_data/human\nThe output files are called human.stats and human.missing and found in the folder Results/GWAS7. By accessing the columns of human.stats, we can create plots similar to those in the notebook GWAS3 with the tutorial on QC:\n\n######### FOR EXERCISE\n\nsnpmiss &lt;- read.table(file=\"Results/GWAS7/human.stats\", header=TRUE)\n\nhead(snpmiss)\n\nhist(snpmiss$MAF, breaks = 50) \n\n#  geom_histogram(binwidth = 0.001, col = \"black\", fill=\"tomato\") + \n#  labs(title = \"Frequency of missingness rates in individuals\") + \n#  xlab(\"Frequency\") + \n# ylab(\"Missingness in Individuals\") + \n# theme_bw()\n\n\n###########################\n\n\nA data.frame: 6 × 7\n\n\n\nPredictor\nA1\nA2\nA1_Mean\nMAF\nCall_Rate\nInfo\n\n\n\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\n21:14642464\nA\nG\n0.884434\n0.442217\n1\n-1\n\n\n2\n21:14649798\nA\nC\n0.974057\n0.487028\n1\n-1\n\n\n3\n21:14669931\nG\nA\n0.969340\n0.484670\n1\n-1\n\n\n4\n21:14688825\nT\nC\n0.983491\n0.491745\n1\n-1\n\n\n5\n21:14736298\nC\nT\n0.858491\n0.429245\n1\n-1\n\n\n6\n21:14757043\nT\nC\n0.929245\n0.464623\n1\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.1: Genomic properties are easily accessible by parsing through the outputted summary statistics\n\n\nIf you wish to perform single-SNP association analysis using linear regression. We would use the main argument --linear in this case. Each main argument requires different options. Remember to check the Documentation at www.dougspeed.com. Most software have a --help option, but LDAK doesn’t, so an alternative is to run the main argument, which will print out the options required and missing for a successful run:\n\n../Software/ldak --linear linear\n\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\nLDAK - Software for obtaining Linkage Disequilibrium Adjusted Kinships and Loads More\nVersion 5.2 - Help pages at http://www.ldak.org\n-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --\n\nThere is one pair of arguments:\n--linear linear\n\nError, you must use \"--pheno\" to provide phenotypes\n\n\n\n: 1\n\n\nThe output can be used to obtain GWAS plots of interest, such as a Manhattan plot:\n\n\n\nFigure 7.2: Manhattan plot outputted by LDAK\n\n\nFurthermore, LDAK offers various additional methods and features, such as the explicit incorporation of covariates and PRS. For those interested, we recommend following the tutorials available here. Additionally, we have included the dataset accompanying this tutorial in the Data folder, conveniently named extra_data.zip. All you need is to run the commands in the tutorial.\nThe takeaway is that while more advanced tools exist, PLINK serves as an excellent starting point for conducting focused and specific analyses, particularly for educational purposes.\n\n\n\nMaterials\nDescription\n\n\n\n\nOther tools\n\n\n\nBOLT_LMMloh2015efficient\nGWAS using mixed-models for large cohorts (tutorial)\n\n\nRegenieloh2015efficient\nDifferent approach to perform GWAS scaling very well for quantitative & binary traits (tutorial)\n\n\nOther public courses\n\n\n\nStatistics of GWAS\nSemester-long course run by the University of Helsinki - more leans towards the mathematical theory behind GWAS (e.g. no practical)\n\n\nIntroduction to GWAS\nSimilar to this course, but with more R implementation\n\n\nPost-GWAS\n\n\n\nThe Post-GWAS Era: From Association to Function\nGood discussion that highlights key advances in the field of functional genomics that may facilitate the derivation of biological meaning post-GWAS\n\n\nPerforming post-genome-wide association study analysis: overview, challenges and recommendations\nMore of a practical guide to the paper above\n\n\nVideos\n\n\n\nIntroduction to genomics theory\n30-minute discussion of using PLINK in the context of GWAS\n\n\nMPG Primer: GWAS design and interpretation\nMedical and Population Genomics Primer from MIT\n\n\nIllumina Sequencing\nVisually intuitive understanding of sequencing from Illumina"
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html",
    "href": "develop/GWAS5-AssociationTesting.html",
    "title": "Association testing",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAfter QC and generating MDS components as covariates to address population structure, the data is ready for association tests. In this tutorial, we provide scripts for association tests suitable for binary traits (e.g., alcohol-dependent patients vs. healthy controls) or quantitative traits (e.g., number of alcoholic beverages consumed per week).\n\n\n\nDiscuss different types of association tests\nIdentify the suitable association test for your data\n\n\n\n\n\nIn this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel\nIn GWAS, linear models have been typically used for continuous phenotypes (e.g. BMI, height, blood pressure) and logistic models for binary traits (e.g. disease presence). These models account for fixed effects (such as genotype) but also need to consider random effects, represented as an error term, \\(e\\), to minimize the influence of covariates, like sex of population structure.\nLinear mixed models (LMMs) are increasingly popular as an alternative to standard linear models and have proven to be effective for analyzing complex traits. They adjust for confounding factors such as population stratification, family structure, and cryptic relatedness, resulting in more reliable test statistics. However, they are usually more computationally demanding."
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html#learning-outcomes",
    "href": "develop/GWAS5-AssociationTesting.html#learning-outcomes",
    "title": "Association testing",
    "section": "",
    "text": "Discuss different types of association tests\nIdentify the suitable association test for your data"
  },
  {
    "objectID": "develop/GWAS5-AssociationTesting.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS5-AssociationTesting.html#how-to-make-this-notebook-work",
    "title": "Association testing",
    "section": "",
    "text": "In this notebook, we will use both R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. We will first run Bash commands.\n\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html",
    "href": "develop/GWAS0-geneticTheory.html",
    "title": "Genetic Theory Review",
    "section": "",
    "text": "Information about this notebook\n\n\n\n\n\nThis section reviews basic genetic theory terminology to help you better understand GWAS principles. Feel free to skip it if you’re already familiar with the concepts.\n\n\n\nReview the basic terminology of genetic theory (DNA and genetic variation)\nDiscuss sources of human genetic variation databases"
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html#learning-outcomes",
    "href": "develop/GWAS0-geneticTheory.html#learning-outcomes",
    "title": "Genetic Theory Review",
    "section": "",
    "text": "Review the basic terminology of genetic theory (DNA and genetic variation)\nDiscuss sources of human genetic variation databases"
  },
  {
    "objectID": "develop/GWAS0-geneticTheory.html#quick-review-of-genetic-theory",
    "href": "develop/GWAS0-geneticTheory.html#quick-review-of-genetic-theory",
    "title": "Genetic Theory Review",
    "section": "Quick Review of Genetic Theory",
    "text": "Quick Review of Genetic Theory\nWe all carry two nuclear genomes (i.e. genomes located in the cell nucleus), one inherited from each of our two parents. Additionally, we have a small mitochondrial genome, assumed to be inherited exclusively from the mother, but in this course, the term ‘genome’ refers to the nuclear genome.\nThe human genome is a 3.2 billion nucleotide (or base pair or DNA letter A, C, G, T) long sequence (see yourgenome.org), that is divided into separate physical pieces called chromosomes (see yourgenome.org). There are 22 autosomal (non-sex related) chromosomes and two sex chromosomes (X and Y chromosomes). Commonly, humans have two copies of each autosome. Individuals with one copy of X and one of Y are males, whereas those with two copies of X are females. An abnormal number of chromosomes, known as aneuploidy, typically leads to severe consequences or early death when present in all cells of an individual. However, a notable non-lethal exception is Down syndrome, characterized by the presence of three copies of chromosome 21. Another condition, mosaicism, occurs when only some cells in the body have abnormal chromosome numbers, a phenomenon often observed in cancer cells.\nWhen we analyze genomes, we encounter three types of pairings:\n\nDNA is typically a double-stranded molecule, where two strands (i.e. the two DNA molecules) are glued together by the chemical base pairings: A-T and C-G. This base pairing is crucial for DNA replication, which is necessary before any cell division [see yourgenome.org (https://www.yourgenome.org/video/dna-replication). The two DNA molecules connected through base pairing contain identical information though their sequences are complementary: A pairs with T and C pairs with G. To distinguish between the two DNA molecules, it is conventionally agreed that one is the forward strand (or positive strand) and the other is the reverse strand (or negative strand). Therefore, if the forward strand contains base A, the corresponding base on the reverse strand is T, and vice versa.\nThe two homologous chromosomes of an individual (for example, paternal chromosome 13 with maternal chromosome 13, or in males, maternal X and paternal Y) are considered a pair. Therefore, the human genome consists of 22 autosomes plus X and Y chromosomes. Each individual possesses two copies of each homologous chromosome, resulting in a total of 46 unique chromosomes organized into 23 pairs of homologous chromosomes.\nBefore any cell division each of the 46 unique chromosomes of an individual undergoes replication (“copies itself”). The two resulting copies (known as sister chromatids) physically pair with each other to form an X-like shape often used in chromosome pictures. This pairing of sister chromatids after replication is crucial for ensuring that each resulting cell receives the correct set of chromosomes during cell division. In mitosis (ordinary cell division), each of the two new cells receives a complete set of 46 unique chromosomes. However, in meiosis, which forms gametes (sperm and eggs), each gamete ends up with only one copy of each homologous chromosome, resulting in 23 unique chromosomes per gamete. During meiosis, the process of recombination shuffles the homologous copies of paternal and maternal chromosomes. This shuffling ensures that each offspring’s chromosomes are a mixture of segments from its grandparents’ chromosomes.\n\n\nOther important terms\n\nGenes: are segments of DNA that encode for proteins (see yourgenome.org). Variations in the physical structure of proteins or the timing and location of protein synthesis can lead to observable traits. Therefore, understanding how genetic variation impacts gene function and the phenotypic consequences is crucial, although much of this remains to be explored. Protein-coding genes constitute less than 2% of the entire human genome, while the remaining 98% plays a critical role in regulating gene activity through various mechanisms.\nLocus (pl. loci): refers to a continuous region of the genome, which can vary greatly in size from a single nucleotide site (1 base pair) to a region spanning millions of base pairs (e.g., 10 Mbp).\nGWAS loci: are regions of the genome that exhibit a significant statistical association with a particular phenotype of interest.\n\n\n\nGenetic variants\nAt any given position in the genome (e.g., nucleotide site at position 13,475,383 of chromosome 1, denoted as chr1:13,475,383), variations can exist between individuals in the population. For instance, my paternal chromosome might have a base A, while my maternal chromosome has a base G (on the + strand of DNA) at that position. Such a single-nucleotide difference, at that specific position in the genome, is known as a single-nucleotide variant (SNV), and these two versions are called alleles. In this example, I would carry both allele A and allele G at that SNV, while you might have two copies of allele A at the same SNV. My genotype would be AG, and yours would be AA.\nAn individual who has different alleles on their two genomes is heterozygous at that locus, whereas someone with two copies of the same allele is homozygous at that locus. If neither allele is very rare in the population—specifically if the minor allele frequency (MAF) is &gt; 1%—the variant is referred to as a single-nucleotide polymorphism (SNP). SNPs are used as markers in evolutionary biology and constitute the most common form of variation that may have consequences at the phenotypic level and be associated with certain diseases. There are over 10 million SNPs identified in the human genome.\nMore complex genetic variations include structural variation (SV) such as copy number variants (CNVs), which include duplications or deletions of genomic regions, as well as rearrangements of the genome, like inversions or translocations of DNA segments (see yourgenome.org).\n\n\n\nFigure 1: SNPs are DNA differences at a specific location (image source)\n\n\nA defined set of 500,000 to 1,000,000 SNPs can be measured reliably and affordably (less than 50 euros per sample) using DNA microarrays, which has been pivotal in enabling GWAS. In this course, we primarily focus on SNPs as the standard type of genetic variation. Typically, SNPs are biallelic, meaning there are only two alleles present in the population, which is the assumption we follow. In principle, however, all four possible alleles of a SNP could be present in the population.\n\nAmbiguous SNPs\nIf the two alleles of an SNP are either (C,G) or (A,T) we call the SNP ambiguous because the strand information must be available (and accurate) to correctly interpret the genotypes at such SNP. For instance, allele C on the positive strand would be equivalent to allele G on the negative strand. If different studies report the SNP with respect to different strands, it can lead to mixed-up results. This issue does not occur with SNPs whose alleles are A, and C, because alleles T and G would correspond on the opposite strand, allowing unambiguous matching of A to T and C to G across studies. Ambiguous SNPs can generally be resolved reliably based on allele frequencies, as long as the minor allele frequency is not close to 50%. When combining multiple studies, it is crucial to begin by plotting allele frequencies between studies. This helps ensure that the alleles are consistently matched across studies before comparing frequencies to verify consistency.\n\n\n\nSome catalogs of genetic variation\nThe human genome map is constantly improving, leading to updates in SNV/SNP coordinates and new discoveries with each new build. The current build is GRCh38 (hg38), published in 2013, while its predecessor, GRCh37 (hg19), is still in use for some data sets. Always specify the genome build when sharing genomic coordinates, as positions can differ between builds. There are tools like LiftOver that can help map coordinates between builds.\nA large part of the genetics research over the last 30 years has been driven by international projects aiming to catalog genetic variation in the public domain.\n\n\n\nDatabase\nYear\nDescription\n\n\n\n\nThe Human Genome Project\n1990-2003\nEstablished a first draft of a human genome sequence. Collins and Fink (1995).\n\n\nThe HapMap project\n2002-2009\nStudied the correlation structure of the common SNPs. Gibbs et al. (2003).\n\n\nThe 1000 Genomes project\n2008-2015\nExpanded HapMap to genome sequence information across the globe and currently remains a widely-used reference for global allele frequency information. 1000G project was able to characterize well common variation in different populations, but missed many rare variants of single individuals because the costs of very accurate sequencing were too high. The tremendous impact of the 1000G project stems from the fact that everyone can download the individual-level genome data of the 1000G samples from the project’s website and use it in their research. Auton et al. (2015).\n\n\nExome Aggregation Consortium (ExAC)\n2014-2016\nConcentrated only on the protein-coding parts of the genome, so-called exons, that make up less than 2% of the genome and was able to provide accurate sequence data for the exomes of over 60,000 individuals. This effort has been particularly important for the medical interpretation of rare variants seen in clinics that diagnose patients with severe disease. ExAC provides summary-level information through browsers and downloads but individual-level data cannot be downloaded. Lek et al. (2016).\n\n\nGenome Aggregation Database (gnomAD)\n2016-2020\nIs expanding the ExAC database and also includes additional whole genome sequencing information. It is the current state-of-the-art among the public genome variation databases. Chen et al. (2024)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genome-Wide Association Studies",
    "section": "",
    "text": "Genome-Wide Association Studies\n\nThis course is an introduction to the method of Genome-Wide Association Studies (GWAS), which quantifies the statistical association between a genetic variant and a phenotype (often on disease traits). This course will not focus on using any particular software, instead explaining why the given analyses are done from a statistical and biological perspective.\n\n\n\n\nAuthors\n\nSamuele Soraggi Conor O’Hare\n\n\n!!! abstract “Overview” 💬 Syllabus:\n1. Understand what is a GWAS is and why we use it\n2. Statistics of GWAS (regression coefficients, P-values, statistical power, Bayes factors)\n3. Genetic relatedness and population structure\n4. Confounding and covariates in GWAS\n5. Haplotypes, linkage disequilibrum, imputation, fine-mapping\n6. Linear mixed models and heritability\n7. Summary statistics and meta-analysis\n8. Advanced tools\n&#128368; **Total Time Estimation:** 6 hours  \n\n&#128193; **Supporting Materials:**  [Original course from the University of Helsinki](https://www.mv.helsinki.fi/home/mjxpirin/GWAS_course) | \n                                     [PLINK documentation](https://zzz.bwh.harvard.edu/plink/) | \n                                     [An Introduction to Statistical Learning (for further statistics explanations)](https://www.statlearning.com/)\n\n&#128203; **License:** [Tutorial Content is licensed under Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)\n!!! warning “Course Requirements” - Knowledge of R. It is recommended that you have at least followed our workshop From Excel to R - Basic statistics and mathematics skills\n\nWe do GWAS because a statistical association between a particular physical region of the genome and the phenotype\n\ncan point to biological mechanisms affecting the phenotype,\n\ncan allow prediction of the phenotype from genomic information.\n\nThese results may further benefit\n\nmedicine by leading to molecular or environmental interventions against harmful phenotypes,\n\nbiotechnology by improving the ways we utilize microbes, plants or animals,\n\nforensics by more accurate identification of an individual from a DNA sample,\n\nbiogeographic ancestry inference of individuals, populations and species,\n\nour understanding of the role of natural selection and other evolutionary forces in the living world.\n\nThe genome of an individual remain (nearly) constant throughout the individual’s lifetime. This is a truly remarkable property compared to, e.g., other molecular sources of information (such as metabolomics, metagenomics, transcriptomics, proteomics or epigenomics) or environmental factors that may vary widely across time. Therefore, the genome seems an ideal starting point for scientific research: it needs to be measured only once for an individual and there is no reverse causation from the phenotype to genome (with cancer as an important exception).\n\nAcknowledgements\n\nCenter for Health Data Science, University of Copenhagen\nMatti Pirinen, PhD, University of Helsinki\nAndries T. Marees, Vrije Universiteit Amsterdam"
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html",
    "href": "develop/GWAS1-WhatIsAGWAS.html",
    "title": "What is a GWAS?",
    "section": "",
    "text": "Information about this notebooks\n\n\n\nOver the past two decades, there has been an increasing interest in investigating the influence of genetic risk factors on various human traits. The technical and analytic tools required to conduct genetic studies have become increasingly accessible, which holds great promise. However, performing genetic association studies properly is complex and requires specific knowledge of genetics, statistics, and (bio)informatics.\nThis course will introduce key concepts and provide guidelines for building a reusable workflow for Genome-Wide association studies (GWAS) by progressively describing all necessary steps in a typical GWAS analysis. This notebook is read-only, while the others are hands-on practical exercises using R and the Linux command line.\n\n\n\nRecognize and discuss the basic terminology and GWAS principles\nIdentify the main steps of a typical GWAS analysis"
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#learning-outcomes",
    "href": "develop/GWAS1-WhatIsAGWAS.html#learning-outcomes",
    "title": "What is a GWAS?",
    "section": "",
    "text": "Recognize and discuss the basic terminology and GWAS principles\nIdentify the main steps of a typical GWAS analysis"
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#what-is-a-genome-wide-association-study",
    "href": "develop/GWAS1-WhatIsAGWAS.html#what-is-a-genome-wide-association-study",
    "title": "What is a GWAS?",
    "section": "What is a genome-wide association study?",
    "text": "What is a genome-wide association study?\nA Genome-Wide Association Study (GWAS) aims to link genotype and phenotype information by identifying genetic variants that have a statistical association with a trait. A phenotype, also called trait, can be any measured or observed property of an individual. Phenotypes can include quantitative traits, like standing height or body mass index (BMI), as well as binary traits, such as diagnoses of multiple sclerosis or schizophrenia.\nGWAS are used to explore the genetic architecture of complex traits and address questions about the distribution of variants contributing to the resulting phenotype, and their associated effect size on the trait. To understand GWAS, it is important to familiarise yourself with the key components and terminology involved in these studies:\n\nGeneral concepts\n\nMonogenic phenotype is determined by a single gene/locus.\nOligogenic phenotype is influenced by a handful of genes/loci.\nPolygenic phenotype is influenced by many genes/loci.\nComplex trait is a (quantitative) phenotype that is not monogenic such as anthropometric, lifestyle, or behavioural traits. Typically, it is polygenic and influenced by both genetic and environmental factors.\nCommon disease is a disease/condition which is common in the population (say, prevalence of 0.1% or more). Examples: Multiple sclerosis (also known as MS) (prevalence in the order of 0.1%), schizophrenia (\\(\\sim 1\\%\\)), or Type 2 diabetes (\\(\\sim 10\\%\\)).\nCommon variant has a frequency of at least 1% (commonly, 5% is also used as the threshold).\nLow-frequency variant has a frequency of at least 0.1% and lower than a common variant.\nRare variant has a frequency lower than a low-frequency variant.\n\n\n\nKey concepts\nGWAS have shown us that, in general, complex traits and common diseases are highly polygenic, influenced by many common variants with small effects. Identifying the exact causal variants for each phenotype is challenging due to the correlation structure among genetic variants (i.e., linkage disequilibrium, genetic interactions, etc.). Additionally, understanding the impact of rare variants on phenotypes requires very large sample sizes analyzed using genome sequencing techniques, rather than just SNP arrays.\nIn GWAS, it is also crucial to account for potential confounding factors. This refers to variables that are linked to both the genetic variants and the trait of interest (i.e., population stratification). Failing to control for these factors can lead to spurious relationships between genetic variants and a trait. We’ll discuss how to address the issue in notebook 4 (Quality control).\nHere are some terms and concepts that you need to be familiar with: * Population stratification is the presence of multiple genetically distinct subpopulations that differ in their average phenotypic values (e.g., the distribution of north and south European individuals in PCA and the height of those individuals). When not accounted for, this can lead to spurious genetic associations. * Heritability is the proportion of variance of the phenotype that is due to genetic differences between individuals (recommended article: Visscher, Hill, and Wray (2008)). * Linkage disequilibrium, also known as LD, is the non-random association of alleles at different loci within a population. LD arises because alleles that are physically close on the same chromosome tend to be inherited together over generations (due to limited recombination), leading to a non-independent assortment of alleles at these loci. This means that certain genetic variants (SNPs, for instance) that are physically close to each other on the genome are often inherited together as a block. Tools like LDPred are key to tackling this problem (recommended reading: (lvilhjalmsson2015modeling?)). * Winner’s curse effect size of newly discovered alleles tends to be overestimated. * Multiple testing refers to the statistical issue that arises when conducting multiple hypothesis tests simultaneously. In the context of GWAS, millions of genetic variants are tested for association with a trait. Researchers commonly apply the Bonferroni testing threshold by dividing the significant threshold by the number of independent tests. We will look further into other correction methods in Notebook 5. * Linear regression is the statistical method commonly used in GWAS to identify genetic variants associated with traits.\n\n\n\n\n\n\nWhy mixed models are important\n\n\n\nIn this module, we will focus on linear models. However, it’s crucial to acknowledge the existence of other model types. The standard linear regression model becomes overly flexible and struggles to fit the data effectively as the number of SNPs increases, especially when effect sizes are unrestricted. High correlations among SNPs exacerbate overfitting issues in linear models.\n\n\n\n\nGWAS output\nThe primary outcome of GWAS is summary statistics, which consist of a table detailing various attributes for each tested SNP, including the effect size. This metric quantifies the magnitude of association between the SNP and the trait, typically expressed as an odds ratio (OR) for binary traits or beta coefficients for quantitative traits. The summary statistics file includes essential information such as SNP ID, SNP chromosome (CHR), genomic position, alleles, strand orientation, effect size with standard error, P-value or test statistic, minor allele frequency, and sample size.\nSummary statistics can be used to calculate polygenic scores for a particular trait. A polygenic score (PGS) is an expression of the predicted genetic predisposition of an individual or a population of having a trait. If the prediction is on a discrete phenotype such as a disease, these scores are known as polygenic risk scores (PRS)."
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#gwas-examples",
    "href": "develop/GWAS1-WhatIsAGWAS.html#gwas-examples",
    "title": "What is a GWAS?",
    "section": "GWAS examples",
    "text": "GWAS examples\nNow, let’s look at some recent examples of GWAS. There are two primary types, a) studies focusing on quantitative traits and b) those investigating disease phenotypes.\n\nExample 1 QT-GWAS\nGWAS on body-mass index (BMI) (Locke et al. 2015) combined data from 339,000 individuals from 125 studies around the world to explore the relationship between genetic variants and BMI. This study identified 97 genomic regions strongly associated with BMI. Pathway analyses provided evidence supporting the involvement of the central nervous system in obesity susceptibility. Some of the newly identified candidates are genes involved in pathways related to synaptic function, glutamate signaling, insulin secretion/action, energy metabolism, lipid biology, and adipogenesis.\n\n\n\nFigure 2: Manhattan plot displaying the \\(–log_{10}\\) P-value of each SNP tested in a GWAS, such as the BMI study by Locke et al. (2015). Although Manhattan plots will be explained later in the course, the key idea is that by setting a genome-wide significance threshold at p=5e-8, equivalent to \\(–log_{10}(p)\\) = 7.3, we can identify variants significantly associated with the phenotype under study. In this plot, previously identified loci are shown in blue, new discoveries are in red, and each locus is labeled with a nearby gene (though the labeled gene may not necessarily be the causal one).\n\n\n\n\nExample 2 Disease GWAS\nGWAS on migraine (Gormley et al. 2016) combined genetic data on 60,000 cases (individuals with migraine) and 315,000 controls (individuals with no known migraine) originating from 22 studies. Genetic data was available on millions of genetic variants. At each variant, the genotype distribution between cases and controls was compared. This study identified 38 regions of the genome that showed a significant statistical association with migraine. Downstream analyses integrated these genes into pathways and cell types, revealing an enrichment of signals near genes that are active in the vascular system.\n\n\n\nFigure 3: Manhattan plot from GWAS study on migraines by Gormley et al. (2016).\n\n\nA third type of GWAS, known as Trait GWAS, focuses on investigating variants linked to specific traits or characteristics that are not quantitative but may not necessarily be a disease (e.g., eye color, hair texture, response to medicaments, etc. )."
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#overview-of-gwas-steps",
    "href": "develop/GWAS1-WhatIsAGWAS.html#overview-of-gwas-steps",
    "title": "What is a GWAS?",
    "section": "Overview of GWAS Steps",
    "text": "Overview of GWAS Steps\nThe aim of genome‐wide association studies (GWAS) is to identify single nucleotide polymorphisms (SNPs)-of which the allele frequencies vary systematically-as a function of phenotypic trait values (e.g., between cases with schizophrenia and healthy controls, or between individuals with high vs. low scores on neuroticism). The identification of trait‐associated SNPs can provide new insights into the biological mechanisms underlying these phenotypes. Advances in technology have made it possible to study the effects of numerous SNPs spread across the genome. Before diving into the procedure, let’s review some essential concepts. The typical steps involved in a GWAS are illustrated in the figure below:\n\n\n\nFigure 4: Overview of GWAS Steps (Uffelmann et al. 2021)\n\n\n\na) Data Collection: Data can be collected from study cohorts, but there is also valuable genetic and phenotypic information that can be used from biobanks or repositories. Depending on the study’s focus, various data collection methods will be used, including questionnaires, clinical assessments, biological samples, or anthropometric measurements. Comprehensive data will allow researchers to investigate the relationships between genetic factors, environmental exposures, and health outcomes. Confounders need to be carefully considered and recruitment strategies must not introduce biases such as collider bias.\nb) Genotyping: Genotypic data can be collected using microarrays to capture common variants, or next-generation sequencing methods for whole-genome sequencing (WGS) or whole-exome sequencing (WES). The data is saved in specific file formats that can be used for downstream analyses.\nc) Quality control: Quality control includes steps both at the wet-laboratory stage, such as genotype calling and DNA switches, and dry-laboratory steps on called genotypes, involving filtering both at the sample and variant level. For instance, poor single-nucleotide polymorphisms (SNPs) and samples will be filtered out. It is also important to detect population strata in the cohort using principal components analyses (PCA). Panel c) of the figure, captures the overall genetic diversity and relatedness within the study cohort by clustering individuals who are more genetically similar.\nd) Imputation: Genotypic data can be phased, and missing (“untyped”) genotypes are often imputed using data from reference populations like the 1000 Genomes Project or TopMed. It is crucial that the reference panel closely matches the ancestry of the individuals being imputed for optimal accuracy, while also being diverse enough to represent the entire population. In panel d) of the figure above, genotypes of SNP1 and SNP3 are imputed based on the directly assayed genotypes of other SNPs. Examples of widely used imputation software include SHAPEIT, BEAGLE, and IMPUTE2.\ne) Association testing: Genetic association tests are conducted for each genetic variant, using an appropriate model (for example, additive, non-additive, linear, or logistic regression). Regardless, of the approach used, it is important to correct for confounders (including population stratification) and control for multiple testing. Outputs are scrutinized for unusual patterns, and summary statistics are generated.\nf) Meta-analysis: A very large number of individuals is required to achieve powerful GWAS. Commonly, to increase sample size, GWAS are typically conducted within consortia such as the Psychiatric Genomics Consortium, the Genetic Investigation of Anthropometric Traits (GIANT) consortium, or the Global Lipids Genetics Consortium. This can be especially relevant in under-studied populations. These consortia analyze data from multiple cohorts using tools such as METAL or GWAMA.\ng) Replication: Results can be validated using internal replication or external replication in an independent cohort. External replication requires the cohort to be ancestrally matched and not share individuals or family members with the discovery cohort.\nh) Post-GWAS analyses: In silico analyses involve fine mapping, SNP-to-gene mapping, gene-to-function mapping, pathway analysis, genetic correlation analysis, mendelian randomization, and polygenic risk prediction. Functional hypotheses can be further tested using experimental techniques such as CRISPR or massively parallel reporter assays, and results can be validated in human trait/disease models (not shown in the figure)."
  },
  {
    "objectID": "develop/GWAS1-WhatIsAGWAS.html#software-overview-for-each-gwas-steps",
    "href": "develop/GWAS1-WhatIsAGWAS.html#software-overview-for-each-gwas-steps",
    "title": "What is a GWAS?",
    "section": "Software overview for each GWAS Steps",
    "text": "Software overview for each GWAS Steps\nNumerous software tools are available for conducting GWAS. This table by (Uffelmann et al. 2021) provides an overview of state-of-the-art tools, categorized by each step in the analysis process.\n\n\n\n\n\n\nWrapping up\n\n\n\nThis course will cover data collection and genotyping, quality control (which will look at factors such as relatedness, population structure, and summary statistics), and association testing.\nModern GWAS involves analyzing tens of thousands of individuals and millions of genetic variants, requiring specialized software capable of handling specific file formats. Among the most commonly used tools for this purpose is PLINK, which we will use in the upcoming notebooks. Additionally, we will explore advanced tools designed for beyond-standard GWAS analysis.\n\n\n\n\n\n\n\n\nPowerful and robust tools\n\n\n\nThere are more advanced tools such as LDAK, BOLT-LMM and Regenie. - LDAK contains non-standard models for GWAS and PRS analysis which are periodically updated. - BOLT-LMM is highly efficient for large datasets and more powerful at controlling for false positives due to the mixed model approach. - Regenie is written in C++ and fast at whole genome regression models on very large genome-wide association studies. These tools are computationally more intensive but necessary when the size of a study scales up considerably."
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html",
    "href": "develop/GWAS4-QualityControlB.html",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nAs we have already mentioned, quality control (QC) analyses are crucial to ensure the reliability and validity of the results. In this section, we will explore confounding factors in GWAS that can lead to spurious associations if not properly controlled, including:\n\nRelatedness\n\nPopulation Stratification/Structure\n\n\n\n\nDiscuss confounding factors that lead to spurious associations\nDetect related individuals\nIdentify population substructure\nCorrect for population stratification\n\n\n\n\nIn this notebook, we will both use R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. * We will first run Bash commands.\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#learning-outcomes",
    "href": "develop/GWAS4-QualityControlB.html#learning-outcomes",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "Discuss confounding factors that lead to spurious associations\nDetect related individuals\nIdentify population substructure\nCorrect for population stratification"
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS4-QualityControlB.html#how-to-make-this-notebook-work",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "",
    "text": "In this notebook, we will both use R and bash command line programming languages. Remember to change the kernel whenever you transition from one language to the other (Kernel --&gt; Change Kernel) indicated by the languages’ images. * We will first run Bash commands.\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#relatedness",
    "href": "develop/GWAS4-QualityControlB.html#relatedness",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "4.1 Relatedness",
    "text": "4.1 Relatedness\nRelatedness refers to the presence of genetically related individuals in a study sample, which can introduce confounding factors into association analyses. Since most statistical methods assume that samples are independent, including related individuals, like siblings, violates this assumption. Addressing relatedness is crucial as a quality control step to ensure that genomes in the dataset are no more similar than expected for unrelated individuals. This process is essential to preserve the validity of the study’s findings.\nWhile all humans share some genetic relatedness, the degree of relatedness varies among individuals. In genome-wide association studies (GWAS), these variations must be accounted for to avoid biasing the statistical associations between genotypes and phenotypes. Cryptic relatedness (genetic relatedness of individuals not expected to be in a family relationship) can interfere with the association analysis (Voight and Pritchard 2005).\nIn a family-based study (e.g., parent-offspring), you do not need to remove related pairs, but the statistical analysis should account for family relatedness. However, for a population-based study, we suggest using a \\(\\hat{\\pi}\\) threshold of 0.2. \\(\\hat{\\pi}\\) is computed as a probability P(IBD = 2) + 0.5 × P(IBD = 1), where IBD refers to “identical-by-descent”. This measures the proportion of alleles shared between individuals due to inheritance from a common ancestor. \\(\\hat{\\pi}\\) ranges between 0 (no relationship) to 1 (identical genomes).\n\nWe use ln -sf to link the data folder and create a directory for output files.\n\nln -sf ../Data\nmkdir -p Results/GWAS4\n\n\n4.1.1 Analysis\nWe will use the set of independent SNPs (generated in the previous section) and the --genome option in PLINK for our analysis.\nThe HapMap dataset is known to contain parent-offspring relationships. Assuming a random population sample, we will exclude all individuals above the \\(\\hat{\\pi}\\) threshold of 0.2 (dealing with cryptic relatedness) using the commands below. Thresholds for relatedness can be changed using the --min and --max options.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_7 --extract Results/GWAS3/indepSNP.prune.in --genome --out Results/GWAS4/pihat\n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/pihat.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_7\n  --extract Results/GWAS3/indepSNP.prune.in\n  --genome\n  --out Results/GWAS4/pihat\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073788 variants loaded from .bim file.\n161 people (77 males, 84 females) loaded from .fam.\n110 phenotype values loaded from .fam.\n--extract: 104129 variants remaining.\nUsing up to 63 threads (change this with --threads).\nBefore main variant filters, 110 founders and 51 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998119.\n104129 variants and 161 people pass filters and QC.\nAmong remaining phenotypes, 55 are cases and 55 are controls.  (51 phenotypes\nare missing.)\nIBD calculations complete.  \nFinished writing Results/GWAS4/pihat.genome .\n\n\nThe table from PLINK contains various IDs in the first columns, then: - RT Relationship - EZ IBD sharing expected value, based on just .fam/.ped relationship - Z0 P(IBD=0) - Z1 P(IBD=1) - Z2 P(IBD=2) - PI_HAT Proportion IBD, i.e. P(IBD=2) + 0.5P(IBD=1) - PHE Pairwise phenotypic code (1, 0, -1 = AA, AU, and UU pairs, respectively) - DST IBS distance, i.e. (IBS2 + 0.5IBS1) / (IBS0 + IBS1 + IBS2) - PPC IBS binomial test - RATIO IBS0 SNP ratio (expected value 2)\nThe specific IBD coefficients (PI_HAT, Z0, Z1 andZ2) are used to infer these relationships. PI_HAT represents the proportion of IBD sharing, and Z0, Z1, and Z2 represent the probabilities that a pair of individuals share 0, 1, or 2 alleles of IBD, respectively. These values together help determine the relationship category.\nFor the relationships RT, you can have:\n\nPO (Parent-Offspring): indicates a parent-offspring relationship. The expected IBD sharing for such a pair is 50%.\nFS (Full Siblings): indicates a full sibling relationship. Full siblings are expected to share 50% of their genome IBD, but the pattern of sharing (i.e., segments shared by descent) differs from that of a parent-offspring pair.\nHS (Half Siblings): indicates a half-sibling relationship, where the individuals share one parent. They are expected to share about 25% of their genome IBD.\nUN (Unrelated): indicates that the pair of individuals is inferred to be unrelated. They share little to no IBD segments, which is expected for unrelated individuals in large populations.\nAV (Avuncular): indicates an avuncular relationship (e.g., uncle/aunt to niece/nephew), where the expected IBD sharing is around 25%.\nGG (Grandparent-Grandchild): indicates a grandparent-grandchild relationship, with expected IBD sharing of about 25%.\nCO (Cousin): is used for cousin relationships, where the expected IBD sharing is about 12.5%.\nOT (Other): is used for more distant relationships or complex kinship structures, and when none of the primary categories apply clearly.\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nWhat assumption in association studies is violated when individuals are related?\nHow would you recognize if the same sample is duplicated in your dataset?\nWhat relationships (RT) are estimated by PLINK? Hint: check for unique values\nAre there closely related individuals? How many individuals show close relatedness (PI_HAT &gt; 0.2)?\n\nN.B. We recommend printing the first few lines of the file to identify the columns of interest. The filename is printed in the logs from the PLINK command.\n\n\n\n# Write your code here (add more cells if needed)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf you have related individuals, you will lose the independence of individuals at each SNP. This is a problem because many models used in GWAS analysis do not include handling family relationships.\nCalculating the identity-by-descent (IBD) coefficient and looking for a \\(\\hat{\\pi}\\) close to 1.\nWe will look for unique values in column 5 (RT.)\nWe will examine \\(\\hat{\\pi}\\) values in column 10.\n\n\n\n\nLet’s print the first few rows of pihat.genome and then, the unique relatioship categories in the file:\n\ncat Results/GWAS4/pihat.genome | head -5\n\n   FID1     IID1   FID2     IID2 RT    EZ      Z0      Z1      Z2  PI_HAT PHE       DST     PPC   RATIO\n   1328  NA06989   1377  NA11891 UN    NA  0.9891  0.0109  0.0000  0.0055   1  0.720373  0.4063  1.9840\n   1328  NA06989   1349  NA11843 UN    NA  0.9846  0.0154  0.0000  0.0077   0  0.718050  0.0223  1.8707\n   1328  NA06989   1330  NA12341 UN    NA  0.9649  0.0351  0.0000  0.0176   1  0.721260  0.2259  1.9501\n   1328  NA06989   1344  NA10850 UN    NA  0.9860  0.0129  0.0011  0.0075   0  0.721665  0.6441  2.0250\n\n\n\nawk '{print $5}' Results/GWAS4/pihat.genome | sort | uniq -c \n\n    222 OT\n     90 PO\n      1 RT\n  12568 UN\n\n\nWe have 90 parent-offspring, 12568 unrelated, and 222 others.\nNow, let’s calculate how many individuals have a PI_HAT parameter (column 10) larger than 0.2.\n\nawk '{ if ($10 &gt; 0.2) print }' Results/GWAS4/pihat.genome | wc -l\n\nThere are 93 individuals with PI_HAT &gt; 0.2 (94 lines minus header).\n\n Switch to the R-GWAS kernel.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nWrite some R code to calculate the summary of the distribution of PI_HAT values (IBD sharing expected value, based on just .fam/.ped relationship) for each RT category. What do you observe?\nHint: by() and summary().\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\nMany parent-offspring (PO) relationships have a parameter close to 0.5, and the maximum value for unrelated (UN) individuals is also unexpectedly high relatedness.\n\n\nLet’s plot the z-values against each other to visualize related samples. You can also find the code for summary PI_HAT values.\n\n# Generate a plot to assess the type of relationship.\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nrelatedness &lt;- read.table(\"Results/GWAS4/pihat.genome\", header=T)\n\n# Relatedness plot\nplot.relatedness &lt;- ggplot(relatedness) +\n  geom_point(aes(x=Z0, y=Z1, col=RT), size=5, alpha=.25) + \n  xlim(0,1) + \n  ylim(0,1) +\n  labs(x = \"Z0\", y = \"Z2\", title = \"Identity by descent probabilities\", col = \"Relationship\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13), legend.text= element_text(size=13), legend.title=element_text(size=14), plot.title=element_text(size=15))\n\nshow(plot.relatedness)\n\n# Relatedness histogram\nhist.relatedness &lt;- ggplot(relatedness, aes(x=relatedness[,10])) +\n  geom_histogram(binwidth = 0.02, col = \"black\", fill=\"tomato\") + \n  labs(title = \"Histogram of relatedness (Pi Hat)\") + \n  xlab(\"Pi Hat\") + \n  ylab(\"Frequency\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13),plot.title=element_text(size=15))\n\nshow(hist.relatedness)\n\n# Summary table of PI_HAT files per RT group\nsummary_by_RT &lt;- by(relatedness$PI_HAT, relatedness$RT, summary)\nsummary_by_RT\n\n\n\n\n\n\n\n\nrelatedness$RT: OT\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.005175 0.010400 0.011772 0.017225 0.042700 \n------------------------------------------------------------ \nrelatedness$RT: PO\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4958  0.5000  0.5000  0.5007  0.5018  0.5060 \n------------------------------------------------------------ \nrelatedness$RT: UN\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00500 0.01070 0.01165 0.01730 0.49230 \n\n\n\n\n\n\n\n\n\nThere are three distinct categories of individuals based on the RT values:\n\nUN (unrelated),\nPO (parent-offspring),\nand OT (other)\n\nThe PO relationship has a 100% probability of two alleles being identical by descent, and most UN and OT samples are unrelated. However, some UN samples are probably related given the high PI_HAT values; their relationship might not be correctly recorded in the data.\nThe presence of related individuals is not a surprise, since the dataset was constructed to contain family trios and population structure to describe patterns of common genetic variation.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nUse PLINK options to filter out related individuals, using a relatedness threshold of 0.2. Name the output --out Results/GWAS4/pihat_exercise. The command is similar to the one used above, but you need an extra option. Check PLINK manual to find the one.\n\nHow many individuals are related and would be filtered out?\nHow many pairs of samples have PI_HAT values above the specified cutoff(s) are?\nReplot the z-values, which relationship categories remain?\n\nHint: - Use the file Results/GWAS4/pihat_exercise.log to answer the first question. They are labeled as non-founders. - Count the lines of the new output vs. the pre-filtered one. - Modify the code above to plot the z-values for the pihat_exercise.genome.\n\n\n Switch to the Bash kernel.\n\n# Write your code here (PLINK command)\n\n Switch to the R-GWAS kernel.\n\n# Write your code here (R code)\n\n\n\n\n\n\n\nSolution\n\n\n\nWe need the option --max 0.2 in PLINK so that only individuals below that threshold are used.\n\n\n\n\nplink --bfile Results/GWAS3/HapMap_3_r3_7 --extract Results/GWAS3/indepSNP.prune.in --genome --out Results/GWAS4/pihat_exercise --max 0.2 \n\nPLINK v1.90b6.21 64-bit (19 Oct 2020)          www.cog-genomics.org/plink/1.9/\n(C) 2005-2020 Shaun Purcell, Christopher Chang   GNU General Public License v3\nLogging to Results/GWAS4/pihat_exercise.log.\nOptions in effect:\n  --bfile Results/GWAS3/HapMap_3_r3_7\n  --extract Results/GWAS3/indepSNP.prune.in\n  --genome\n  --max 0.2\n  --out Results/GWAS4/pihat_exercise\n\n385567 MB RAM detected; reserving 192783 MB for main workspace.\n1073788 variants loaded from .bim file.\n161 people (77 males, 84 females) loaded from .fam.\n110 phenotype values loaded from .fam.\n--extract: 104129 variants remaining.\nUsing up to 63 threads (change this with --threads).\nBefore main variant filters, 110 founders and 51 nonfounders present.\nCalculating allele frequencies... done.\nTotal genotyping rate is 0.998119.\n104129 variants and 161 people pass filters and QC.\nAmong remaining phenotypes, 55 are cases and 55 are controls.  (51 phenotypes\nare missing.)\nIBD calculations complete.  \nFinished writing Results/GWAS4/pihat_exercise.genome .\n\n\nBased on the log file, a total of 51 non-founders must be excluded. Now, let’s examine the change in the number of lines after applying the --max 0.2 filter. There are 93 sample pairs removed.\n\nwc -l Results/GWAS4/pihat.genome\n\n12881 Results/GWAS4/pihat.genome\n\n\n\nwc -l Results/GWAS4/pihat_exercise.genome\n\n12788 Results/GWAS4/pihat_exercise.genome\n\n\n\nLet’s plot the z-values again (repeating the plot from above)\n\n# Generate a plot to assess the type of relationship.\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nrelatedness &lt;- read.table(\"Results/GWAS4/pihat_exercise.genome\", header=T)\n\n# Relatedness plot\nplot.relatedness &lt;- ggplot(relatedness) +\n  geom_point(aes(x=Z0, y=Z1, col=RT), size=2.5) + \n  xlim(0,1) + \n  ylim(0,1) +\n  labs(x = \"Z0\", y = \"Z2\", title = \"Identity by descent probabilities\", col = \"Relationship\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13),plot.title=element_text(size=15), legend.text = element_text(size=14),legend.title = element_text(size=14))\n\nshow(plot.relatedness)\n\n\n\n\n\n\n\n\nWe can see there are only UN (unrelated) individuals left.\n\n Switch to the Bash kernel.\nSo far, you’ve learned how to filter individuals using PI_HAT thresholds. Now, we’ll demonstrate that most of the relatedness was due to parent-offspring relationships. We will achieve this by using the --filter-founders option to create a new filtered dataset that includes only the founders (individuals without listed parents in the data). This generates .bed, .bim, and .fam files, which are then used to create a .genome file containing relatedness values.\n\nplink --bfile Results/GWAS3/HapMap_3_r3_7 --filter-founders --make-bed --out Results/GWAS4/HapMap_3_r3_8 --silent\n\nplink --bfile Results/GWAS4/HapMap_3_r3_8 --extract Results/GWAS3/indepSNP.prune.in --genome --out Results/GWAS4/pihat_founders --silent\n\n Switch to the R-GWAS kernel.\nLet’s plot the results from Results/GWAS4/pihat_founders.genome.\n\n# Generate a plot to assess the type of relationship.\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nrelatedness &lt;- read.table(\"Results/GWAS4/pihat_founders.genome\", header=T)\n\n# Relatedness plot\nplot.relatedness &lt;- ggplot(relatedness) +\n  geom_point(aes(x=Z0, y=Z2, col=RT), size=2.5) + \n  xlim(0,1) + \n  ylim(0,1) +\n  labs(x = \"Z0\", y = \"Z2\", title = \"Identity by descent probabilities\", col = \"Relationship\") + \n  theme_bw()+\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13),plot.title=element_text(size=15), legend.text = element_text(size=14),legend.title = element_text(size=14))\n\n\nshow(plot.relatedness)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\n1. Do you observe anything unexpected in the plot?\n2. Can you identify the IIDs of the sample pair? Hint: filter for Z0 values.\n3. Based on the z-values, what is the most likely relationship between the pair?\n4. What would you do about it? Hint: remove one or both? which one?\n\n\n\n\n\nWrite answer here\n\n# R code here\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n1. The file pihat_founders.genome shows that, after excluding all non-founders, one individual pair removed in the exercise remains in the HapMap data.\n2. Below, we can look at the individual from the table by setting \\(Z_0 &lt; 0.5\\). Even if labeled as unrelated, it has high relatedness. The IIDs of the pair are NA07045 and NA12813.\n\n\n\n\n\nrelatedness[relatedness$Z0 &lt; 0.5,]\n\n\nA data.frame: 1 × 14\n\n\n\nFID1\nIID1\nFID2\nIID2\nRT\nEZ\nZ0\nZ1\nZ2\nPI_HAT\nPHE\nDST\nPPC\nRATIO\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n2639\n13291\nNA07045\n1454\nNA12813\nUN\nNA\n0.2574\n0.5005\n0.2421\n0.4923\n0\n0.839757\n1\n9.6694\n\n\n\n\n\n\n3. This remaining individual is likely to be a full sibling or DZ (dizygotic) twin pair based on the Z values (expected values for full siblings: z0=0.25; z1=0.50; z2=0.25). Noteworthy, they were not given the same family identity (FID) in the HapMap data.\n4. We don’t need to remove both individuals from the dataset (IID1=NA07045; IID2=NA12813). It’s enough to remove just one, and the individual with the highest missing rate (lowest quality) should be chosen. Let’s calculate the missing rates using PLINK.\n\n\n Switch to the Bash kernel.\n\nplink --bfile Results/GWAS4/HapMap_3_r3_8 --missing --out Results/GWAS4/HapMap_3_r3_8 --silent\n\nThen, find the two individuals from the output file using grep and sorting descendingly by missing rate (EZ, column 6)\n\n# Let's look at the output\ncat Results/GWAS4/HapMap_3_r3_8.imiss | grep -E 'NA07045|NA12813' | sort -k6,6nr\n\n  13291   NA07045          N     2560  1073788 0.002384\n   1454   NA12813          N     1956  1073788 0.001822\n\n\nNA07045 is the individual to be removed. Once this is removed, their offspring can still be used in analyses that don’t involve trios, such as family-related studies.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nPlot the distribution of missing rates from HapMap_3_r3_8. What is the value for NA07045?\nRemove NA07045 from the PLINK files\n\nHint: - Use the imiss file to plot a histogram of the missing scores from the file HapMap_3_r3_8.imiss in R (check previous notebooks for help). Is the score of NA07045 amongst the higher/lower ones? You can add a vertical line in the histogram representing the value for NA07045 using geom_vline. - Create a file with the sample ID to remove and use the --remove option in PLINK.\n\n\n Switch to the R-GWAS kernel.\n\n# Write your code here\n\n\n\n\n\n\n\nSolution\n\n\n\nWe can extract the column from the file and observe in the histogram that the individual NA07045 has a missing rate closer to the higher values.\n\n\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\noptions(repr.plot.width = 9, repr.plot.height = 4)\n\n# Read data into R \nimiss &lt;- read.table(\"Results/GWAS4/HapMap_3_r3_8.imiss\", header=T)\n\nhist.relatedness &lt;- ggplot(data=imiss, aes(F_MISS)) +\n  geom_histogram(col = \"black\", fill = \"tomato\") + \n  geom_vline(xintercept = 0.002384, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Histogram of missing rates\") + \n  xlab(\"Missing rate\") + \n  ylab(\"Frequency\") + \n  theme_bw() +\n  theme(axis.title=element_text(size=14), axis.text=element_text(size=13),plot.title=element_text(size=15))\n\nshow(hist.relatedness)\n\nWarning message:\n“Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.”\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n Switch to the Bash kernel.\nTo remove the individual from the data, we create a file containing its number and ID, and provide it to PLINK with the option --remove\n\necho \"13291  NA07045\" &gt; Results/GWAS4/id_remove.txt\n\n\n# Delete the individuals with the lowest call rate in 'related' pairs with a pihat &gt; 0.2 \nplink --bfile Results/GWAS4/HapMap_3_r3_8 --remove Results/GWAS4/id_remove.txt --make-bed --out Results/GWAS4/HapMap_3_r3_9 --silent"
  },
  {
    "objectID": "develop/GWAS4-QualityControlB.html#population-stratification",
    "href": "develop/GWAS4-QualityControlB.html#population-stratification",
    "title": "Quality Control: Relatedness & Population Stratification",
    "section": "4.2 Population Stratification",
    "text": "4.2 Population Stratification\n\n\n\n\n\n\nSome theory\n\n\n\nPopulation stratification presents a significant source of systematic bias in GWAS, arising when subpopulations exhibit systematic differences in allele frequencies. Research indicates that even subtle degrees of population stratification can exist within a single ethnic population (Abdellaoui et al. 2013). Thus, testing and controlling for the presence of population stratification is an essential QC step.\nThe population structure (or in other words, the ancestral relationship of the populations) is a so-called confounding factor. This means that it affects both the dependent and independent variables, as shown in the figure below, where both the genotype and traits are influenced by population structure (e.g., the distribution of north and south European individuals in the PCA space and the height of those individuals).\n{fig-align=“center”, width=400px}\nWhy is a bias introduced? Population structure can influence allele frequencies and produce false positives/negatives when doing association testing. Graphically, consider the example in the figure below. Case and control have minor allele frequencies of 1/6 and 1/8 (population 1) and 1/2, 7/12 (population 2). If you remove population structure, case and control have MAFs of 3/10, and 2/5, and those new values depend on how many samples you have from each population in the two conditions, and the MAFs of each population.\n{fig-align=“center”, width=400px}\nThe same problem arises in population studies without Case-control categories. Imagine having a population of randomly sampled individuals, each from a different ethnicity (the blue and red minor alleles in the example below). The final group of individuals will have a different proportion of MAFs depending on the sampling of various ethnicities.\n{fig-align=“center”, width=400px}\nThere are several methods to correct for population stratification (Price et al. 2010, price_principal_2006). Here, we illustrate a method integrated into PLINK: the multidimensional scaling (MDS) approach. MDS calculates the genome-wide average proportion of shared alleles between any pair of individuals to generate quantitative indices (components) of the genetic variation for each individual. The individual component scores can be visualized to identify groups of genetically similar individuals. For instance, in a genetic study including subjects from Asia and Europe, MDS analysis would reveal that Asians are genetically more similar to each other than to Europeans and Africans. Figure below shows another example of MDS using HapMap, Genome diversity project, and authors’ data:\n\n\n\nExample of MDS plot of the first two MDS components scores on integrated datasets in Somers et al. (2017). Here TWN, a past isolated population in the Netherlands, is separated from the other individuals from the same country (NDL). Sardinians, notoriously different from continental Italians, are also grouped far away from them. Central European populations colocalize as expected.\n\n\nTo investigate which individuals the generated component scores deviate from in the target population, plotting the scores of the dataset under investigation and a population of known ethnic structure (e.g., HapMap/1KG data) is helpful: this step is called anchoring (Rietveld et al. 2013). This enables the researcher to obtain ethnic information on their data and to determine possible ethnic outliers. For example, in ?@fig-MDSexample, if TSI (Tuscans from Italy) is the anchor population, one can hypothesize that the yellow dots might be ethnically similar (as in the example).\nOutliers identified based on MDS analysis should be excluded from further analyses. Following their removal, a new MDS analysis must be conducted, and its primary components are utilized as covariates in association tests to correct for any residual population stratification within the population. The number of components to include depends on the population structure and sample size (usually 10-20).\nThe MDS from Cortellari et al. (2021) shows a distinct goat population outlier. The second axis is dominated by this outlier, obscuring structure in the other populations. Removing the outlier reveals a clearer structure among the remaining populations.\n \n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nIt is also possible to correct for relatedness (family structure). Should we also do it?\n\n\n\n4.2.1 Analysis\nWe aim to merge the HapMap and 1000GP datasets, using 1000GP Phase I as the anchor for HapMap. Our goal is to check if we can identify the ethnicity of the HapMap data based on the ethnicities in the 1000GP dataset. There are several steps to ensure compatibility between the datasets, so stay with us!\n\n1000GP data download\nHere are some commands to download and convert the 1000GP data for GWAS analysis. You don’t need to run them, as we’ve already processed the data.\n\n1000 Genomes Project - Phase I: genetic information for 629 individuals from various ethnic groups (&gt;60GB). Phase III is now available, and we recommend using it for research purposes.\n\nwget ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20100804/ALL.2of4intersection.20100804.genotypes.vcf.gz\nThe data was converted from the vcf file (Variant Call Format) to plink format (bim, fam, bed):\nplink --vcf ALL.2of4intersection.20100804.genotypes.vcf.gz --make-bed --out ALL.2of4intersection.20100804.genotypes\n\n\n\n\n\n\nNote\n\n\n\nThe 1000 Genomes data downloaded above is rather large so the commands are not executable and are shown for reference only. To save time, we’ve provided the .bed, .bimand .fam files in the Data folder.\n\n\nLet’s unzip the files and see how many samples we have.\n\nunzip -o Data/1000genomes.zip -d Results/GWAS4\n# count lines in fam \nwc -l Results/GWAS4/1000genomes.genotypesA.fam\n\nArchive:  Data/1000genomes.zip\n  inflating: Results/GWAS4/1000genomes.genotypesA.bed  \n  inflating: Results/GWAS4/1000genomes.genotypesA.bim  \n  inflating: Results/GWAS4/1000genomes.genotypesA.fam  \n  inflating: Results/GWAS4/1000genomes.genotypesA.log  \n  inflating: Results/GWAS4/1000genomes.genotypesA.nosex  \n37 Results/GWAS4/1000genomes.genotypesA.fam\n\n\nWe have a subset of 37 individuals. Now, let’s explore the bim file.\n\ncat Results/GWAS4/1000genomes.genotypesA.bim | head -5\n\n1   rs112750067 0   10327   C   T\n1   .   0   11508   A   G\n1   .   0   12783   G   A\n1   .   0   13116   G   T\n1   .   0   14933   A   G\n\n\nOne should note that the file 1000genomes.genotypes.bim contains SNPs without an rs-identifier (or Reference SNP cluster ID). The missing rs-identifiers (noted as .) are not a problem for this tutorial. However, for good practice, we will assign unique identifiers to the SNPs (using available information):\n\nplink --bfile Results/GWAS4/1000genomes.genotypesA --set-missing-var-ids @:#[b37]\\$1,\\$2 --make-bed --out Results/GWAS4/1000genomes.genotypesA_no_missing_IDs --silent\n\nNow, let’s visualize the data to check the SNP names assigned. These are derived from the format @:#[b37]\\$1,\\$2 in the command above, which PLINK interprets as chromosome:locus[b37]Allele1,Allele2:\n\n# Show changes on the bim file\ncat Results/GWAS4/1000genomes.genotypesA_no_missing_IDs.bim | head -5\n\n1   rs112750067 0   10327   C   T\n1   1:11508[b37]A,G 0   11508   A   G\n1   1:12783[b37]A,G 0   12783   G   A\n1   1:13116[b37]G,T 0   13116   G   T\n1   1:14933[b37]A,G 0   14933   A   G\n\n\nPretty neat, right?\n\n\nQC on 1000GP data\nAs we covered in the GWAS3 notebook, it’s important to account for missingness, sex discrepancies, and minor allele frequency. We’ll apply standard QC thresholds to the 1000 GP data before merging it with HapMap data.\n\nplink --bfile Results/GWAS4/1000genomes.genotypesA_no_missing_IDs --geno 0.02  \\\n    --allow-no-sex --make-bed --out Results/GWAS4/1kG_MDS --silent\n\nplink --bfile Results/GWAS4/1kG_MDS --mind 0.02  \\\n    --allow-no-sex --make-bed --out Results/GWAS4/1kG_MDS2 --silent\n    \nplink --bfile Results/GWAS4/1kG_MDS2 --maf 0.05 --allow-no-sex --make-bed   \\\n    --out Results/GWAS4/1kG_MDS3 --silent\n\n\n\nSNPs matching between datasets\nN.B: Ensure that the datasets you want to merge share the same genomic build! Otherwise, you’ll need to include a liftover step.\nWe want to only consider SNPs that both datasets have in common. First, extract SNP names from the HapMap data and filter the 1000GP data to include only matching SNPs.\n\n#Print out SNPs from the HapMap data\nawk '{print$2}' Results/GWAS4/HapMap_3_r3_9.bim &gt; Results/GWAS4/HapMap_SNPs.txt\n\n#Extract the HapMap SNPs from the 1000GP data\nplink --bfile Results/GWAS4/1kG_MDS3 --extract Results/GWAS4/HapMap_SNPs.txt \\\n--make-bed --out Results/GWAS4/1kG_MDS4 --silent\n\nThis is how part of the list of SNP names looks like:\n\ncat Results/GWAS4/HapMap_SNPs.txt | head -5\n\nrs3131972\nrs3131969\nrs1048488\nrs12562034\nrs12124819\n\n\nNow we take the variants from the reduced 1000GP data, and go the other way around. We extract 1000GP variants from the HapMap data. In other words, the two extraction passages will intersect the SNPs. Below is the code to use the SNPs of the 1000GP data to reduce the HapMap data.\n\n#Print out SNPs from the HapMap data\nawk '{print$2}' Results/GWAS4/1kG_MDS4.bim &gt; Results/GWAS4/1kG_MDS4_SNPs.txt\n\n#Extract the HapMap SNPs from the 1000GP data\nplink --bfile Results/GWAS4/HapMap_3_r3_9 --extract Results/GWAS4/1kG_MDS4_SNPs.txt --recode \\\n--make-bed --out Results/GWAS4/HapMap_MDS --silent\n\nLook at the SNP names. Now, they are matching between the two bim files.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nLook at the two outputs a bit more carefully. Is there any problem?\nHint: - compare the chromosome and position across the 2 datasets. - compare the two alleles\n\n\n\nhead Results/GWAS4/HapMap_MDS.bim\n\n1   rs3131969   0   744045  A   G\n1   rs12562034  0   758311  A   G\n1   rs4970383   0   828418  A   C\n1   rs4475691   0   836671  T   C\n1   rs1806509   0   843817  C   A\n1   rs28576697  0   860508  C   T\n1   rs3748595   0   877423  A   C\n1   rs13303118  0   908247  G   T\n1   rs1891910   0   922320  A   G\n1   rs3128097   0   970323  G   A\n\n\n\nhead Results/GWAS4/1kG_MDS4.bim\n\n1   rs3131969   0   754182  A   G\n1   rs12562034  0   768448  A   G\n1   rs4970383   0   838555  A   C\n1   rs4475691   0   846808  T   C\n1   rs1806509   0   853954  A   C\n1   rs28576697  0   870645  C   T\n1   rs3748595   0   887560  A   C\n1   rs13303118  0   918384  T   G\n1   rs1891910   0   932457  A   G\n1   rs3128097   0   980460  G   A\n\n\n\n\nBuild matching\nGenomic data is based on a reference genome, and our datasets use different human reference versions. Since the reference genome improves over time, SNP positions may differ between datasets from different versions.\nWe extract SNP names and positions from the HapMap data and align the 1000GP data to match these SNPs using the --update-map option in PLINK.\n\n#Extract the HapMap variant coordinates\nawk '{print$2,$4}' Results/GWAS4/HapMap_MDS.map &gt; Results/GWAS4/buildhapmap.txt\n\nThis is how the list of SNPs look like:\n\ncat Results/GWAS4/buildhapmap.txt | head -5\n\nrs3131969 744045\nrs12562034 758311\nrs4970383 828418\nrs4475691 836671\nrs1806509 843817\n\n\nWe run PLINK to update the 1000GP variant coordinates based on HapMap, ignoring the warning about non-ascending positions:\n\nplink --bfile Results/GWAS4/1kG_MDS4 --update-map Results/GWAS4/buildhapmap.txt --make-bed \\\n--out Results/GWAS4/1kG_MDS5 --silent\n\nWarning: Base-pair positions are now unsorted!\n\n\n\n\nMerging datasets and performing MDS\nBefore merging the HapMap and 1000 Genomes datasets, we ensure compatibility through 3 steps:\n\nVerify the reference genome is compatible in both datasets.\nAlign SNP orientations (strand) across datasets.\nRemove SNPs that still differ after these steps.\n\nThe next steps are technical but ensure the datasets correspond correctly.\n1. We’ve matched SNP positions, but we also need to ensure the reference alleles align. Remember that most PLINK analyses consider the A1 allele (typically the minor allele) as the reference allele, which is logical when dealing exclusively with biallelic variants.\nBelow, we generate a list of SNPs ID and ‘reference alleles’ (corresponding to A1, column 5) from 1000GP.\n\n#Extract variant coordinates and reference alleles from 1000GP data\nawk '{print$2,$5}' Results/GWAS4/1kG_MDS5.bim &gt; Results/GWAS4/1kg_ref-list.txt\n\nHow the list looks like:\n\nhead -5 Results/GWAS4/1kg_ref-list.txt\n\nrs3131969 A\nrs12562034 A\nrs4970383 A\nrs4475691 T\nrs1806509 A\n\n\nThen, we assign them to the HapMap data --reference-allele option (aliases for --a1-allele). We use &&gt; /dev/null to redirect many warning messages away from the screen (Warning: Impossible A1 allele assignment for variant rs11488462). This warning flags variants with genotype mismatches. To address these warnings, we will first check for strand orientation issues before excluding any problematic variants.\n\nplink --bfile Results/GWAS4/HapMap_MDS --reference-allele Results/GWAS4/1kg_ref-list.txt --make-bed \\\n--out Results/GWAS4/HapMap-adj &&gt; /dev/null\n\n2. To resolve strand issues, we flip SNPs found in both datasets with complementary alleles (i.e. they were reported in opposite strands). We generate SNP lists (ID and alleles) for both datasets, identify unique SNPs, and visualize differences in allele reporting. If a SNP is unique but reports alleles differently, it will appear twice. Below are examples of SNPs with strand issues from the 1000GP and HapMap data:\n\nawk '{print$2,$5,$6}' Results/GWAS4/1kG_MDS5.bim &gt; Results/GWAS4/1kGMDS5_tmp\nawk '{print$2,$5,$6}' Results/GWAS4/HapMap-adj.bim &gt; Results/GWAS4/HapMap-adj_tmp\n\nsort Results/GWAS4/1kGMDS5_tmp Results/GWAS4/HapMap-adj_tmp |uniq -u &gt; Results/GWAS4/all_differences.txt\n\n\nhead -6 Results/GWAS4/all_differences.txt\n\nrs10006274 C T\nrs10006274 G A\nrs1008660 A G\nrs1008660 T C\nrs10088098 C T\nrs10088098 G A\n\n\nHow many of these differences are there?\n\nwc -l Results/GWAS4/all_differences.txt\n\n604 Results/GWAS4/all_differences.txt\n\n\nSome of these differences might be might be due to strand issues.\nLet’s look at this variant rs10006274. Will it be flipped in the HapMap dataset?\nThe answer is yes! If we look at the reference allele in 1kg_ref-list.txt, it shows C. This means the SNP is on the forward strand in 1000GP (C/T) and on the reverse strand in HapMap (G/A).\n\ngrep rs10006274 Results/GWAS4/1kg_ref-list.txt\n\nrs10006274 C\n\n\n\ngrep rs10006274 Results/GWAS4/all_differences.txt\n\nrs10006274 C T\nrs10006274 G A\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nLook at these other SNPs rs9614750 and rs10088098. Which ones will have to be flipped? Is it always the same dataset that must be flipped?\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe will first print out the SNPs from the reference file to know which line corresponds to each dataset (since we know we used the 1000 Genomes Project as the reference). If there are strand issues, the SNP will need to be flipped in the dataset that wasn’t used as the reference.\n\n\n\n\ngrep rs9614750 Results/GWAS4/1kg_ref-list.txt \n\nrs9614750 A\n\n\n\ngrep rs9614750 Results/GWAS4/all_differences.txt\n\nrs9614750 A G\nrs9614750 C G\n\n\nFor rs9614750, the genotype is reported as A/G in the 1000GP data, while in HapMap, it is C/G. This discrepancy between the two datasets means that the SNP will need to be removed later.\n\ngrep rs10088098 Results/GWAS4/1kg_ref-list.txt \n\nrs10088098 C\n\n\n\ngrep rs10088098 Results/GWAS4/all_differences.txt\n\nrs10088098 C T\nrs10088098 G A\n\n\nFor rs10088098, the genotype is reported as C/T in the 1000GP data, while in HapMap, it is G/A. This means that PLINK will flip the allele, as they are complementary.\n\nNow we take only the SNP names and give them to PLINK (option --flip), together with the reference genome (option --reference-allele):\n\n## Flip SNPs for resolving strand issues.\n# Print SNP-identifier and remove duplicates.\nawk '{print$1}' Results/GWAS4/all_differences.txt | sort -u &gt; Results/GWAS4/flip_list.txt\n\n\nwc -l Results/GWAS4/flip_list.txt\n\n302 Results/GWAS4/flip_list.txt\n\n\nThese are the SNP ID of non-corresponding SNPs (N=302) between the two files.\n\nhead -5 Results/GWAS4/flip_list.txt\n\nrs10006274\nrs1008660\nrs10088098\nrs1011297\nrs1023098\n302 Results/GWAS4/flip_list.txt\n\n\nApply the flipping option:\n\nplink --bfile Results/GWAS4/HapMap-adj --flip Results/GWAS4/flip_list.txt --reference-allele Results/GWAS4/1kg_ref-list.txt \\\n--make-bed --out Results/GWAS4/corrected_hapmap --silent\n\nWarning: Impossible A1 allele assignment for variant rs2581195.\nWarning: Impossible A1 allele assignment for variant rs9614750.\n\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThere might still be problematic SNPs after flipping.\n\nCheck if the expected allele flip occurred. (Hint: use grep to find the rs10006274 and rs9614750 variants; then compare the alleles assignments in the HapMap file before and after flipping.)\n\n\n\n\n# Write your code here \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nPLINK attempts to flip all SNPs in the list, but an error occurs when A1 does not match the one in the reference.\n\n\n\nNotice how this SNP has changed as we predicted:\n\ngrep rs10006274 Results/GWAS4/corrected_hapmap.bim \n\n4   rs10006274  0   124165369   C   T\n\n\n\ngrep rs10006274 Results/GWAS4/HapMap-adj.bim\n\n4   rs10006274  0   124165369   G   A\n\n\nrs10006274 was flipped and has the same strand orientation in both datasets (same alleles in A1 and A2).\nWhat happened to this one? PLINK attempts to resolve the mismatch by flipping the alleles but throws an error because the complementary alleles do not match the reference!\n\ngrep rs9614750 Results/GWAS4/corrected_hapmap.bim\n\n22  rs9614750   0   44436371    G   C\n\n\n\ngrep rs9614750 Results/GWAS4/HapMap-adj.bim \n\n22  rs9614750   0   44436371    C   G\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t need to flip the 1000GP data because the reference allele (A1) in the 1000GP data already matches the strand orientation used in the HapMap data.\n\n\n3. After flipping SNPs, some differ in their alleles when comparing datasets to each other (e.g. SNP rs9614750) and such SNPs must be removed.\nWe extract the SNPs from the corrected HapMap data and search for unique SNP (ID, A1, and A2), comparing them with those from the 1000GP data.\n\nawk '{print$2,$5,$6}' Results/GWAS4/corrected_hapmap.bim &gt; Results/GWAS4/corrected_hapmap_tmp\n\nsort Results/GWAS4/1kGMDS5_tmp Results/GWAS4/corrected_hapmap_tmp | uniq -u  &gt; Results/GWAS4/uncorresponding_SNPs.txt\n\nHow many SNP missmatches are there?\n\nwc -l Results/GWAS4/uncorresponding_SNPs.txt\n\n24 Results/GWAS4/uncorresponding_SNPs.txt\n\n\nThis corresponds to 12 unique SNP IDs with mismatched information.\n\nhead Results/GWAS4/uncorresponding_SNPs.txt \n\nrs11524965 T C\nrs11524965 T G\nrs12646999 G A\nrs12646999 G T\nrs17114359 C A\nrs17114359 C T\nrs17269854 C A\nrs17269854 C T\nrs2060424 G A\nrs2060424 G C\n\n\nWe extract again the SNP IDs from the file above, and exclude them using the PLINK option --exclude in both datasets\n\nawk '{print$1}' Results/GWAS4/uncorresponding_SNPs.txt | sort -u &gt; Results/GWAS4/SNPs_for_exclusion.txt\n\nplink --bfile Results/GWAS4/corrected_hapmap --exclude Results/GWAS4/SNPs_for_exclusion.txt \\\n--make-bed --out Results/GWAS4/HapMap_MDS3 --silent\nplink --bfile Results/GWAS4/1kG_MDS5 --exclude Results/GWAS4/SNPs_for_exclusion.txt \\\n--make-bed --out Results/GWAS4/1kG_MDS6 --silent\n\n5. We can finally merge the data! We provide our dataset (-bfile) and the one to add (--bmerge option):\n\nplink --bfile Results/GWAS4/corrected_hapmap --bmerge Results/GWAS4/1kG_MDS6.bed Results/GWAS4/1kG_MDS6.bim Results/GWAS4/1kG_MDS6.fam \\\n--allow-no-sex --make-bed --out Results/GWAS4/MDS_merge --silent\n\n\n\n\nPerform MDS on HapMap-CEU data anchored by 1000 Genomes data.\nMDS is typically performed on independent SNPs (pruned SNPs). We have previously identified such SNPs in this course, so we will extract only these SNPs for the analysis.\n\nplink --bfile Results/GWAS4/MDS_merge --extract Results/GWAS3/indepSNP.prune.in \\\n    --genome --out Results/GWAS4/MDS_merge --silent\n\nNow, we can use PLINK to run MDS with the option ---mds-plot specifying the number of components to calculate.\n\n# mds-plot\nplink --bfile Results/GWAS4/MDS_merge --read-genome Results/GWAS4/MDS_merge.genome \\\n    --cluster --mds-plot 10 --out Results/GWAS4/MDS_merge --silent\n\nFor visualization purposes, we downloaded the 1000 Genomes Project (1000GP) panel, which includes individual names and their corresponding population information.\n\nwget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20100804/20100804.ALL.panel -P Results/GWAS4 -q\n\nTo determine the population origins of HapMap individuals, we created a new file that combines the 1000GP panel information with the HapMap data, labeling the population HapMap entries as ‘OWN’.\n\nawk '{print$1,$2,\"OWN\"}' Results/GWAS4/HapMap_MDS.fam &gt; Results/GWAS4/popfile_own.txt\nawk '{print$1,$1,$2}' Results/GWAS4/20100804.ALL.panel &gt; Results/GWAS4/20100804.ALL.panel.txt\n\ncat &lt;(echo \"FID IID POP\") Results/GWAS4/20100804.ALL.panel.txt Results/GWAS4/popfile_own.txt &gt; Results/GWAS4/popfile.txt\n\n\n\n\n\n\n\nNote\n\n\n\nThe 1000 Genomes Project (1000GP) categorizes individuals into major continental groups—such as Europeans (EUR), Africans (AFR), Americans (AMR), East Asians (EAS), and South Asians (SAS)—each comprising various subpopulations. We will use this population structure information to visualize and determine the clusters our samples belong to.\n\n\n\n Switch to the R-GWAS kernel.\nLet’s visualize population stratification using the multidimensional scaling (MDS) results.\n\noptions(repr.plot.width = 12, repr.plot.height = 6)\n\nsuppressMessages(suppressWarnings(library(ggplot2)))\n\n# Read data into R \ndata &lt;- read.table(file=\"Results/GWAS4/MDS_merge.mds\",header=TRUE)\npop &lt;- read.table(file=\"Results/GWAS4/popfile.txt\",header=TRUE)\ndatafile &lt;- merge(data,pop,by=c(\"FID\",\"IID\"))\n\n# Metapopulation information for the population in the 1000GP dataset\nsuperpop &lt;- c(\n  \"JPT\" = \"ASN\",\n  \"ASW\" = \"AFR\",\n  \"CEU\" = \"EUR\",\n  \"CHB\" = \"ASN\",\n  \"CHD\" = \"ASN\",\n  \"YRI\" = \"AFR\",\n  \"LWK\" = \"AFR\",\n  \"TSI\" = \"EUR\",\n  \"MXL\" = \"AMR\",\n  \"GBR\" = \"EUR\",\n  \"FIN\" = \"EUR\",\n  \"CHS\" = \"ASN\",\n  \"PUR\" = \"AMR\",\n  \"OWN\" = \"UN\"\n)\n\n# add metapopulation info to the table \ndatafile$SUPERPOP &lt;- superpop[datafile$POP]\n\n# Plotting                \nscatter.mds &lt;- ggplot(datafile, aes(x=C1, y=C2, color=SUPERPOP)) +\n  geom_point(size=5, alpha=.4) +\n  scale_color_manual(values=c(\"AFR\" = \"red\", \"AMR\" = \"springgreen4\", \"ASN\" = \"gold\", \"EUR\" = \"blue\", \"UN\" = \"grey\" )) +\n  xlab(\"MD Component 1\") + \n  ylab(\"MD Component 2\") +\n  labs(color=\"Superpop\") +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), legend.text = element_text(size = 15), \n        axis.text = element_text(size = 14), legend.title=element_text(size=15))\n  \nshow(scatter.mds)\n\n\n\n\n\n\n\n\nThe HapMap data clusters closely with European populations such as CEU, TSI, IBS, GBR, and FIN, confirming its European composition. Additionally, the absence of distant points indicates no outliers in the HapMap dataset (grey datapoints cluster together).\n\nExclude ethnic outliers\nLet’s run the scripts to filter population stratification outliers for educational purposes (e.g. imagine a HapMap individual clusters in the lower-right corner with African populations).\n Switch to the Bash kernel.\nTo identify and exclude ethnic outliers in the HapMap dataset, select individuals falling within specific cut-off thresholds. These thresholds should be determined based on the visualization of the first two dimensions from the multidimensional scaling (MDS) analysis.\nWhat values would you select or apply in this context, and why? Hint: look at the plot above.\nPreview of the MDS results:\n\nhead -3 Results/GWAS4/MDS_merge2.mds | cut -f1-6 -d$'\\t'\n\n    FID       IID    SOL           C1           C2           C3           C4           C5           C6           C7           C8           C9          C10 \n   1328   NA06984      0   -0.0218368  -0.00620683  -0.00464884   0.00121512 -0.000413235   0.00221093    0.0104188  -0.00199382    0.0173257   -0.0131241 \n   1328   NA06989      0   -0.0208157  -0.00581126  -0.00638572   0.00503345  -0.00116741  -0.00369152    0.0120005   -0.0229035  -0.00238946    0.0381386 \n\n\nBased on the position of the target population’s cluster in the MDS plot, we will exclude individuals with MDS component 1 values less than 0 and MDS component 2 values less than -0.05.\nThe selection has to be done for the individuals we want to keep, so the area to be chosen has to be mirrored into &gt;0 and &gt;-0.05. We provide the MDS component values in columns 4 and 5 of the file (corresponding to the first 2 components), and extract the individuals using --keep\n\nawk '{ if ($4 &gt;0 || $5 &gt;-0.05) print $1,$2 }' Results/GWAS4/MDS_merge2.mds &gt; Results/GWAS4/EUR_MDS_merge2\n\nplink --bfile Results/GWAS4/HapMap_3_r3_9 --keep Results/GWAS4/EUR_MDS_merge2 --make-bed  \\\n--out Results/GWAS4/HapMap_3_r3_10 &gt; /dev/null\n\n\n\nCreating covariates for GWAS analysis\nThe 10 MDS dimensions will be used as covariates in the association analysis in the next tutorial to correct for population stratification. The covariate file is created by removing column 3 (SOL, optional metadata) from the MDS output file.\n\nplink --bfile Results/GWAS4/HapMap_3_r3_10 --extract Results/GWAS3/indepSNP.prune.in --genome  \\\n--out Results/GWAS4/HapMap_3_r3_10 &gt; /dev/null\nplink --bfile Results/GWAS4/HapMap_3_r3_10 --read-genome Results/GWAS4/HapMap_3_r3_10.genome \\\n--cluster --mds-plot 10 --out Results/GWAS4/HapMap_3_r3_10_mds &gt; /dev/null\n\n# Change the format of the .mds file into a plink covariate file.\nawk '{print $1, $2, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13}' Results/GWAS4/HapMap_3_r3_10_mds.mds &gt; Results/GWAS4/covar_mds.txt\n\nThe covar_mds.txt file contains the covariates to adjust for residual population stratification.\n\nhead -5 Results/GWAS4/covar_mds.txt\n\nFID IID C1 C2 C3 C4 C5 C6 C7 C8 C9 C10\n1328 NA06989 0.0193503 -0.0481539 0.053743 -8.56966e-05 0.0124037 -0.00872553 0.0146577 -0.0266013 0.0064429 -0.0149862\n1377 NA11891 0.0105154 -0.0241653 -0.00713715 -0.0276522 0.0272997 0.0044621 -0.00373271 -0.00561896 -0.0317101 0.0188078\n1349 NA11843 -0.00217144 0.0120046 -0.00508388 0.0193558 -0.00738542 0.0285001 -0.00512723 0.00271516 0.0029428 0.000145191\n1330 NA12341 -0.0124555 -0.0114929 0.0019162 -0.0252928 -0.0300722 -0.00411769 -0.0207568 -0.0122574 -0.017065 0.0353729\n\n\n\n\n\n\n\n\nWrapping up\n\n\n\nYou have now successfully checked your data for relatedness population stratification. You filtered out the individuals with high relatedness and produced a summary of the population structure using the MDS projection. You will use the MDS coordinates as a proxy for the population structure you want your association testing to be corrected for.\nIn the next notebook on Association Testing, you will need the following files from the folder Results/GWAS4/: - HapMap_3_r3_10 (the bfile, i.e., HapMap_3_r3_10.bed, HapMap_3_r3_10.bim, and HapMap_3_r3_10.fam) - covar_mds.txt which are the HapMap data and the MDS covariates highlighting the population stratification. Those are already available once you have been running this notebook.\nBelow is a cheat sheet of our new methods of QC. Again, it is important to remember that each method of QC should be justified, which will depend on the nature of the feature you are trying to analyze.\n\n\n\n\n\n\n\n\n\nStep\nCommand\nFunction\nThresholds and explanation\n\n\n\n\n6: Relatedness\n–genome\nCalculates identity by descent (IBD) of all sample pairs.\nUse independent SNPs ( pruning) for this analysis and limit it to autosomal chromosomes only.\n\n\n-\n–min\nSets threshold and creates a list of individuals with relatedness above the chosen threshold. This means that subjects who are related at, for example, pi‐hat &gt;0.2 (i.e., second-degree relatives) can be detected.\nCryptic relatedness can interfere with the association analysis. If you have a family‐based sample (e.g., parent‐offspring), you do not need to remove related pairs but the statistical analysis should take family relatedness into account. However, for a population-based sample, we suggest using a pi‐hat threshold of 0.2, which is in line with the literature (Anderson et al., 2010; Guo et al., 2014).\n\n\n7: Population Stratification\n–genome\nCalculates identity by descent (IBD) of all sample pairs.\nUse independent SNPs ( pruning) for this analysis and limit it to autosomal chromosomes only.\n\n\n-\n–cluster –mds-plot k\nProduces a k‐dimensional representation of any substructure in the data, based on IBS.\nK is the number of dimensions, which needs to be defined (typically 10). This is an important step of the QC that consists of multiple proceedings but for reasons of completeness, we briefly refer to this step in the table. This step will be described in more detail in the section “Controlling for population stratification.”"
  },
  {
    "objectID": "develop/general-intro.html",
    "href": "develop/general-intro.html",
    "title": "Getting Started with the GWAS Module",
    "section": "",
    "text": "In this course, we will use JupyterLab, an open-source interactive development environment (IDE) for working with Jupyter Notebooks. If you’re not familiar with this interface, check out the JupyterLab Documentation. It includes numerous screenshots and videos showcasing the cool features of JupyterLab.\nIn particular, we suggest reviewing: - Working (manage) files - How to edit files - How to use Terminals - Maning kernels and terminals"
  },
  {
    "objectID": "develop/general-intro.html#general-note-on-how-to-make-the-notebooks-work",
    "href": "develop/general-intro.html#general-note-on-how-to-make-the-notebooks-work",
    "title": "Getting Started with the GWAS Module",
    "section": "1 General note on how to make the notebooks work",
    "text": "1 General note on how to make the notebooks work\n\nWe will primarily use R and bash command line programming languages, where R is used for statistical analysis of the output from various tools running in bash.\nSince we use multiple coding languages, you need to choose a kernel every time we shift from one language to another. A kernel contains a programming language and the necessary packages to run the course material. To choose a kernel, go to the menu at the top of the page, select Kernel --&gt; Change Kernel, and then select the preferred one.\nWe will shift between two kernels, and along the notebook, you will see a picture indicating when to change the kernel. The two pictures are shown below:\n\n Choose the Bash kernel  Choose the R-GWAS kernel\n\nYou can run the code in each cell (grey background) by clicking the run cell sign in the toolbar, or simply by pressing Shift+Enter. When the code is done running, a small green check mark will appear on the left side.\nYou need to run the cells sequentially to execute the analysis. Please do not run a cell until the one above is done running, and do not skip any cells.\nTextual descriptions accompany the code to help you understand what is happening. Please try not to focus on understanding the code itself in too much detail, but rather focus on the explanations and commands’ output.\n\nYou can create new code cells by pressing + in the Menu bar above or by pressing B after selecting a cell.\n\n\n\n\n\n\n\nWarning\n\n\n\n\nIf a cell fails to run, verify the kernel in use, shown in the top-right corner.\nYou don’t know the answer to the exercises? You can use Generative AI to help with the code. It can assist you when the tutorial alone isn’t enough or if you want to explore additional concepts beyond the exercise."
  },
  {
    "objectID": "develop/exercises/gwas2-mice.html",
    "href": "develop/exercises/gwas2-mice.html",
    "title": "Mice data exercise",
    "section": "",
    "text": "1. Find out how many individuals and how many SNPs there are in the mice data. Which chromosomes are considered in the data? Is it possible to check it for sex discrepancy?\nThere are 1940 individuals and 2984 SNPs. There is only data from chromosomes 1-4. You cannot look for chromosome X inbreeding\n2. Are there any parents in the fam file? Hint: the fam file has just a backspace as a separator and is not tab-separated. This needs the specific option -d' ' for the cut command.\nNo parents’ information.\n4. Is there any data for sex and phenotype in the .fam file? Is this data from a case-control study or a sample-based study?\nNo information in the fam file.\n6. How can you find the minimum and maximum value of the phenotype (last column) using only the command line?\nThe minimum value is -4.13 and the maximum is 3.60.\n\n# Number of individuals \nwc -l Data/mice.fam\n\n\n# Number of variants\nwc -l Data/mice.bim\n\n\n# Chromosomes info\ncut -f1 Data/mice.bim | sort | uniq -c \n\n\n# Mother and father info \ncut -f3 -d\" \" Data/mice.fam | sort | uniq -c \ncut -f4 -d\" \" Data/mice.fam | sort | uniq -c \n\n\n# View .fam file \nhead -n 5 Data/mice.fam \n\n\n# sex \ncut -f6 -d\" \" Data/mice.fam | sort | uniq -c \n\n\n# phenotype \ncut -f6 -d\" \" Data/mice.fam | sort | uniq -c \n\n\n# phenotype lowest value\ncut -f3 -d\" \" Data/mice.pheno | sort -n | head -n1\n\n-4.124257\n\n\n\n# phenotype highest value\ncut -f3 -d\" \" Data/mice.pheno | sort -n | tail -n1\n\n3.594109"
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html",
    "href": "develop/GWAS2-DataCollection.html",
    "title": "Data collection",
    "section": "",
    "text": "Important notes for this notebook\n\n\n\nThis course module introduces fundamental concepts regarding designing and executing GWAS. We touch on data collection (which involves gathering genomic data and phenotypic information from diverse populations), potential biases, and practical considerations on the standard file formats in GWAS.\n\n\n\nUnderstand and identify types of GWAS studies in the scientific literature\nExplore the content of classical data files for GWAS through the command line\nApply and extend some command line programs to retrieve and explore data\n\n\n\n\nWe will only use the bash command line in this notebook. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#learning-outcomes",
    "href": "develop/GWAS2-DataCollection.html#learning-outcomes",
    "title": "Data collection",
    "section": "",
    "text": "Understand and identify types of GWAS studies in the scientific literature\nExplore the content of classical data files for GWAS through the command line\nApply and extend some command line programs to retrieve and explore data"
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#how-to-make-this-notebook-work",
    "href": "develop/GWAS2-DataCollection.html#how-to-make-this-notebook-work",
    "title": "Data collection",
    "section": "",
    "text": "We will only use the bash command line in this notebook. Be sure to click on the menu Kernel --&gt; Change Kernel --&gt; Bash\n Choose the Bash kernel"
  },
  {
    "objectID": "develop/GWAS2-DataCollection.html#description-of-the-data",
    "href": "develop/GWAS2-DataCollection.html#description-of-the-data",
    "title": "Data collection",
    "section": "Description of the Data",
    "text": "Description of the Data\nTo demonstrate all analysis steps with realistic genetic data, we will use a simulated dataset (N = 165) with a binary outcome measure, based on the publicly available data from the International HapMap Project (Gibbs et al. 2003). For this tutorial, we only included Utah residents with ancestry from Northern and Western Europe (CEU) to create an ethnically homogenous dataset. Because of the relatively small sample size of the HapMap data, genetic effect sizes in these simulations were set at values larger than usually observed in genetic studies of complex traits. It is important to note that larger sample sizes (e.g., at least in the order of thousands but likely even tens or hundreds of thousands) will be required to detect genetic risk factors of complex traits.\n Choose the Bash kernel.\nFirst, we link the data folder to easily access it by using the ln -sf command.\n\nln -sf ../Data\n\n\nFam file - Info on individuals\nWe begin by looking at HapMap_3_r3_1.fam, which you can do using the command below (head), which prints and selects the first 10 lines of a file:\n\nhead -10 Data/HapMap_3_r3_1.fam\n\n1328 NA06989 0 0 2 2\n1377 NA11891 0 0 1 2\n1349 NA11843 0 0 1 1\n1330 NA12341 0 0 2 2\n1444 NA12739 NA12748 NA12749 1 -9\n1344 NA10850 0 NA12058 2 -9\n1328 NA06984 0 0 1 2\n1463 NA12877 NA12889 NA12890 1 -9\n1418 NA12275 0 0 2 1\n13291 NA06986 0 0 1 1\n\n\nIt is just a plain text file with six columns separated by the others using the so-called tab spacing and no header. What information does each column contain?\n\n1st column (FID) is the family identification abbreviated as FID. The PLINK software was primarily developed for genomic analyses in humans, which is reflected in the naming terminology and default settings. As an example, in the goat Adatapt project (AdaptMap), the use of this column is to specify breed identity. Since this field is required, you can organize your data into any meaningful grouping that suits your needs, or repeat the sample ID if no other category fits better.\n2nd column (IID) is the “within family ID” or “individual ID” and is abbreviated as IID which is unique to each individual.\n3rd and 4th columns: the father and mother IDs are recorded in the third and fourth columns if genotyped. If parents are unknown or not available, their entries are set to 0.\n5th column (sex) contains the sex information of the individual in the IID column. According to the built-in coding, 1 is for males, 2 for females, and 0 is unknown. Similar to parent information, this is also many times missing, usually not a problem, but specific PLINK options need to be included in case any issues come up.\n6th column: denotes the phenotype of individuals in the IID column, with 1 for controls, 2 for cases, and other values or continuous measurements for other phenotypes. Missing values are represented by 0 or -9.\n\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\nThe exercises provide solutions below. However, you should try to solve the questions on your own. Feel free to use online search and AI tools to ask questions and find the answers.\n\nQ1. How many individuals are represented in the fam file? Find a command that counts the number of lines in the file.\nQ2. How many unique fathers and mothers are there in the population? Try to extract column 3 and count the unique occurrences of each ID of the fathers. Do the same with column 4 for the mothers. Hint: there is a white-space between columns.\nQ3. How many individuals do not have phenotype information? Search for missing values in column 6.\n\n\n\n\n# Write your code here - Q1\n\n\n# Write your code here - Q2\n\n\n# Write your code here - Q3\n\n\n\n\n\n\n\nSolution\n\n\n\nThe command wc (which stands for Word Count) can count the words in a file. With the option -l it will instead count the lines of the file.\n\n\n\nwc -l Data/HapMap_3_r3_1.fam\n\n165 Data/HapMap_3_r3_1.fam\n\n\nQ1: There are 165 individuals.\nTo see how many unique fathers there are, we need a sequence of commands. Each command has an output, which is sent to the next command using the pipe | symbol. We will: - cut the 3rd column of the text file setting the space as a separator for the columns, - sort the column extracted, so multiple occurrences of the same fathers are grouped together and not counted as separate groups - count how many times each father is shown using the command uniq with the option -c for counting - displays the first 5 rows of the file, allowing you to preview the data and check its format\n\ncut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | head -n5\n\n    115 0\n      1 NA06986\n      1 NA06993\n      1 NA06994\n      1 NA07051\n\n\nYou can see how there are 115 unknown fathers (0s), and all the others occur only once. To count how many fathers there are, we can simply run the same commands and add wc -l at the end. There are 51 lines, meaning 50 known fathers if we remove the unknown ones\n\ncut -f3 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l\n\n51\n\n\nYou can observe a similar thing for the mothers, where we have one less which is unknown\n\ncut -f4 -d\" \" Data/HapMap_3_r3_1.fam | sort | uniq -c | wc -l\n\n52\n\n\nQ2: There are 50 unique fathers and 51 unique mothers in the dataset.\nFinally, we will count the occurrences of 0 and -9 in column 6 using the awk command:\n\nawk '{if ($6 == 0 || $6 == -9) print $0}' Data/HapMap_3_r3_1.fam | wc -l \n\n53\n\n\nQ3: There are 53 individuals with missing phenotypes in the dataset.\nEnd of solution\n\n\n\nBim file - SNP location info\nThe .bim file contains the genomic locations of all SNPs in the data, and looks like this:\n\nhead -10 Data/HapMap_3_r3_1.bim\n\n1   rs2185539   0   556738  T   C\n1   rs11510103  0   557616  G   A\n1   rs11240767  0   718814  T   C\n1   rs3131972   0   742584  A   G\n1   rs3131969   0   744045  A   G\n1   rs1048488   0   750775  C   T\n1   rs12562034  0   758311  A   G\n1   rs12124819  0   766409  G   A\n1   rs4040617   0   769185  G   A\n1   rs2905036   0   782343  C   T\n\n\nSimilar to the .fam file, the bim file has six columns.\n\n1st column contains the chromosome number where the SNP is located. You can see that the first 10 SNPs are located on Chromosome 1.\n2nd column is the SNP name. This name is predefined during the construction of the SNP chip. If you ever want to compare versions of different SNP chips for the same species, overlapping the SNP name is an excellent way to start.\n3rd column is the position of the SNP in Morgans or centimorgans (cM), with zero value if you do not know or care. For most of the analyses, this could be kept as zero.\n4th column is the base pair coordinate of the SNP. In other words, you start to count from the beginning of the chromosome, and for each SNP write down its exact location. At the beginning of each new chromosome, the counter resets and starts from one again.\n\nIn the remaining two columns 5th and 6th are the alleles for respective SNPs. All SNPs on chips are biallelic, meaning each row shows only two alleles, with missing genotypes represented by zero (not shown in the .bim file). Genotypes in column five usually represent the minor allele, and column six shows the major allele (more about allele frequencies in data quality control).\nSimilar to .fam files, you can extract useful information just by looking at the file. Here, each row contains information about a particular SNP.\n\n\n\n\n\n\nStop - Read - Solve\n\n\n\n\nQ4. What is the total number of variants in the HapMap dataset?\n\n\n\n\n# Write your code here - Q4 \n\nDid you also get 1,457,897 SNPs for the HapMap data with the wc -l Data/HapMap_3_r3_1.bim command?\n\n\nBed file - Individual genotypes\nSo far, we know that the files you downloaded contain genotypes for 165 individuals, each of them genotyped for 1,457,897 SNPs. But where are the genotypes for the individual samples?\nThese are located in the binary file called HapMap_3_r3_1.bed file, but unfortunately, opening it as a normal text looks like this:\n\nhead -1 Data/HapMap_3_r3_1.bed\n\nl\u001b\u0001�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003��λ������������/����������������������\u0003��λ������������/�����������������������\u0003��λ������������/����������������������\u0003��������?�������������������������������\u0002������������������������⸿Ͼ��,��\u0002z�\u0003��ο������������/�����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003���������ﮪ���������+���������������\u0003����������������������������������������\u0003�����誮����\u000fΫ������������:���*�?����\u0003��������������﫿����������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003���?�������￿�����;�����������������\u0003//���������﮿������;����ή����������\u0002���?�������ʯϿ�\u000f����;����Ϯ�����������\u0002�����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003����������ʯ￾�����;����Ϯ���&lt;�������\u0002����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0003��뿌�������\u000fϿ������:���Ϫ���&lt;�.�?����\u0002�����������������������������������������\u0003����������������������������������������\u0003����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0003����������������������������������������\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002����̣�������?�������������˫�\u000e��������+�\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002�����������������������������������������\u0002������������������������������β�����.�\u0003�����������������������������������������\u0003����������?������������������������������\u0003�����������������������������������������\u0003�����������������������������������������\u0002�����������������(������/����������\n\n\nThis is because the genotypes are stored in a binary format, which saves disk space and allows faster processing by the computer, as it’s already in a machine-readable format. It is often useful to check out the individual genotypes, for that, you will need a new command called xxd to open the file which can then be pipeped into the head command.\n\nxxd -b Data/HapMap_3_r3_1.bed | head -10\n\n00000000: 01101100 00011011 00000001 11111111 11111111 11111111  l.....\n00000006: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000000c: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000012: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000018: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000001e: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000024: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n0000002a: 11111111 11111111 00000011 11111111 11111111 11111111  ......\n00000030: 11111111 11111111 11111111 11111111 11111111 11111111  ......\n00000036: 11110011 11111111 11111111 11111111 11111111 11111111  ......\n\n\nThe non-binary file format for the genotype is stored in the so-called .ped and .map files. These are also some well-known formats and widely used in various programs.\n\n\n\n\n\n\nChallenge yourself with the command line programs\n\n\n\nWe have real mice data from the heterogeneous stock data with an example phenotype. The datasets are with extensions .bed, .bim, .fam, .pheno and name prefix Data/mice. The mice.pheno file contains an example phenotype per individual.\n\nFind out how many individuals and how many SNPs there are in the mice data. Which chromosomes are considered in the data? Is it possible to check it for sex discrepancy?\nAre there any parents in the fam file? Hint: the fam file has just a backspace as a separator and is not tab-separated. This needs the specific option -d' ' for the cut command.\nIs there any data for sex and phenotype in the .fam file? Is this data from a case-control study or a sample-based study?\nHow can you find the minimum and maximum value of the phenotype (last column) using only the command line?\n\nAnswer the questions by creating all the code cells you need for the code to check your answers.\n\n\n\n\n\n\n\n\nClick to view answers\n\n\n\n Download mice-solutions.ipynb\n\n\n\n\n\n\n\n\nWrapping up\n\n\n\nWe have learned about the principles of study design for GWAS and the genotyping process. Now you are also able to use some basic commands to show the content of typical GWAS file formats."
  },
  {
    "objectID": "access/index.html",
    "href": "access/index.html",
    "title": "HPC access",
    "section": "",
    "text": "The Sandbox is collaborating with the two major academic high performance computing platforms in Denmark. Computerome is located at the Technical University of Denmark (and co-owned by the University of Copenhagen) while UCloud is owned by the University of Southern Denmark. These HPC platforms each have their own strengths which we leverage in the Sandbox in different ways."
  },
  {
    "objectID": "access/index.html#ucloud",
    "href": "access/index.html#ucloud",
    "title": "HPC access",
    "section": "UCloud",
    "text": "UCloud\nUCloud is a relatively new HPC platform that can be accessed by students at Danish universities (via a WAYF university login). It has a user friendly graphical user interface that supports straightforward project, user, and resource management. UCloud provides access to many tools via selectable Apps matched with a range of flexible compute resources, and the Sandbox is deploying training modules in this form such that any UCloud user can easily access Sandbox materials independently. The Sandbox is also hosting workshops and training events on UCloud in conjunction with in-person training.\n\n\n\n\n\n\nAccess Sandbox Apps on UCloud\n\n\n\nFind detailed instructions on accessing Sandbox apps here via UCloud. Check out UCloud’s extensive user docs here."
  },
  {
    "objectID": "access/index.html#computerome",
    "href": "access/index.html#computerome",
    "title": "HPC access",
    "section": "Computerome",
    "text": "Computerome\nComputerome is the home of many sensitive health datasets via collaborations between DTU, KU, Rigshospitalet, and other major health sector players in the Capital Region of Denmark. Computerome has recently launched their secure cloud platform, DELPHI, and in collaboration with the Sandbox has built a Course Platform on the same backbone such that courses and training can be conducted in the same environment as real research would be performed in the secure cloud. The Sandbox is supporting courses in the Course Platform, but it is also available for independent use by educators at Danish universities. Please see their website for more information on independent use and pricing, and contact us if you’d like to collaborate on hosting a course on Computerome. We can help with tool installation, environment testing, and user support (ranging from using the environment to course content if we have Sandbox staff with matching expertise).\nParticipants in courses co-hosted by the Sandbox can check here for access instructions."
  },
  {
    "objectID": "access/index.html#genomedk",
    "href": "access/index.html#genomedk",
    "title": "HPC access",
    "section": "GenomeDK",
    "text": "GenomeDK\nIn development."
  },
  {
    "objectID": "access/index.html#any-other-computing-cluster",
    "href": "access/index.html#any-other-computing-cluster",
    "title": "HPC access",
    "section": "Any other computing cluster",
    "text": "Any other computing cluster\nIn development."
  },
  {
    "objectID": "access/index.html#your-local-pc",
    "href": "access/index.html#your-local-pc",
    "title": "HPC access",
    "section": "Your local PC",
    "text": "Your local PC\nIn development."
  }
]