{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dbca95-89ad-4be5-a224-3239b6714db4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Association testing\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    toc: true\n",
    "  ipynb:\n",
    "    toc: true\n",
    "    number-sections: false\n",
    "bibliography: references/references_5.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5561ec9b-23a1-4d10-9ff0-8f5a60243a5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "::: {.callout-note title=\"Important notes for this notebook\" icon=false}\n",
    "\n",
    "After QC and generating MDS components as covariates to address population structure, the data is ready for association tests. In this tutorial, we provide scripts for association tests suitable for binary traits (e.g., alcohol-dependent patients vs. healthy controls) or quantitative traits (e.g., number of alcoholic beverages consumed per week).\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "- **Discuss** different types of association tests\n",
    "- **Identify** the suitable association test for your data\n",
    "\n",
    "## How to make this notebook work\n",
    "\n",
    "* In this notebook, we will use both `R` and `bash command line` programming languages. Remember to **change the kernel** whenever you transition from one language to the other (`Kernel --> Change Kernel`) indicated by the languages' images. We will first run `Bash` commands.  \n",
    "  \n",
    "<img src=\"Images/bash.png\" alt=\"Bash\" width=\"80\"> Choose the Bash kernel\n",
    " \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204aa031-8aae-4741-8fb6-f797269a2853",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{.callout-note title=\"Some theory\"}\n",
    "\n",
    "### Biometric model\n",
    "\n",
    "The theory behind genetic association is rooted in the biometrical model, first established by Fisher. According to this model, each genetic variant has an additive effect on a trait's value. For a specific variant and its genotypes, each genotype contributes differently to the trait. For example, in a two-allele system (A and a), the effects of the three genotypes (`AA, Aa, a`) are defined by two parameters: *d* (twice the difference between the homozygotes, AA and aa) and *h* (the effect of the heterozygote, Aa). The mean effect of the homozygotes is *m*. These parameters, *d* and *h*, are called genotypic effects [@neale2013methodology].\n",
    "\n",
    "![Figure 3.1. Biometrical genetics. The d and h increments of the gene difference A – a. Aa may lie on either side of m and the sign of h will vary accordingly; in the case illustrated h would be negative (adapted from Mather and Jinks, 1977, p. 32).](Images/biometric.png){fig-align=\"center\" label=\"fig-biometricmodel\"}\n",
    "\n",
    "#### Example \n",
    "\n",
    "Imagine that we are talking about genes that influence adult stature. Let us assume that the normal range for males is from 1.47m to 2m: that is, about **0.56m**. Let's assume that each somatic chromosome has one gene of roughly equivalent effect. Then, in each locus, the **homozygotes contribute ±d=±0.28 cm** (from the midpoint, *m*), depending on whether they are *AA*, the increasing homozygote, or *aa*, the decreasing homozygote. While some loci may have larger effects, others are likely to have smaller contributions. This model suggests that the effect of any given gene is subtle and difficult to detect using classical genetic methods.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f618a8",
   "metadata": {},
   "source": [
    "In GWAS, linear models have been typically used for continuous phenotypes  (e.g. BMI, height, blood pressure) and logistic models for binary traits (e.g. disease presence). These models account for fixed effects (such as genotype) but also need to consider random effects, represented as an error term, $e$, to minimize the influence of covariates, like sex of population structure. \n",
    "\n",
    "Linear mixed models (LMMs) are increasingly popular as an alternative to standard linear models and have proven to be effective for analyzing complex traits. They adjust for confounding factors such as population stratification, family structure, and cryptic relatedness, resulting in more reliable test statistics. However, they are usually more computationally demanding.\n",
    "\n",
    "# Modelling\n",
    "\n",
    "\n",
    "### The linear regression model\n",
    "\n",
    "The basic linear regression model is written as:\n",
    "\n",
    "$$y = G\\beta_G + X\\beta_X + \\epsilon$$\n",
    "\n",
    "Here, $y$ is the phenotype vector, $G$ is the genotype/dosage matrix (the allele counts) for the current variant, $X$ is the fixed-covariate matrix, and $e$ is the error term subject to least-squares minimization. \n",
    "\n",
    "\n",
    "PLINK supports SNP-trait association testing for both quantitative and binary traits:\n",
    "\n",
    "* `-assoc`: It performs chi-square tests for binary traits. For quantitative traits, it uses asymptotic methods (likelihood ratio test or Wald test) or empirical significance values. Covariates are not supported. It will automatically treat outcomes as quantitative when the phenotype column contains values other than 1, 2, 0, or missing. \n",
    "* `--linear`: Fits linear regression models for quantitative traits, allowing covariates.\n",
    "* `--logistic`: Fits or Firth logistic regression models for binary traits, supporting covariates and SNP-covariate interactions.\n",
    "\n",
    "Both `--linear` and `--logistic` are more flexible than `--assoc` but may run slower. Further details are available in PLINK's documentation. For detailed information on PLINK's association methods, visit PLINK Association Analysis [PLINK 1.9](https://www.cog-genomics.org/plink/1.9/assoc) or [PLINK 2.0](https://www.cog-genomics.org/plink/2.0/assoc). Note that command options differ between versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc8cbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PLINK in association testing\n",
    "\n",
    "PLINK performs one degree of freedom (1 df) chi-square allelic test in which the trait value, or the log‐odds of a binary trait, increases or decreases linearly as a function of the number of risk alleles. This basic biallelic test will compare the frequency of the alleles in cases vs. controls. All models are tests for the minor allele *a*: \n",
    "* allelic association test, 1 df: *a* vs. *A*\n",
    "  \n",
    "In addition, non‐additive tests are available:\n",
    "* dominant gene action test, 1 df: (*aa* & *Aa*) vs *AA*\n",
    "* recessive gene action test, 1 df: aa vs (*Aa* & *AA*)\n",
    "* genotypic association test, 2 df: *aa* vs *Aa* vs *AA*\n",
    "\n",
    "However, non‐additive tests are not widely applied, because the statistical power to detect non‐additivity is low in practice. More complex analyses (e.g., Cox regression analysis) can be performed by using R‐based “plug‐in” functions in PLINK.\n",
    "\n",
    "\n",
    "### Analysis with PLINK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9f2a0-a156-4e9d-9d0d-1d76f3197022",
   "metadata": {},
   "source": [
    "<img src=\"Images/bash.png\" alt=\"Bash\" width=\"40\"> Switch to the Bash kernel.\n",
    "\n",
    "We link the data folder again and create a folder for output files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7317ea-43cf-4538-80f5-88d38de2e2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln -sf ../Data\n",
    "mkdir -p Results/GWAS5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fba9b",
   "metadata": {},
   "source": [
    "Recall that our dataset contains **binary** traits: phenotype can take two values 0 or 1. In this tutorial, we will apply both `--assoc` and `--logistic` to our data. A reminder that the `-assoc` option does not allow correct covariates such as principal components (PCs)/MDS components for population stratification makes it less suited for association analyses. However, we will look at the results for educational purposes.\n",
    "\n",
    "We start with `--assoc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959006a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plink --bfile Results/GWAS4/HapMap_3_r3_10 --assoc --out Results/GWAS5/assoc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7382325",
   "metadata": {},
   "source": [
    "Let's have a look at the association output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e2613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head -5 Results/GWAS5/assoc_results.assoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a42bc5",
   "metadata": {},
   "source": [
    "where the columns represent:\n",
    "\n",
    "* `CHR`\tChromosome code  \n",
    "* `SNP`\tVariant identifier  \n",
    "* `BP`\tBase-pair coordinate  \n",
    "* `A1`\tAllele 1 (usually minor)  \n",
    "* `F_A`\tAllele 1 frequency among cases  \n",
    "* `F_U`\tAllele 1 frequency among controls  \n",
    "* `A2`\tAllele 2  \n",
    "* `CHISQ`\tAllelic test chi-square statistic\n",
    "* `P`\tAllelic test p-value. The p-value indicates the probability that the observed association (or one more extreme) would occur by chance if there is no true association between the SNP and the trait.\n",
    "* `OR` odds(allele 1 | case) / odds(allele 1 | control)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8327a",
   "metadata": {},
   "source": [
    "Next, we use the `--logistic` and `--covar` options to provide the MDS components `covar_mds.txt` as covariates (from the previous tutorial). We will remove rows with `NA` values from the output to prevent issues during plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1242c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --logistic \n",
    "# Note, we use the option --hide-covar to only show the additive results of the SNPs in the output file.\n",
    "plink --bfile Results/GWAS4/HapMap_3_r3_10 \\\n",
    "    --covar Results/GWAS4/covar_mds.txt \\\n",
    "    --logistic hide-covar \\\n",
    "    --out Results/GWAS5/logistic_results \\\n",
    "    --silent\n",
    "\n",
    "# Remove NA values, those might give problems generating plots in later steps.\n",
    "awk '!/'NA'/' Results/GWAS5/logistic_results.assoc.logistic > Results/GWAS5/logistic_results.assoc_2.logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9689c31-30fa-4f81-9579-38b3f15434e8",
   "metadata": {},
   "source": [
    "In addition to the columns (CHR, SNP, BP, A1, OR, and P) also present in the `--assoc` output, new columns include:\n",
    "\n",
    "- `TEST`: type of test performed. It usually includes \"ADD\" (additive model) but may also include other genetic models depending on the options specified (e.g., dominant, recessive).\n",
    "- `NMISS`: number of non-missing observations (individuals) used in the analysis for that particular SNP.\n",
    "- `STAT`: the test t-statistic for the logistic regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef27076-2a68-4c86-bbf6-08ea46f68361",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -5 Results/GWAS5/logistic_results.assoc.logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6055c6e",
   "metadata": {},
   "source": [
    "The results of these GWAS analyses will be visualized in the final step, highlighting any genome-wide significant SNPs in the dataset.\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "For quantitative traits the option `--logistic` should be replaced by `--linear`. The logistic regression is used for binary trait (e.g. disease status: 1 = affected, 0 = unaffected) and gives the Odds Ratio at each SNP for the two trait values. Linear regression is for continuous phenotypes (e.g., height, blood pressure, gene expression levels) and makes a linear regression test.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee689d",
   "metadata": {},
   "source": [
    "# Correction for multiple testing\n",
    "\n",
    "Modern genotyping arrays can test up to 4 million markers, increasing the risk of false positives due to multiple testing. While a single comparison has a low error rate, analyzing millions of markers amplifies this risk. Common methods to address this include:\n",
    "\n",
    "- **Bonferroni Correction**: Adjusts the p-value threshold by dividing $0.05$ by the number of tests, controlling false positives. It controls the probability of at least one false positive but may be overly strict due to SNP correlation caused by linkage disequilibrium (hence, increased FN).\n",
    "- **False Discovery Rate (FDR)**: Minimizes the proportion of false positives among significant results (specified threshold) being less conservative than Bonferroni. However, it assumes SNP independence, which may not hold with LD.\n",
    "- **Permutation Testing**: Randomizes outcome labels to generate an empirical null distribution, enabling robust p-value adjustments. This process is repeated extensively (often millions of times) to eliminate true associations. It is computationally heavier.\n",
    "\n",
    "To learn more about statistical testing and false positives, [look at this online book chapter](https://web.stanford.edu/class/bios221/book/06-chap.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae8b6f",
   "metadata": {},
   "source": [
    "### Examining PLINK `--assoc` output\n",
    "\n",
    "Before executing PLINK's command for multiple testing, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158389b-142c-4a5e-a925-ef9eed4d3ad4",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "\n",
    "The Bonferroni-corrected p-value threshold is calculated using an initial threshold of 0.05. \n",
    "\n",
    "1. Determine the new BF threshold for this dataset.\n",
    "2. How many SNPs in your dataset appear to be significantly associated with the phenotype using this threshold, and how many would be considered significant without the multiple testing correction?\n",
    "\n",
    "Hint: \n",
    "\n",
    "- 1. Apply the formula: bonferroni_threshold <- alpha / num_snps. You can get the number of SNPs from `Results/GWAS4/HapMap_3_r3_10.bim`. Use Python or R\n",
    "- 2. Look at the P-values from the association test in column 9 (`Results/GWAS5/assoc_results.assoc`), how many SNPs would pass the two different thresholds?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9bef5-dfcf-4154-bf61-c85161a875f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here and change kernel accordingly \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce6210-f96d-4502-bb0a-18390e149294",
   "metadata": {},
   "source": [
    ":::{.callout-tip title=\"Solution\" collapse=true}\n",
    "\n",
    "- BF P-value: $4.7e-08$. \n",
    "- 55433 SNPs are significant with $0.05$ cutoff and 0 would pass the threshold $4.7e-08$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b351c-62b0-4d8d-a521-98d8a851cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l Results/GWAS4/HapMap_3_r3_10.bim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589b40b-f233-43b3-af3a-70809eaf361d",
   "metadata": {},
   "source": [
    "<img src=\"Images/R.png\" alt=\"R\" width=\"40\"> Switch to the R kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42533a52-ca04-422e-a240-44c93adce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "result <- 0.05 / 1073788\n",
    "format(result, scientific = TRUE, digits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82531aaa-e0c2-47e4-a8c7-bc91541dcb28",
   "metadata": {},
   "source": [
    "<img src=\"Images/bash.png\" alt=\"Bash\" width=\"40\"> Switch to the Bash kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a7b83-e44f-4c62-8938-bf2b9e9be8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '$9 < 0.05' Results/GWAS5/assoc_results.assoc | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5b661-1768-4944-9b53-37a01c6f287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '$9 < 4.7e-08' Results/GWAS5/assoc_results.assoc | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e182c8c-effd-4fb7-bdb8-689077de099e",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e4332-fe21-4815-af6e-347e927b879e",
   "metadata": {},
   "source": [
    "### PLINK Commands\n",
    "\n",
    "We know that no SNPs would pass the strict BF cutoff, is this also the case for other correction approaches?\n",
    "\n",
    "#### Adjustment for multiple testing \n",
    "\n",
    "PLINK's `--adjust` option will generate a file containing the adjusted significance values for several multiple correction approaches, saved to `Results/GWAS5/adjusted_assoc_results.assoc.adjusted`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8686d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --adjust\n",
    "plink --bfile Results/GWAS4/HapMap_3_r3_10 \\\n",
    "    --assoc \\\n",
    "    --adjust \\\n",
    "    --out Results/GWAS5/adjusted_assoc_results \\\n",
    "    --silent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855e0cf-20dc-4eeb-92f9-725dcb447acc",
   "metadata": {},
   "source": [
    "Now, let's look at the output file from PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9835a22-4844-4d8c-81ca-c7d240b6f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 Results/GWAS5/adjusted_assoc_results.assoc.adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0789f77-772e-4745-8a76-1259f2f3a3e9",
   "metadata": {},
   "source": [
    "which contains the fields: \n",
    "\n",
    "- `CHR`         Chromosome number\n",
    "- `SNP`         SNP identifier\n",
    "- `UNADJ`       Unadjusted p-value\n",
    "- `GC`          Genomic-control corrected p-values\n",
    "- `BONF`        Bonferroni single-step adjusted p-values\n",
    "- `HOLM`        Holm (1979) step-down adjusted p-values\n",
    "- `SIDAK_SS`    Sidak single-step adjusted p-values\n",
    "- `SIDAK_SD`    Sidak step-down adjusted p-values\n",
    "- `FDR_BH`     Benjamini & Hochberg (1995) step-up FDR control\n",
    "- `FDR_BY`      Benjamini & Yekutieli (2001) step-up FDR control \n",
    "\n",
    "The Bonferroni correction for all SNPs (`BONF`) gives a value of 1, indicating that the SNP is not significantly associated with the phenotype based on the threshold *0.05/n*. As mentioned earlier, this suggests that the method might be too conservative, potentially leading to a high number of false negatives (Type II errors).\n",
    "\n",
    "However, this is not the case for the Benjamini & Hochberg method of FDR (`FDR-BH`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0215a0",
   "metadata": {},
   "source": [
    "<img src=\"Images/R.png\" alt=\"R\" width=\"40\"> Switch to the R kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5bd24-6970-46ad-8b63-1f1502088f32",
   "metadata": {},
   "source": [
    "In the code below, we will plot the distribution of `FDR-BH` values to illustrate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575384cc-8ed9-4a0c-a2c5-e0bf13211c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(suppressWarnings(library(ggplot2)))\n",
    "\n",
    "options(repr.plot.width = 9, repr.plot.height = 4)\n",
    "\n",
    "tests <- read.table(\"Results/GWAS5/adjusted_assoc_results.assoc.adjusted\", header=T)\n",
    "\n",
    "hist.relatedness <- ggplot(tests, aes(x=FDR_BH)) +\n",
    "  geom_histogram(binwidth = 0.02, col = \"black\", fill=\"tomato\") + \n",
    "  labs(title = \"Histogram of p-values for FDR correction (B-H correction)\") + \n",
    "  xlab(\"p-value\") + \n",
    "  ylab(\"Frequency\") + \n",
    "  theme_bw() +\n",
    "  theme(axis.title=element_text(size=14), axis.text=element_text(size=12))\n",
    "\n",
    "show(hist.relatedness)\n",
    "\n",
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ac9b-2978-44a9-a33e-35f3b3e3d67c",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "In the R code above, use the `summary()` to get an overview of the distribution of `FDR-BH` values. \n",
    "\n",
    "- What is the minimum FDR-adjusted p-value? and the mean FDR-adjusted p-value?\n",
    "- Are there any SNPs significantly associated with the phenotype after applying genome-wide correction?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85086dbc-5733-4762-9740-bf320514f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e700e1-5896-4771-9e8f-9c00cda0b368",
   "metadata": {},
   "source": [
    ":::{.callout-tip title=\"Solution\"}\n",
    "\n",
    "In R: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c8b9b-6766-44d1-958a-b7881ccc8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(tests$FDR_BH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56062b7d-e9bf-47f3-a17d-a84a61790803",
   "metadata": {},
   "source": [
    "\n",
    "The black line shows very few values with an FDR-adjusted p-value below ~0.95, with the lowest around 0.29 (as shown in the summary table). Therefore, no variants are significant at the 0.05 level after genome-wide correction.\n",
    "\n",
    ":::\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd0e0b",
   "metadata": {},
   "source": [
    "#### Permutation\n",
    "Let's perform a permutation correction. This is a computationally intensive approach, so we will run it on a subset of the data to reduce the computational time (e.g. chr 22). We need the option `--mperm` to define how many permutations we want to do.\n",
    "\n",
    "First, we generate a subset of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e10fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "awk '{ if ($1 == 22) print $2 }' Results/GWAS4/HapMap_3_r3_10.bim > Results/GWAS5/subset_snp_chr_22.txt\n",
    "\n",
    "plink --bfile Results/GWAS4/HapMap_3_r3_10 \\\n",
    "    --extract Results/GWAS5/subset_snp_chr_22.txt \\\n",
    "    --make-bed \\\n",
    "    --out Results/GWAS5/HapMap_subset_for_perm \\\n",
    "    --silent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa416ea1-fcac-46ec-bf00-57cf5ee2a0fc",
   "metadata": {},
   "source": [
    "Then, we perform 100K permutations (usually you would do more):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98069683-b3c5-40fb-966f-1c2f6ebcb783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plink --bfile Results/GWAS5/HapMap_subset_for_perm \\\n",
    "    --assoc \\\n",
    "    --mperm 1000000 \\\n",
    "    --threads 4 \\\n",
    "    --out Results/GWAS5/perm_result \\\n",
    "    --silent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e51d18-29f9-4687-a889-18437a038b9f",
   "metadata": {},
   "source": [
    "In the output, the `EMP1` indicates the empirical p-value, and `EMP2` is the corrected one. Let's check the ordered permutation results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439644f-def6-45bb-957a-2f4b89eb0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort -gk 4 Results/GWAS5/perm_result.assoc.mperm | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5ed2a-e852-431d-8fc7-a36398e22799",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "- Are there any significant SNPs? \n",
    "\n",
    "Hint: generate an overview of the distribution of `EMP2` values (similar to what we did for `FDR_BH`).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97951a-5242-487f-a0f8-a4b4b64600d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e970f5-3569-4f18-aa4b-3d39acbfadd1",
   "metadata": {},
   "source": [
    ":::{.callout-tip title=\"Solution\" collapse=\"true\"}\n",
    "\n",
    "Again, we do not infer any significance from the permutation correction. Let's use the `summary()` function and visualize the values. \n",
    "\n",
    "<img src=\"Images/R.png\" alt=\"R\" width=\"40\"> Switch to the R kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a8c79-7ce1-4b4c-8c40-708967e5b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages(suppressWarnings(library(ggplot2)))\n",
    "\n",
    "options(repr.plot.width = 9, repr.plot.height = 4)\n",
    "\n",
    "tests <- read.table(\"Results/GWAS5/perm_result.assoc.mperm\", header=T)\n",
    "\n",
    "hist.relatedness <- ggplot(tests, aes(x=EMP2)) +\n",
    "  geom_histogram(binwidth = 0.02, col = \"black\", fill=\"tomato\") + \n",
    "  labs(title = \"Histogram of p-values corrected by permutation\") + \n",
    "  xlab(\"p-value\") + \n",
    "  ylab(\"Frequency\") + \n",
    "  theme_bw() +\n",
    "  theme(axis.title=element_text(size=14), axis.text=element_text(size=14), plot.title=element_text(size=15))\n",
    "\n",
    "\n",
    "show(hist.relatedness)\n",
    "\n",
    "summary(tests$EMP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f1075-ba13-4686-b204-6244db86ab70",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97be6b7",
   "metadata": {},
   "source": [
    "In summary, when correcting for multiple testing, it is crucial to remember that different correction methods have distinct properties. It is the responsibility of the investigator to choose the appropriate method and interpret the results accordingly. Generally, permutation correction is considered the gold standard in GWAS analysis, though it may not always be effective with certain statistical models [@joo_multiple_2016, @uffelmann_genome-wide_2021], a limitation to be mindful of. Further pros and cons of this method, which can be used for association and dealing with multiple testing, are described in this article [@marees2018tutorial]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5dfea-fcfb-47e9-8072-9128c579f294",
   "metadata": {},
   "source": [
    "This step would also need to be performed for the logistic output; however, we will skip it in this case as there are no differences in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a7381",
   "metadata": {},
   "source": [
    "## Manhattan and QQ-plots\n",
    "\n",
    "A common approach to identify high-association alleles is to plot the association results and look for peaks visually. One such method is the Manhattan plot, where each SNP is plotted against the negative log of its p-value from the association test [@gibson2010hints]. This can be done using the `manhattan()` function from the `qqman` package in `R`. To customize the plots (adjust colors, font sizes, etc.), check the package vignette [here](https://cran.r-project.org/web/packages/qqman/vignettes/qqman.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bbfc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup to avoid long messages and plot on screen\n",
    "options(warn=-1)\n",
    "options(jupyter.plot_mimetypes = 'image/png')\n",
    "\n",
    "# Load GWAS package qqman\n",
    "suppressMessages(library(\"qqman\"))\n",
    "\n",
    "# Manhattan plot using --logistic results\n",
    "results_log <- read.table(\"Results/GWAS5/logistic_results.assoc_2.logistic\", head=TRUE)\n",
    "manhattan(results_log, main = \"Manhattan plot: logistic\", cex.axis=1.1)\n",
    "\n",
    "# Manhattan plot using --assoc\n",
    "results_as <- read.table(\"Results/GWAS5/assoc_results.assoc\", head=TRUE)\n",
    "manhattan(results_as, main = \"Manhattan plot: assoc\", cex.axis=1.1)  \n",
    "\n",
    "# Zoom-in version in a significant region in chromosome 3\n",
    "manhattan(subset(results_as, CHR==3), xlim = c(8.1e7, 8.5e7), chr=\"CHR\", \n",
    "          main = \"Manhattan plot: assoc, chr 3\", cex.axis=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d13d7c-0e3f-425b-9944-e3ccebc82bdb",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "\n",
    "The blue line represents the threshold for significance (in the two plots, $10^{-5}$). We  see no significant SNPs associated with the phenotype when we use the `--logistic` command (first plot). However, when we use the `--assoc` command (second plot), we obtain significant SNPs. \n",
    "\n",
    "Why is there a difference?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387264e2-8dfc-4933-9a03-2a42e815892c",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{.callout-tip title=\"Solution\" collapse=\"true\"}\n",
    "\n",
    "Recall from the beginning of this chapter that the `--assoc` command does not correct for covariates. So even though we have promising (and hopefully publishable!) results, this form of analysis may be flawed by the underlying population stratification, which is taken into account with the `--logistic` model. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bc1a3",
   "metadata": {},
   "source": [
    "The second method of visually determining significance is to use a [**QQ-plot**](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot). This plots the expected $-\\log_{10}p$ value against the observed $-\\log_{10}p$ value. It's a good way to observe not only outliers that could have significant associations but also peculiarities within our data. For example, if a plot suggests an extreme deviation between the x- and y-axes, then there might be an error with our analyses or data. \n",
    "\n",
    "We will create these plots using the qq() function from the qqman package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71434c4b-e28f-4ed5-b81e-0d4935934374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup to avoid long messages and plot on-screen\n",
    "options(warn=-1)\n",
    "options(jupyter.plot_mimetypes = 'image/png')\n",
    "\n",
    "# Install and load GWAS package qqman\n",
    "suppressMessages(library(\"qqman\")) \n",
    "\n",
    "# QQ plot for --logistic\n",
    "results_log <- read.table(\"Results/GWAS5/logistic_results.assoc_2.logistic\", head=TRUE)\n",
    "qq(results_log$P, main = \"Q-Q plot of GWAS p-values (log) using --logistic\")\n",
    "\n",
    "# QQ plot for --assoc\n",
    "results_as <- read.table(\"Results/GWAS5/assoc_results.assoc\", head=TRUE)\n",
    "qq(results_as$P, main = \"Q-Q plot of GWAS p-values (log) using --assoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def0584-dcc4-4c11-9c96-5231d13ff6ab",
   "metadata": {},
   "source": [
    ":::{.callout-important title=\"Stop - Read - Solve\"}\n",
    "Given the two Q-Q plots (based on logistic regression and basic association test), **how do the observed p-values compare to the expected p-values under the null hypothesis?** Write a short interpretation based on your observations\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b5cea-907e-46e5-ac02-c48d90f1acf3",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "Because of the relatively small sample size of the HapMap data, the genetic effect sizes in these simulations were set higher than what is typically observed in genetic studies of complex traits. In reality, detecting genetic risk factors for complex traits requires much larger sample sizes—typically in the thousands, and often in the tens or even hundreds of thousands. Finally, it is important to remember that this is a simulated dataset designed to mimic real data but remains very limited in size.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0777013a",
   "metadata": {},
   "source": [
    ":::{.callout-tip title=\"Solution\" collapse=\"true\"}\n",
    "- In the first plot (`--logistic`), the observed values are lower than the expected ones (consistent with what we saw in the Manhattan plot). This suggests an unexpected lack of significant findings. This could be due to overly conservative corrections, biases in the dataset, or poor study power (small sample size or very small effect sizes). \n",
    "- On the other hand, in the `assoc` QQ-plot, some SNPs show stronger associations than expected (observed p-values lower than expected), deviating from the diagonal which suggests a potential true association. Although the top-right corner typically continues deviating upward with observed values higher than expected, here it follows an unexpected pattern. However, before trusting any result, we must conduct further analyses, particularly to assess population stratification. Even if we have confidence in our association test and sufficient power to detect associated variants, careful evaluation is necessary to rule out confounding factors.\n",
    "\n",
    "Moreover, it is important to remember that, while this suggests an association between these SNPs and the studied phenotype, there isn't sufficient information here to determine the **causal variant**. In fact, there could potentially be multiple causal variants and the causal variants could be in LD with some of the significant variants. Identifying the causal variants would require further investigation using biological methods. However, this analysis has significantly reduced the number of SNPs that need to be studied.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Matti Pirinen, University of Helsinki",
   "date": "Updated: 10-11-2020; 1st version: 6-Feb-2019.",
   "output": {
    "html_document": "default"
   },
   "title": "GWAS 6: Confounders and covariates",
   "urlcolor": "blue"
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
